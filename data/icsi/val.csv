Source,Summary
O_K Uh. Alright. So. I uh uh wanted to mention a couple little bits of news. Um Hynek is supposed to come for a couple days next week. Don't know which days yet. So hopefully he'll have some intensive time to - to work with people. Um. The second thing is that um we're starting to talk about maybe having Sunil come here uh for some chunk of the summer. So that may or may not happen but if he does since actually Pratibha is going to be off at I_B_M um the uh effort will pretty much shift here  cuz Sunil will be here and other people are working on other things I think. So. So. Uh. That's my news. Alright. Cool. I need a new office mate. Oh  O_K. Yeah. That's cool. There you go. Right. It will be some- sometime in summer. July or August  or. Yeah  I mean it may not happen. I mean he wants - uh I think he wants some experience someplace else and he's - he's uh thinking of going someplace  but it's - I mean Pratibha is getting her experience going to I_B_M and he may come here. So. Mm-hmm. But y- I don't know maybe June. Maybe earlier. But uh. Anyway  Hynek will be here next week and maybe he'll know more about it. Oh yeah. Well  the news more specifically t- for Aurora um So I guess there was again a conference call but uh they are not decide on everything yet. For the V_A_D they - probably they will do something like having some kind of idealized V_A_D that they could run on the channel zero of the SpeechDat-Car and then take the same um end points Mm-hmm. and apply them on channel one so it's - Oh so take a real V_A_D but apply it to - to - to the clean - Uh g- Yeah  to the clean and take the end points for the noisy. Mmm. clean data. O_K. But I am not sure this is decided yet. Um. And - and i- when they're talking about it  do you have the impression that they're talking about a particular V_A_D which everybody would use? or - or just that everybody would use the same procedure? Well   probably uh s- the same V_A_D for everybody. Mm-hmm. Um. So they would just provide that as part of the data. Maybe. But this is still - Yeah. Sounds like they're still arguing. Yeah. Yeah  they're still not decided. Yeah. Yeah. Um I don't know what - Yeah. Nothing much. Yeah. Probably the um - these weight things  they will apply the same kind of weighting scheme for T_I-digits than for the SpeechDat-Car. So it would be weighting of um - It would be an average of improvements rather than an average of word error rates which would make the more clean Mm-hmm. parts of T_I-digits more important than they are right now. O_K. Uh but it sounds like none of this is really decided  that this is how things are leaning and - This They - they t- I think they will tend to go this way  but hmm. Uh. Yeah  if we have the result for the tandem with um M_S_G also So @@ it was t- Yeah there is no surpri- there is no surprise. Well  so there is nor significant improvement. Um. Yeah  basically that's all. We've started to work on some kind of report for the work so we've not much Mm-hmm. more results. Hmm. Yeah you have a uh - you have a lunch talk sometime in - When is it? Mm-hmm. It's next week  yeah. Next week? Oh  O_K. How about the um - the thing that you guys were working on before the uh Uh voiced-unvoiced uh - Oh yes. But  no. This week I'm - I am begin to - to write the report on - Ah. I stopped it. Interfered. Yeah. You stopped working on it I see O_K. Uh. So it sounds like basically things are slowing down a bit? And - and - and trying to collate results? and get something from it? Mm-hmm. Yeah. Yeah. Um. Yeah. Right now  Sunil seems i- is in India actually. Uh so there is no progress apparently from their side neither. Right. Right. But that sort of puts it on us to do it. But. Um. And - I'm sorry? Kind of puts it on us to put more in  then  really. Yeah. I mean. Uh. Who's - who's - was uh looking at the combination of uh spectral s- subtraction approaches with what we had for instance. Sunil was working on this. O_K. Um. He sent a bunch of - a bunch of results uh but I don't know what's the status of this. I guess it was just the result that he sent  so. Um. What was that again? He just used the spectral subtraction and the L_D_A filters I guess Mm-hmm. Mmm. And - And it was not better than what we had before. Then he tried to put the on-line normalization and it did not improve further  putting the on-line normalization  so. Um. Yeah. Hmm. Huh. O_K. Well - Hmm. Yeah. I - uh  I g- so I guess nothing has ever happened about uh making a standardized uh place where the software sits so that people can work with it  and upgrade it? No. Well  I - I sent mails to start the - the process and I guess we should have to - Well  we know most what we have to - to put in - in this. And. Yeah. So  I guess. Yeah  we m- O_K. Well  uh. Let's - let's come back to this uh later. Um. O_K. Um. Chuck  did you get a chance to do anymore stuff with the uh No. I didn't. Um  are you talking about - H_T_K  or - ? Uh  no. This week I haven't. I've been - my whole time's been taken up with uh Meeting Recorder stuff. Uh  disk crash and uh O_K. u- O_K. covering things. This may be a very short meeting. Uh. Um. Anything from your side? Uh  continuing readings we come Uh. We're doing some background reading on phonetics. Uh-huh. O_K. Dave? Yeah. Well um. One thing in - in the paper Avendano and his collaborators wrote is that - is that um they tried doing channel normalization on the reverberant in speech by um subtracting the mean of the log spectral magnitude over a two second window. But they didn't do anything with the phase  and they said perhaps that limited their approach that it did not try to normalize the phase in any way. So I'm - I'm going to start thinking about um ways that the ph- that the phase could be used. Um. Si- if - if the um channel and the reverberation is multiplicative in the frequency domain with the speech spectrum then the phases should be additive. So um perhaps just subtracting the mean of the phase would - would help. Um but I don't know I th- I get the impression that they tried to do some things with the phase and they weren't successful. O_K. Oh. You know  there is one other thing. Um Stephane showed me a paper yesterday um where th- uh for the Italian system they had done a series of experiments playing around with the um - the number of iterations  that I talked about last week? And  um  so  there was a whole series of those that they had done. They didn't  I don't think  reported timing for those  but um Mm-hmm. it turns out that the one that they're actually using was not the best  uh in - in their series of experiments  which I uh - Maybe it's because they uh wanted to use the same number of iterations across all different languages and this was only done on Italian or something. Sure. Wh- who's they - they? Uh  I don't know who did it do you know  Stephane? Who did that? Um. I don't know but it's the company who prepared the Italian database  so it was - Is it Alcatel  or - ? I think so. I - Mmm. I don't know. So um you know there wasn't a huge difference in terms of the performance across all the different experiments that they did. Um. But it varied a little bit. And uh - So I guess the main thing that I take out of that is that I think that for our purposes here we could definitely you know decrease the number of iterations that we do and um  at least while we're  you know  working on uh all different of kinds of variations  and that would let us  you know  pump through a lot more experiments. So um I still have to - to send everybody a pointer about uh how to run the um H_T_K system on the Linux boxes and about changing these number of iterations so that - so that you can do that. Um. So the - the other thing that that I was thinking about maybe trying out next is um - Oh! The other th- the other experiment that they had in that paper was uh uh playing with the number of Gaussians per state. And so. Uh. Mm-hmm. I think it's - was playing with the number of states per word. They had sixteen  seventeen  eighteen. Yeah  because it was around - between sixteen and twenty or - O_K. I should look at that more carefully cuz I wonder Yeah. what they did about - Oh  O_K. I was thinking it was Gaussians but it's states. O_K. So  and - Yeah  apparently  um they had better results when they increased the number of states. From - from eighteen to twenty  or - Mm-hmm. Yeah. So. The thing I was thinking about was uh  you know  the number of insertions really goes up when you start adding all the noise in  and maybe the thing to do next would be to try to um uh make the silence model more powerful  you know  increasing the number of Gaussians to the number of states  different - different things like that  so. That's probably the next little thing I'll play with when I get a chance Um. Let's see. Um. Why don't - why don't we uh - if there aren't any other major things  why don't we do the digits  and then - then uh turn the mikes off. So I'll start. Uh. Uh I got transcript uh L_ six four Four four six one  three five three six  six two three seven. Five  five two nine  one eight  four three eight  two. Eight  one one seven  five zero  four six two  eight. One six eight  three five zero  eight nine five. Six  six eight zero  six nine  three zero six  nine. Eight five eight  four two  three one eight seven. Nine three two six  three  three one three. Zero six four zero  seven  four seven three. Transcript L_ dash sixty five. Three three six  nine zero  one four five one. Six nine two eight  zero four O_ six  O_ three seven two. Five zero  one four  three eight  two three  nine six. Six O_ six  eight nine  two nine five nine. Seven seven eight seven  five nine eight nine  six one two zero. Eight seven one  five one  nine six six eight. Three five zero  one three zero  eight four eight two. Four eight two five  nine six two five  one two nine one. Transcript L_ sixty six. Eight seven  three two  zero one  three five  five three. Two eight six  O_ two  O_ six six eight. Seven  three two three  five three  three seven zero  two. Two four six  three nine  five seven five zero. Seven  two three O_  four four  four six eight  one. Eight  five six four  eight one  one seven eight  five. D'you put two? Four four two  five two five  seven seven one. Two seven nine  five nine  eight five seven four. My name is Maria. Oh  yeah. Transcript L_ dash sixty seven This. Seven one five  six six  seven five O_ five. Maria Carmen? Yeah. Hmm. One six six O_  seven two nine nine - Um  I'll read that again. One six six O_  seven two nine nine  six six five three. Three O_  four four  five one  two seven  one two. Eight seven  three one  eight nine  one three  five five. Five six six  zero four three  four eight zero. Eight six  seven eight  five one  zero six  six nine. One two two five  seven one eight six  nine nine five three. Two four eight  four eight eight  four seven zero. Transcript L_ dash sixty eight. five zero two  one five  six two one four eight one nine  two five  one three two eight three  four three two  one O_  four one five  five two eight five  zero nine four  five nine zero one eight four two  two one eight  two six nine seven three four six  one  zero zero zero zero seven seven zero  three  two four six six four two four  one  three nine six Transcript L_ dot sixty nine. Five nine seven  six eight six  three five nine four. Six six five  six nine eight  five three five. Six seven one three  nine  seven one eight. I'm sorry. Seven nine eight. Six O_ one six  eight  nine one three. Eight seven nine  five five four  eight five nine. Nine five nine nine  four  one eight five. Four zero four six  three three one two  zero six nine one. Three six zero five  two eight  five two four  three. O_K. ,ICSI's Meeting Recorder Group have returned from a meeting with some important decisions to make. They have developed a piece of software which allows them to implement their two main approaches to dealing with noise. The base rate is currently set at the second best rate as of the last project evaluation  and it does not yet include everything the group have been working on. With this in mind  they have decided to set most things  and concentrate on studying only a few key aspects  the neural network  the voice activity detector  and the noise estimation. By the time a senior member of their research partners OGI returns  they want to have a firm plan of what they will be doing. System latency is still an issue  but limits have still not been set by the project heads. The group have encountered problems with frame-dropping  and will need to bear that in mind since their neural network would come after that stage. While deciding which of two approaches to finally adopt  the group put together one piece of software for all to use that implements both spectral subtraction and wiener filtering. Speaker me026 has done his quals  and is looking at some of the feedback he received. 
"O_K. O_K  so We - we had a meeting with  uh - with Hynek  um  in - in which  uh  uh  Sunil and Stephane  uh summarized where they were and - and  uh  talked about where we were gonna go. So that - that happened sort of mid-week. D- did - did you guys get your code Uh. Oh  yeah. pushed together? Yeah. It's - it's - it's - it was updated yesterday  right? Cool. Yeah. Yeah. Oh  right  I saw - I saw the note. You probably received the mail. Yeah. Mm-hmm. What was the update? What was the update? Yeah. So there is th- then - the - all the new features that go in . The  um  noise suppression  the re-synthesis of speech after suppression. Is the  um - These are the - Yeah. the C_V_S mechanism working well? Are - are people  uh  up at O_G_I grabbing code uh  via that? Uh  I don't think - I don't think - Or - ? I don't know if they use it  but. Uh-huh. Yeah  I- I don't think anybody up there is like working on it right now. Mmm. I think it more likely that what it means is that when Sunil is up there Yeah. he will grab it. Yeah. Yeah. So right now nobody's working on Aurora there. I see. They're - Yeah. They're working on a different task. I see. Yeah. O_K. But what'll happen is - is he'll go back up there and  uh  Pratibha will come back from - from  uh  the east coast. Mm-hmm. Uh. And  uh - and - and I guess actually  uh  after Eurospeech for a little bit  uh  he'll go up there too. So  actually everybody who's working on it will be up there for at least a little while. So they'll remotely access it from there . Yeah. So has - Has anybody tried remotely accessing the C_V_S using  uh  uh  S_S_H? Um  I don't know if Hari did that or - You d- @@ I can actually do it today. I mean  I can just log into - Have you tried it yet? No  I didn't. O_K. So I- I'll try it today. Good idea. Yeah. Actually I - I tried wh- while - Yeah. when I installed the repository  I tried from Belgium. I Yeah? logged in there and I tried It worked good? to import - Yeah  it works. Oh  good! Great! Oh. But it's - So  right now it's the mechanism with S_S_H. I don't s- I didn't set up - You can also set up a C_V_S server on a new port. It's like Yeah. Right. well uh  a main server  or d- You can do a C_V_S server. Then that's using the C_V_S password mechanism and all that  right? But. Yeah  right. But I didn't do that because I was not sure about security problems. I - I would have to - So w- when you came in from Belgian - Belgium  using S_S_H  uh  was it asking you for your own password into ICSI? So if yo- you can only do that if you have an account at ICSI? Right. Yeah. O_K. Yeah. Cuz there is an - a way to set up anonymous C_V_S right? So that - Yeah  you ha- in this way you ca- you have to set up a C_V_S server but then  yeah  you can access it. you - you can set up priorities. You can access them and mostly if you - if y- the set- the server is set up like this. Oh  O_K. So the anonymous mechanism - O_K. Because a lot of the open source stuff works with anonymous C_V_S and I'm just wondering - Mm-hmm. Uh  I mean  for our transcripts we may want to do that. Yeah. Uh. Yeah  for this stuff I don't think we're quite up to that. I mean  we're still so much in development. We want to have just the insiders. Mm-hmm. Yeah  yeah  yeah. Oh  I wasn't suggesting for this. I'm thinking of the Meeting Recorder stuff but. Yeah. Yeah. O_K. Cool. Yeah. So  uh - What's new? Well  I mean  I think maybe the thing to me might be - I me- I'm sure you've just been working on - on  uh  details of that since the meeting  right? And so - Mmm  since the meeting  That was - that was Tuesday. well  I - I've been - I've been train- training a new V_A_D and a new feature net. O_K. So they should be ready. Um. But I guess maybe the thing - since you weren't - yo- you guys weren't at that - that meeting  might be just - just to  um  sort of recap  uh  the - the conclusions of the meeting. Oh  great. Mm-hmm. You're talking about the meeting with Hynek? So. Yeah. Cuz that was sort of  uh - we - we'd sort of been working up to that  that - that  uh  he would come here this week and - Uh-huh. and we would sort of - Since he's going out of town like now  and I'm going out town in a couple weeks  uh  and time is marching  sort of  given all the mu- many wonderful things we could be working on  what - what will we actually focus on? Mm-hmm. And  uh - and what do we freeze? And  you know  what do we - ? So  um. I mean  this software that these guys created was certainly a - a key part. So then there's something central and there aren't at least a bunch of different versions going off in - in ways that differ trivially. Uh  um  and  um  Yeah. That's - that's nice. and then within that  I guess the idea was to freeze a certain set of options for now  to run it  uh  a particular way  and decide on what things are gonna be experimented with  as opposed to just experimenting with everything. So keep a certain set of things constant. So  um. Uh  maybe describe roughly what - what we are keeping constant for now  or - ? Yeah. Well. So we've been working like six weeks on - on the noise compensation and we end up with something that seems reasonable. Um. Are you gonna use - which of the two techniques? So finally it's - it's  um  Wiener filtering on F_F_T bins. And it uses  uh  two steps  smoothing of the transfer function  the first step  that's along time  which use recursion. And after this step there is a further smoothing along frequency  which use a sliding window of twenty F_F_T bins. Mmm. And  uh - So this is on the - uh  before any mel scaling has been done? This is - Yeah  yeah. This - this smoothing is done on the estimate  It was - Yeah. um  of what you're going to subtract? Or on the thing that has already had something subtracted? Uh  it's on the transfer function. So - Oh  it's on the transfer function for the Wiener filter. Yeah. Yeah  O_K. Yeah  so basically we tried different configuration within this idea. We tried u- u- applying this on mel bands  having spectral subtraction instead of wiener filtering. Um. Well  finally we end up with this configuration that works  uh  quite well. So we are going to fix this for the moment and work on the other aspects of the whole system. So - Mm-hmm. Actually  let me int- eh  Dave isn't here to talk about it  but let me just interject. This module  in principle  i- I mean  you would know whether it's true in fact  is somewhat independent from the rest of it. I mean  because you - you re-synthesize speech  right? Mm-hmm. So  um. Uh  well you don't - I guess you don't re-synthesize speech  but you could - We - we do not fo- Uh  but you could. Well - well  we do  but we don't - don't re-synthesize. In - in the program we don't re-synthesize and then re-analyze once again. We just use the clean F_F_T bins. But you have a re-synthesized thing that you - that's an - an option here . This is an option that - then you can - Yeah. Yeah  I gu- I guess my point is that  um  i- in some of the work he's doing in reverberation  one of the things that we're finding is that  uh  it's - it's - for the - for an artificial situation  we can just deal with the reverberation and his techniques work really well. But for the real situation uh  problem is  is that you don't just have reverberation  you have reverberation in noise. And if you don't include that in the model  it doesn't work very well. So in fact it might be a very nice thing to do  to just take the noise removal part of it and put that in front of what he's looking at. Mm-hmm. And  uh  generate new files or whatever  and - and  uh  uh - and then do the reverberation part. So it's - Mmm. Anyway. So Dave hasn't tried that yet? No  no. He's - I mean  e- a- I guess he's busy with - Yeah  prelims  right. Yeah. Pre-prelim hell. Yeah. So. Yeah. Uh  but - but  you know  that'll - uh  it's clear that we  uh - we are not - with the real case that we're looking at  we can't just look at reverberation in isolation because the interaction between that and noise is - is considerable. And that's I mean  in the past we've looked at  uh  and this is hard enough  the interaction between channel effects and - and  uh - and additive noise  uh  so convolutional effects and - and additive effects. And that's hard enough. I mean  I don't think we really - I mean  we're trying to deal with that. In a sense that's what we're trying to deal with in this Aurora task. And we have  uh  the  uh  uh  L_D_A stuff that in principle is doing something about convolutional effects. And we have the noise suppression that's doing something about noise. Uh  even that's hard enough. And - and the on-line normalization as well  in that s- category. i- i- There's all these interactions between these two and that's part of why these guys had to work so hard on - on juggling everything around. But now when you throw in the reverberation  it's even worse  because not only do you have these effects  but you also have some long time effects. And  um  so Dave has something which  uh  is doing some nice things under some conditions with - with long time effects but when it's - when there's noise there too  it's - it's - it's pretty hard. So we have to start - Since any - almost any real situation is gonna have - uh  where you have the microphone distant  is going to have both things  we - we actually have to think about both at the same time. Hmm. So  um - So there's this noise suppression thing  which is sort of worked out and then  uh  maybe you should just continue telling what - what else is in the - Yeah  well  the  um  the form we have. the other parts of the system are the - the blocks that were already present before and that we did not modify a lot. So that's - again  that - that's the Wiener filtering  followed by  uh - uh  that's done at the F_F_T level. Then - Yeah  th- then the mel filter bank  Mm-hmm. then the log operation  Mm-hmm. Mmm. The - the - the filtering is done in the frequency domain? Yeah. Yeah  O_K. And then the mel and then the log  and then the Then the L_D_A filter  L_D_A filter. mmm  And then uh then the downsampling  downsample  D_C_T  D_C_T  then  um  on-line normalization  on-line norm  followed by upsampling. Then finally  we compute delta and we put the neural network also. Right  and then in parallel with - an - a neural net. And then following neural net  some - probably some orthogonalization. Uh - Yeah. Um. And finally frame dropping  which um  would be a neural network also  used for estimated silence probabilities. And the input of this neural network would be somewhere between log mel bands or Mm-hmm. one of the earlier stages of the processing. So that's sort of - most of this stuff is - yeah  is operating parallel with this other stuff. Mm-hmm. Yeah. So the things that we  um  uh  I guess we sort of - uh  There's - there's some  uh  neat ideas for V_A_Ds - So  I mean  in - I think there's sort of like - There's a bunch of tuning things to improve stuff. There's questions about various places where there's an exponent  if it's the right exponent  or ways that we're estimating noise  that we can improve estimating noise. And there's gonna be a host of those. But structurally it seemed like the things - the main things that - that we brought up that  uh  are - are gonna need to get worked on seriously are  uh  uh  a - a significantly better V_A_D  uh  putting the neural net on  um  which  you know  we haven't been doing anything with  the  uh  neural net at the end there  and  uh  the  uh  opening up the second front. Uh. The other half of the channel? That what you mean? Yeah  yeah  I mean  cuz we - we have - we have  uh  uh  half the - the  uh  data rate that they allow. And  uh  so the initial thing which came from  uh  the meeting that we had down south was  uh  that  um  we'll initially just put in a mel spectrum as the second one. It's  you know  cheap  easy. Uh. There's a question about exactly how we do it. We probably will go to something better later  Mm-hmm. but the initial thing is that cepstra and spectra behave differently  so. Um  I think Tony Robinson used to do - I was saying this before. I think he used to do mel  uh  spectra and mel cepstra. He used them as alternate features. Hmm. Put them together. Uh. So if you took the system the way it is now  the way it's fro- you're gonna freeze it  Mm-hmm. and it ran it on the last evaluation  where it would it be? It  uh  In terms of ranking? Second. Ri- right now it's second. Um. Mm-hmm. Although you - you know  you haven't tested it actually on the German and Danish  have you? No  we didn't. No  um. Yeah. So on the ones that you did test it on it would have been second? Yeah. Would it - I mean - But - When you're saying second  you're comparing to the numbers that the  uh - that the best system before got on  uh - also without German and Danish? Yeah  yeah. Yeah  O_K. And th- the ranking actually didn't change after the German and Danish. So  yeah. Well ranking didn't before  but I'm just asking Yeah. where this is to Yeah. where theirs was without the German and Danish  right? Yeah. Mmm. Yeah  yeah. So. Where - where - where were we actually on the last test? Oh  we were also esp- essentially second  although there were - there were - I mean  we had a couple systems and they had a couple systems. And so  I guess by that we were third  but I mean  there were two systems that were pretty close  Uh-huh. I see. that came from the same place. O_K. Uh  so institutionally we were - we were second  with  uh  the third - third system. We're - so this second that you're saying now is system-wide second? See - Uh  no I think it's also institutional  isn't it? Right? I mean  I think both of their systems probably - Still institutionally second? Uh  we are between their two systems. So Oh  are we? I - Yeah. It is a triumph . Is it? Their - their first system is fifty-four point something. And  uh  we are fifty-three point something. And their second system is also fifty-three point something. But everything is within the range of one - Yeah  one percent. one percent. Oh  wow! Yeah  so - so basically they're all - they're all pretty close. And - That's very close. So. Yeah. Yeah. and  um  you know  in some sense we're all doing fairly similar things. Uh  I mean  one could argue about the L_D_A and so forth but I - I think  you know  in a lot of ways we're doing very similar things. But what - what - So how did they fill up this - all these - these bits? I mean  if we're u- u- Um  why are we using half? Yeah. Well  so you could - you c- Or how are they using more than half  I guess maybe is what I - Yeah  so I - I think - uh  you guys are closer to it than me  so correct me if I'm wrong  but I - I think that what's going on is that in - in both cases  some kind of normalization is done to deal with convola- convolutional effects. Uh  they have some cepstral modification  right? Mm-hmm. In our case we have a couple things. We have the on-line normalization and then we have the L_D_A RASTA. And they seem to comple- complement each other enough and be different enough that they both seem to help - help us. But in any event  they're both doing the same sort of thing. But there's one difference. The L_D_A RASTA  uh  throws away high modulation frequencies. And they're not doing that. So th- So - So that if you throw away high modulation frequencies  then you can downsample. Get down. I see. I see. So - So what if you didn't - So do you explicitly downsample then? Do we explicitly downsample? Yeah. Yeah. And what if we didn't do that? Would we get worse performance? I think it doesn't affect it  does it? Um Yeah  not better  not worse. I see. O_K. Yeah. So I think the thing is  since we're not evidently throwing away useful information  let's try to put in some useful information. Yeah. Yeah. And  uh  so I - you know  we - we've found in a lot of ways for quite a while that having a second stream uh  helps a lot. So that's - that's put in  and you know  it may even end up with mel spectrum even though I'm saying I think we could do much better  just because it's simple. Mm-hmm. Um. And you know  in the long run having something everybody will look at and say  ""oh  yeah  I understand""  is - is very helpful. So you would - you're - You're thinking to put the  uh  mel spectrum in before any of the noise removal stuff? or after? Well  that's a question. I mean  we were talking about that. It looks like it'd be straightforward to - to  uh  remove the noise  um  and  uh  Cuz that happens before the mel conversion  right? Yeah. So  I mean  to do it after the mel conversion - uh  after the noise removal  after the mel conversion. There's even a question in my mind anyhow of whether th- you should take the log or not. Uh. I sort of think you should  but I don't know. What about norm- normalizing also? Right. Uh. Well  but normalizing spectra instead of cepstra? Yeah. Yeah  probably. Some kind would be good. You know? I would think. Well  it - it - it - it - so it actually makes it dependent on the overall energy of the - uh  the frame. If you do or don't normalize? If yo- if you don't normalize and - if - if you don't normalize. Right. Yes  so I mean  one would think that you would want to normalize. But I - I - w- w- My thought is  uh  particularly if you take the log  try it. And then if - if normalization helps  then y- you have something to compare against  and say  ""O_K  this much effect"" - I mean  you don't want to change six things and then see what happens. You want to change them one at a time. So adding this other stream in  Mm-hmm. that's simple in some way. And then saying  oh - uh - particularly because we've found in the past there's all these - these - these different results you get with slight modifications of how you do normalization. Normalization's a very tricky  sensitive thing and you learn a lot. So  I would think you would wanna have some baseline that says  ""O_K  we don't normalize  this is what we get""  when we do this normalization  when we do that normalization. But - but the other question is - So I think ultimately we'll wind up doing some normalization. I agree. So this second stream  will it add latency to the system or - ? No  it's in parallel. Para- S- We're not talking about computation time here. We're ta- I think we're pretty far out. So it's just Yeah. in terms of what data it's depending on. It's depending on the same data as the other. So it's in parallel. Same data. O_K. Uh-huh. So with this  uh  new stream would you train up a V_A_D on both - both features  somehow? No  I guess the V_A_D has its own set of features. O_K. I mean  which could be this - one of these streams  or it can be something derived from these streams. and that's - Yeah. O_K. And there is also the idea of using TRAPS  maybe  for the V_A_D  which  um - Yeah  that's also - Well  Pratibha apparently showed  when  she was at I_B_M  that it's a good idea. So. Would - would that fit on the handset  or - ? Oh! I have no idea. O_K. Well  it has t- I mean the - th- It would have to fit but - Yeah. Yeah  if it has to fit the delays and all this stuff. Well  there's the delays and the storage  yeah. O_K. Yeah. But I don't think the storage is so big for that. Right. I think th- the biggest we've run into for storage is the neural net. Yeah. Right? Yeah. Um. And so I guess the issue there is  are we - are we using neural-net-based TRAPS  and - and how big are they? Oh  right. So that'll - that'll be  you know  an issue. Yeah. Cuz sh- Maybe they can be little ones. Right. Cuz she also does the  uh - the correlation-based  Mini-TRAPS. uh  TRAPS  with- without the neural net  just Right. looking at the And maybe for V_A_D they would be O_K. Yeah. correlation between - Yeah. Yeah. Yeah. That's true. Or a simple neural net  right? I mean  the thing is  if you're doing correlation  you're just doing a simple - uh  uh - uh  dot product  you know  with some weights which you happened to learn from this - learn from the data. And so  Mm-hmm. uh  putting a nonlinearity on it is  you know  not that big a deal. Mm-hmm. It certainly doesn't take much space. Right. So  uh  the question is  how complex a function do you need? Do you need to have an added layer or something? In which case  uh  potentially  you know  it could be big. So. Mm-hmm. So  uh  uh - So what's next? Maybe s- s- remind us. So the meeting with Hynek that you guys just had was to decide exactly what you were gonna freeze in this system? Is that - ? Or was there - ? Were you talking about what t- new stuff  or - ? What to freeze and then what to do after we froze. Mmm. Yeah. And like I was saying  I think the - you know  the basic directions are  uh  uh - I mean  there's lots of little things  such as improve the noise estimator but the bigger things are adding on the neural net and  uh  the second stream. And then  uh  improving the V_A_D. Uh. So. So  I'll  um - I'll actually - after the meeting I'll add the second stream to the VAD and maybe I'll start with the feature net in that case. It's like  you're looking at the V_A_D  right? Uh  yeah. I'll - I- I've a new feature net ready also. For the V_A_D? No  uh. Well p- two network  one V_A_D and one feature net. Mm-hmm. Oh  you already have it? O_K  so just figure how to take the features from the final - Yeah. O_K. Um. But  yeah  I think there are plenty of issues to work on for the feature net @@ . What about the  um - Feature net. uh  the new part of the evaluation  the  uh  Wall Street Journal part? Right. Right. Um. Have you ever - ? Very good question. Have you ever worked with the Mississippi State h- uh  software? Sorry. No. Not yet. Oh. Well you - you may be called upon to help  uh  uh  on account of  uh  all the work in this stuff here has been  uh  with small vocabulary. O_K. Mm-hmm. So what - how is the  uh  interaction supposed to happen? Uh  I remember the last time we talked about this  it was sort of up in the air whether they were going to be taking  uh  people's features and then running them or they were gonna give the system out or - Yeah. Yeah. Oh  so they're gonna just deliver a system basically. Yeah  yeah. Do we already have it? Yeah  th- I - I guess it's almost ready. Uh-huh. So - That's what - So they have released their  uh  document  describing the system. I see. Maybe you could  uh  point it at Chuck  because  I mean - Sure. So we'll have to grab this over C_V_S or something? It- no  it's just downloadable from their - from their web site. Is that how they do it? O_K. O_K. Cuz one of the things that might be helpful  if you've - if you've got time in all of this is  is if - if these guys are really focusing on improving  uh  all the digit stuff  uh  maybe - Mm-hmm. and you got the front-end from them  maybe you could do the runs for the - Sure. and - and  you know  iron out hassles that - that you have to  uh  tweak Joe about or whatever  because you're more experienced with running the large vocabulary stuff. O_K. S- So I'll point you to the web site and the mails corresponding. So I- And it - but it's not ready yet  the system? Uh  I - I think they are still  uh  tuning something on that. So they're like  d- they're varying different parameters like the insertion penalty and other stuff  and then seeing what's the performance. Are those going to be parameters that are frozen  nobody can change? Or - ? Uh  w- I guess there is  uh  time during which people are gonna make suggestions. Oh  but everybody's gonna have to use the same values. After that. Oh! Interesting. O_K. Yeah  I guess. So these sugges- these - this  uh  period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or - Yeah  so I th- th- certainly the thing that I would want to know about is whether we get really hurt  uh  on in- insertion penalty  language model  scaling  sorts of things. Using our features. Yeah. Yeah  yeah. Uh  in which case  um  H- Hari or Hynek will need to  you know  push the case Mm-hmm. more about - about this. Um. And we may be able to revisit this idea about  you know  somehow modifying our features to Yes. In this case  that's right. work with - Yeah. That's right. Um  some of that may be  uh  a last minute rush thing because if the - if our features are changing - Yeah. Uh. Uh. But  um. Yeah  the other thing is that even though it's months away  uh  it's starting to seem to me now like November fifteenth is right around the corner. And  um  if they haven't decided things like this  like what the parameters are gonna be for this  uh  when ""deciding"" is not just somebody deciding. I mean  in fact there should be some understanding behind the  uh  deciding  which means some experiments and - and so forth. It - it - it seems pretty tight to me. So wha- what's the significance of November fifteenth? That's when the evaluation is. O_K. Yeah. So  yeah  so after - But  you know  they may even decide in the end to push it off. It wouldn't  you know  entirely surprise me. But  uh  due to other reasons  like some people are going away  I'm - I'm hoping it's not pushed off for a l- a long while. That would be  uh - put us in an awkward position. But - Anyway. O_K. Great. Yeah  I think that'll be helpful. There's - there's not anybody O_G_I currently who's - who's  uh  working with this and - and Is - is this part of the evaluation just a small part  or ho- how important is this to the overall - ? I - I think it's - it's  um - it depends how badly you do. I mean  I think that it - it is - Uh. b- This is one of those things that will be debated afterwards? Yeah. Well  I mean  it's - it's - Conceptually  it - my impression  again  you guys correct me if I'm wrong  but my impression is that  um  they want it as a double check. That you haven't come across - you haven't invented features which are actually gonna do badly for a - a significantly different task  particularly one with larger vocabulary. Mmm. And  um  but it's not the main emphasis. I mean  the truth is  most of the applications they're looking at are pretty small vocabulary. Mmm. So it's - it's a double check. So they'll probably assign it some sort of low weight. Seems to me that if it's a double check  they should give you a one or a zero. Y- you passed the threshold or you didn't pass the threshold  and they shouldn't even Yeah. care about what the score is. But  I mean  we'll - we'll - we'll see what they come up with. Uh  but Yeah. in - in the current thing  for instance  where you have this well-matched  moderately-matched  and - and mis- highly-mismatched  uh  the emphasis is somewhat on the - on the well-matched  but it's only a - a marginal  right? It's like forty  thirty-five  twenty-five  or something like that. So you still - Yeah. if you were way  way off on the highly-mismatched  it would have a big effect. Mm-hmm. And  um  it wouldn't surprise me if they did something like that with this. So again  if you're - if you get - Oh. If it doesn't help you much  uh  for noisy versions of this - of large vocabulary data  then  uh  you know  it may not hurt you that much. But if it - if you don't - if it doesn't help you much at all  um  or to put it another way  if it helps some people a lot more than it helps other people  uh  if their strategies do  then - Mm-hmm. So is this  uh - ? Uh  Guenter was putting a bunch of Wall Street Journal data on our disks. That's it. So that's the data that we'll be running on? Yeah. I see. O_K. Yeah. So we have the data  just not the recognizer. O_K. So this test may take quite a while to run  then. May- judging by the amount of data that he was putting Uh  on. well there's training and test  right? I - I guess  I'm not sure. I just - No  I mean  if it's like the other things  there's - there's data for training the H_M_Ms and - and data for testing it. So I wouldn't - So it - it's - O_K. So there's - So  training the recognizer  but  um Um. But I think it's trained on clean and - Is it trained on clean and - and test on - ? The Wall Street? Yeah. Apparently  no. It's training on Mm-hmm. a range between ten and twenty D_B  I think  and testing between five and fifteen. Yeah. That's O_K. what I got on - It's  uh - It's like a medium - medium-mismatch condition  sort of. I see. Yeah  and - So the noise is - There is a range of different noises also - um - which are selected randomly and added randomly  uh  to the files. And there are noises that are different from the noises used on T_I-digits. Yeah. Yeah. I mean  I wouldn't imagine that the amount of testing data was that huge. They probably put training - uh  almost certain they put training data there too. Maybe not. So. That's that. Anybody have anything else? Uh  one - one last question on that. When did they estimate that they would have that system available for download? Um  I guess - I guess one - some preliminary version is already there. Oh  so there's w- something you can download to just Yeah  it's already there. Yeah. learn? O_K  good. But they're actually parallel-y doing some modifications also  I think. O_K. So I guess the f- final system will be frozen by middle of  like  one more week maybe. Oh  well that's pretty soon. Yeah  that's just one more. Is this their  um  S_V_M recognizer? No  it's just a straightforward H_M_M. Oh  O_K. You know  their - their - They have a lot of options in their recognizer and - and the S_V_M is one of the things they've done with it  but it's not their more standard thing. Uh-huh. For the most part it's - it's Gaussian mixtures. Oh  O_K. Oh  O_K. Yeah. It's just a H_M_M  Gaussian mixture model. Gaussian mixture H_M_M. O_K. Yeah. Yeah  the S_V_M thing was an H_M_M also. It was just a - it - it - it was like a hybrid  like - what? Yeah. Yeah  this is a g- yeah  this i- yeah. Mm-hmm. So  just so that I understand  they're providing scripts and everything so that basically  uh  you - you push a button and it does training  and then it does test  and everything? Is that the idea? I - I - I think - yeah  I - I guess something like that. Mm-hmm. It's like - as painless as possible  is what - I see. Hmm. Do they provide all the scripts  everything  and then - Somehow yo- there's hooks to put your Just  ju- Yeah  I th- I think. features in and - Hmm. Hmm. Yeah  um. In fact  I mean  if you look into it a little bit  it might be reasonable - You know Joe  right? Mm-hmm. Yeah. Just to sort of ask him about the issue of  um  different features having different kinds of  uh  scaling characteristics and so on. So that  you know  w- w- possibly having entirely different optimal values for - for the usual twiddle factors and what's - what's the plan about that? O_K. So sh- shall we  like  add Chuck also to the mailing lists? It may be better  I mean  in that case if he's going to - Because there's a mailing list for this. Yeah. Is that O_K? Yeah  that'd be great. Yeah  I guess maybe Hari or Hynek  one of them  has to send a mail to Joe. Or maybe if you - I - I could send him an email. Well  yeah  to add or maybe wh- I - I know him really well. I - I was just talking with him on email the other day actually. Yeah  so that's just fine. So - So - Uh  yeah  and just  um  se- maybe see. Do you have Hari's  uh - ? About other things  but. I have Hari's - Yeah  so maybe just C_C Hari and say that you've just been asked to handle the large vocabulary part here  O_K. and  uh  you know  end. Would it be better if I asked Hari to ask Joe? Uh. Why don't you just ask Joe but C_C Hari  and then in the note say  ""Hari  hopefully this is O_K with you"". O_K. O_K. And then if Joe feels like he needs a confirmation  Hari can answer it. Yeah. That way you can get started asking Joe quickly while he's - while he's maybe still  you know  putting in nails and screws and doing that stuff And there is an  uh  archive of all the mails that has been Yeah. gon- that has gone  uh  between these people - among these people. O_K. So just you can see all this mails in the I_S_I_P web site - Mississippi web site. O_K. Is that a password controlled - ? O_K. Yeah  it's password protected. So  like - like  it's  like - Have you thought about how long would be uh  most useful for you to go up to O_G_I? I don't know  uh. We can - For September  we can set up a work schedule and we can maybe work independently. And then at some point it maybe be better to work together again. Oh  so you're - you're imagining more that you would come back here first for a while and then - and then go up there? I mean  it's to you. I ju- you guys are I - Maybe  yeah. Well  y- anyway  you don't have to decide this second but thi- think about it - about what - what you would think would be the - But  uh Huh. Mm-hmm. the best way to work it. I'll support it either way  so. Mm-hmm Right. O_K. Uh. Got anything to tell us? Um. Well  I've been reading some literature about clustering of data. Just  um  I guess  let me put it in context. O_K  so we're talking about discovering intermediate categories to  um - to classify. And  uh  I was looking at some of the work that  uh  Sangita was doing on these TRAPS things. So she has  um - she has temporal patterns for  um  a certain set of phonemes  from - from TIMIT  right? the most common phonemes. And each one of them has - has a - a nice pattern over time  a one - one second window. And it has - has these patterns. Um  so she has  um a TRAP for each one of the phonemes  um  times fifteen  for each of the fifteen critical bands. And  um  she does this agglomerative hierarchical clustering which - which basically  um  is a clustering algorithm that  uh  starts with many  many  many different points - many different clusters - uh  corresponding to the number of data  uh  patterns that you have in the data. And then you have this distance mej- metric which  uh  measures how - how closely related they are. And you start  um by merging the patterns that are most closely related. And you create a tree. And y- yeah  yeah  a dendrogram tree. Mm-hmm. Um. And then you can pick  uh  values anywhere along that tree to fix your set of clusters. Right  usually it's when  um - when the sol- similarity measures  um  don't go down as much. Mm-hmm. And so  uh - so you stop at that point. And what she found was  sh- um  was there were five broad  um - broad categories  Mm-hmm. uh  corresponding to  uh  things like  uh  fricatives and  uh  vocalic  um  and  uh  stops. And  uh  one for silence and - and another one for schwa - schwa sounds. Um  and  um  I was thinking about ways to - to generalize this because w- you're - it's sort of like a - it's not a completely automatic way of clustering  because yo- beforehand you have these - these TRAPS and you're saying that - that these frames correspond to this particular phoneme. Um  and that's - that's constraining your - your clustering to - to the set of phonemes that you already have. Um  whereas maybe we want to just take - take a look at  um  arbitrary windows in time  Mm-hmm. um  of varying length  um  and cluster those. And I'm thinking if we - Mm-hmm. if we do that  then we would probably  um  at some point in the clustering algorithm find that we've clustered things like  O_K  thi- this is a transition  um  this is a relatively stable - stable point. Um  and I'm hoping to find other things of - of similarity and maybe use these things as the intermediate  um - intermediate categories that  uh  um  I'll later classify. Are you looking at these in narrow bands? Mm-hmm. Um  right. F- um  I'm - Cuz that's what you're gonna be using  right? Yeah  yeah. I - I haven't exactly figured out  um  the exact details for that but  uh  the - the representation of the data that I was thinking of  was using  um  critical band  um  energies  um  over different lengths of time. So - Yeah. Yeah  I mean  it seems somehow that needs th- uh  there's a couple things that I wonder about with this. I mean  so one is - O_K. is  again  looking at the same representation  I mean  if you're going for this sort of thing where you have uh  little detectors that are looking at narrow bands  then what you're going to be looking for should be some category that you can find with the narrow bands. Mm-hmm. That - that seems to be kind of fundamental to it. Right. Um  and then the other thing  uh  is - that I wonder about with it  and - and don't take this in the wrong way  like I - I know what I'm doing or anything  but  I mean. Um  just wondering really. Mm-hmm. Um  the sort of standard answer about this sort of thing is that if you're trying to find the right system in some sense  whether you're trying by categories or - or parameters um  and your goal is discrimination  then having choices based on discrimination as opposed to  um  unsupervised nearness of things  Hmm. um  is actually better. Um  and I don't know if that - I mean  since you're dealing with issues of robustness  you know  maybe - maybe this isn't right  but it'd be something I'd be concerned about. Because  for instance  you can imagine  uh  uh  i- i- if you remember from - from  uh - from your - your quals  John Ohala saying that  uh  ""buh"" and ""puh"" differed  uh  not really cuz of voicing but because of aspiration. Mm-hmm. I mean  in as far as wha- what's really there in the acoustics. So  um  if you looked - if you were doing some coarse clustering  you probably would put those two sounds together. And yet  I would gue- I would guess that many of your recognition errors were coming from  uh  um  pfft  screwing up on this distinction. Mm-hmm. So  in fact  it's a little hard because recognizers  to first order  sort of work. And the reasons we're doing the things we're doing is because they don't work as well as we'd like. And since they sort of work  uh  it means that they are already doing - if you go and take any recognizer that's already out there and you say  ""how well is it distinguishing between schwas and stops?"" Mm-hmm. Boy  I bet they're all doing nearly perfectly on this  right? So these - these big categories that differ in huge obvious ways  we already know how to do. Mm-hmm. So  what are we bringing to the party? I mean  in fact what we wanna do is have something that  particularly in the presence of noise  uh  is better at distinguishing between  uh  categories that are actually close to one another  and hence  would probably be clustered together. Mmm. So that's th- that's the hard thing. I mean  I understand that there's this other constraint that you're considering  is that you wanna have categories that  uh - that would be straightforward for  say  a human being to mark if you had manual annotation. And it's something that you really think you can pick up. But I think it's also essential that you wanna look at what are the confusions Mm-hmm. that you're making and how can you come up with  uh  categories that  uh  can clarify these confusions. Hmm. So  I mean  the standard sort of way of doing that is take a look at the algorithms you're looking at  but then throw in some discriminative aspect to it. Y- y- this is more like  you know  how does L_D_A differ from P_C_A? I mean  they're the same sort of thing. They're both orthogonalizing. But  Right. you know - and - and  um  this is a little harder because you're not just trying to find parameters. You're actually trying to find the - the - the - the categories themselves. Uh  so a little more like brain surgery  I think on yourself. Uh. So  uh Um  anyway. Yeah. That's my thought. O_K. You've been thinking about this problem for a long time actually. I mean  well - Yeah. W- actually  you stopped thinking about it for a long time  but you used to think about it a lot. And you've been thinking about it more now  these categories. Mm-hmm. Yeah. Yeah. I guess - I don't - I don't - um  it's not clear to me how to reconcile  you know  what you're saying  which I think is right  with the way I've been looking at it. That it's - it's - it's all not very clear to me. But it seems to me that the desire - the desirable feature to have is something that  um  is bottom-up. You know  however we do that. And Mm-hmm. and so I guess what I don't understand is how to do that and still be discriminative  because to be discriminative you have to have categories Right. and the only categories that we know of to use are sort of these human - human sig- significant - categories that are significant to humans  like phonemes  things like that. But that's sort of what you want to avoid. And so Well  here's a - here's a  uh  uh that feels - I don't know how to get out of this. Here's a generic and possibly useless thought  which is  um  what do you really - I mean  in a sense the only s- s- systems that make sense  uh  are ones that - that have something from top-down in th- in them. Right? Because if e- even the smallest organism that's trying to learn to do anything  if it doesn't have any kind of reward for doing - or penal- penalty for doing anything  then it's just going to behave randomly. Mm-hmm. So whether you're talking about something being learned through evolution or being learned through experience  it's gotta have something come down to it that gives its reward or  you know  at least some reinforcement learning  right? Right. So the question is  how far down? And We could stop at words  but we don't  right? We go all the way down to phonemes. Right  but I me- I - I think that maybe in some ways part of the difficulty is - is trying to deal with the - with these phonemes. Mm-hmm. You know  and - and - and i- it's almost like you want categories if - if our - if our  uh  um  metric of - of goodness  uh  i- if our - correction - if our metric of badness is word error rate then  um  maybe we should be looking at words. Mm-hmm. I mean  for - for - for very nice  uh  reasons we've looked for a while at syllables  and they have a lot of good properties  but i- i- i- if you go all the way to words  I mean  that's really - I mean  d- w- In many applications you wanna go further. You wanna go to concepts or something  or have - have - have concepts  actions  this sort of thing. But  words aren't bad  yeah. And - and Yeah. But words would be a nice - Yeah  so the common - right  the common wisdom is you can't do words because there's too many of them  right? So you have to have some smaller set that you can use  uh  and - and so everybody goes to phonemes. But the problem is that we - we build models of words in terms of phonemes and these models are - are really cartoon-ish  right? So when you look at conversational speech  for example  you don't see the phonemes that you - that you have in your word models. Yeah. But - but - but we're not trying for models of words here. See  so her- here's maybe where - If the issue is that we're trying to come up with  um  some sort of intermediate categories which will then be useful Mm-hmm. for later stuff  uh  Mm-hmm. then maybe it doesn't matter that we can't have enough - I mean  what you wanna do is - is build up these categories that are - that are best for word recognition. Right. Right. And - and somehow if that's built into the loop of what the categories - I mean  we do this every day Ah. in this very gross way of - of running o- a thousand experiments because we have fast computers and picking the thing that has the best word error rate. Right. Yeah. In some way - I mean  we derive that all the time. In some ways it's really not a bad - bad thing to do because it tells you in fact how your adjustments at the very low level affect the - Mm-hmm. the final goal. Mm-hmm. Um  so maybe there's a way to even put that in in a much more automatic way  where you take  you know  something about the error at the level of the word or some other - it could be syllable - but in some large unit  Right. Uh-huh. uh  and uh - yeah  you may not have word models  you have phone models  whatever  but you sort of don't worry about that  Mm-hmm. and just somehow feed it back through. You know  so that's  uh  wh- what I called a useless comments because I'm not really telling you how to do it. But I mean  it's a - it's - it's  you know - it No  but I think the important part in there is that  you know  if you want to be discriminative  you have to have uh  you know  categories. Right. And I think this - the important categories are the words  Yeah. and not the phones. Yeah. Maybe. And so - Right. If you can put the words in to the loop somehow for determining goodness of your sets of clusters - Uh - Now  that being said  I think that - that if you have something that is  um - i- Once you start dealing with spontaneous speech  all the things you're saying are - are really true. Mm-hmm. If you have read speech that's been manually annotated  like TIMIT  Yeah. then  you know  i- i- you- the phones are gonna be right  actually  for the most part. So - so  uh  it doesn't really hurt them to - Yeah  yeah. to do that  to put in discrimination at that level. Um  if you go to spontaneous speech then it's - it's trickier and - and - and  uh  the phones are - uh  you know  it's gonna be based on bad pronunciation models that you have of - and  um - Mmm. And it won't allow for the overlapping phenomenon that - So it's almost like there's this mechanism that we have that  you know  when - when we're hearing read speech and all the phonemes are there you know  we - we deal with that  but - but when we go to conversational  and then all of a sudden not all the phonemes are there  it doesn't really matter that much to us as humans because we have some kind of mechanism that allows for these word models  whatever those models are  to be munged  you know  and - and it doesn't really hurt  and I'm not sure how - how to build that in. Uh. Yeah  I mean  I guess the other thing i- is - is to think of a little bit - I mean  we- when y- when you start looking at these kind of results I think it usually is - is pretty intuitive  but start looking at um  what are the kinds of confusions that you do make  uh  you know  between words if you want or - or - or  uh  even phones in - in - in - in read speech  say  uh  when there is noise. You know  so is it more across place or more across manner? Or is it cor- you know  is it - ? I mean  I know one thing that happens is that you - you - you  uh  Mm-hmm. you lose the  um  uh  low energy phones. I mean  if there's added noise then low energy phones sometimes don't get heard. And if that - if that is - if it - uh  if that turns it into another word or - or different - you know  or another pair of words or something  then it's more likely to happen. But  um  Mm-hmm. I don't know  I w- I would - I would guess that you'd - W- I don't know. Anyway  that's - I think part of the difficulty is that a l- a lot of the robustness that we have is probably coming from a much higher level. You know  we understand the context of the situation when we're having a conversation. And so if there's noise in there  you know  our brain fills in and imagines what - what should be there. Mm-hmm. Yeah. We're - we're doing some sort of prediction of what - Well that - Yeah  exactly. Oh  sure  that's really big. Uh  but I mean  even if you do Yeah. um  uh  diagnostic rhyme test kind of things  you know  where there really isn't an- any information like that  uh  people are still better in noise than they - than they are in - in  uh - uh  than the machines are. Hmm. So  I mean  that's - i- Right. We can't - we can't get it at all without any language models. Language models are there and important but - but  uh - Uh. If we're not working on that then we should work on something else and improve it  but - especially if it looks like the potential is there. So - Should we do some digits? Yeah. Since we're here? Go ahead  Morgan. O_K  transcript L_ dash three three eight. Eight five six five five six four eight one five one three four two seven two seven one nine nine eight two five two four eight eight five eight zero three zero two seven five eight zero zero one zero five nine nine two nine four five eight five one nine six nine two four nine seven two four nine three three nine zero seven three four three three zero. Two zero four one seven five one seven. Transcript L_ dash three three nine. Eight eight nine two six four zero seven zero zero. One seven five nine eight four eight nine. Two eight four eight five one five five one. Six seven one zero nine five zero six five. Two eight eight eight nine five. Two one eight two. Seven nine three zero seven eight seven O_ seven nine. Three six two six one four nine eight one three. Eight nine nine seven four four six seven zero four zero five. Transcript L_ dash three three three six three seven zero three six nine zero six zero zero two eight three two seven. Seven seven six zero seven one seven four seven three eight one one four one zero six six. Nine five seven four three one nine nine zero four four zero six eight zero zero five eight. Zero eight one five four three seven two four five two seven four eight one three four eight. Transcript L_ dash three three six. Seven six zero one four nine five three eight one seven nine six four nine three nine nine eight nine zero zero zero two two three eight one one nine five four three six zero five nine zero four seven seven five six nine eight six seven three O_ three eight nine five three nine two eight six one four six four six four eight. Six three eight four zero six zero seven two zero one nine. Transcript L_ dash three three four. One three seven four zero nine one eight zero four four seven nine four six six five six four seven one two four eight zero four seven five one four. Eight two two one seven three five seven zero five nine one zero six three six three five nine four three nine six zero three nine two eight three eight. Zero six nine two zero nine one six nine zero two three eight four five eight eight three three zero. O_K. O_K. That's all folks. ",The Berkeley Meeting Recorder group focussed its discussion on overlapping speech segments. Speaker fe008 presented raw counts and percentages for one transcribed meeting  revealing a large number of overlaps throughout the 40-plus-minute transcript. Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm. The group also tentatively discussed the erection of visual barriers during meeting recordings  and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM. For future meetings  speaker me011 will generate a system for mapping speakers and their positions in the recording room. Speaker fe008 will analyze backchannels for a subset of meeting data and givee a report in the next meeting. For language and dialogue modelling  current methods of marking and segmenting overlap are abstracted from real time  as individual speaker turns are indicated sequentially. A large amount of data must be collected to address research questions concerning overlapping speech. For automatic speaker identification  thresholding and filtering methods are sensitive regarding the particular filter width and threshold selected. While such parameters can be finely tuned for one speaker to achieve good results  extending the same parameters to another speaker is problematic. The broad phone classifier of the speaker-change detector is peforming poorly. The prospect of erecting visual barriers during meetings would require partitioning off each of the participants. Also  barriers that do not affect the overall room acoustics would be required. Efforts are in progress to mark where regions of speaker overlap occur in meeting transcripts and note the number of speakers involved. Such information is currently being encoded within relatively loose time boundaries. A large number of overlapping speech regions were identified throughout one recorded meeting  wherein overlaps were found to occur in bursts  rather than being evenly distributed throughout the meeting. A cursory analysis was done on regions of overlap involving two speakers to determine whether speakers are more likely to be overlapped with or to cause overlap with other speakers. Attempts were also made to classify types of speaker overlap---e.g. backchannels  answering questions as they are being asked  and responding in unison---with future work focussed on subcategorizing types of backchannels. Speaker fe016 is interested in the contribution of multiple speakers in an interaction to the amount and types of overlap observed  and comparing this to findings from the Switchboard corpus. Future work includes generating predictive models of overlap  and the tentative erection of visual barriers during meeting recordings. Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm. 
"Test. O_K. Let's see  I should be As close to your mouth as you can get it. Two. La Is this channel one? Gee  O_K. Yes. O_K. Up high - high as you can get. Yeah  on your upper lip. Channel one one one. O_K  so for - for - This is - chan- For people wearing the wireless mikes  like - like this one  I find the easiest way to wear it is sorta this - this sorta like that. It's actually a lot more comfortable then if you try to put it over your temples  so - channel channel Channel five  channel five. Yeah. one one two three Mm-hmm. Test  test test. What do you do  you do it higher? Mm-hmm. Adam's just trying to generate good uh data for the recognizer there. Yeah  I think we're supposed to - that's right. Oh it was. And then also  for - for all of them  if your boom is adjustable  the boom should be towards the corner of your mouth  and about a- uh a thumb to a thumb and a half distance away from your mouth  so about like I'm wearing it now. Test test. By the way  there was a bug. Yeah  i- it wasn't using the proper basically it wasn't adapting anything. Oh. Oh that's interesting. So why didn't you get the same results and the unadapted? It's not always possible. so- so Jane  you could actually do even a little closer to your mouth  but - Hmm? I could - can this be adjuste- like this? Is that @@ ? O_K  thank you. Why didn't you get the same results and the unadapted? Oh  because when it estimates the transformer pro- produces like a single matrix or something. Yep. Adam  I'm not - uh  looks kinda low on channel five - no? Maybe not. Hello? It's O_K? Is this O_K? O- Oh oh I see. I see  I see. O_K. Channel five  s- speak again. Yeah  that's alright. I mean  we could - we could up the gain slightly if you wanted to. Hello. Basically there were no counts @@ Yeah. O_K. I see what you mean. Who's channel B_? but - Uh  channel B_ is probably Liz. Uh channel B_ - I am channel B_. No  channel B_. Yeah  yeah. Uh oh. Channel eight  eight. You wanna close this  or No I- yeah  yeah  you're channel B_. So can you talk a bit? I thought it might be too O_K. Thank you. Hello  hello. O_K  yeah  channel B_  one two three four five. Yeah  it's alright. So  the gain isn't real good. We're recording  right? Yeah. O_K  so we are recording. O_K. Ah. Oh. O_K. Um everyone should have at least two forms possibly three in front of you depending on who you are. Um we - we're doing a new speaker form and you only have to spea- fill out the speaker form once but everyone does need to do it. And so that's the name  sex  email  et cetera. Mm-hmm. We - we had a lot of discussion about the variety of English and so on so if you don't know what to put just leave it blank. Um I - I designed the form and I don't know what to put for my own region  so Mmm. California. I think - California. California. Um may I make one suggestion? Instead of age put date of - uh year of birth because age will change  but Sure. Oh. The year of birth changes  you know  stays the same  usually. Although on - A- actually  wait a minute  shouldn't it be the other way around? Birth year? Not for me. Yeah. course on the other - on the other hand you could - On the other side  yeah. you view it as the age at the time of the - Well the thing is  if ten years from now you look at this form knowing that - Yes  but what we care about is the age at - at the recording date rather than the - But there's no other date on the form. O- yeah. W- we don't care how they - old they really are. Well - well I don't know. Yes. Unless we wanna send them a card. Well I guess it depends on how long the corpus is gonna be collected for. Anyway. Yeah  that's true. I still don't see the problem. Either way yeah I think - I think age is alright and then O_K. If you have the date @@ . um there will be attached to this a point or two these forms Mm-hmm. uh so that you'll be able to extract the date off that so  anyway. And so then you also have a digits form which needs to be filled out every time  the speaker form only once  the digit form every time even if you don't read the digits you have to fill out the digits form so that we know that you were at the meeting. O_K? And then also if you haven't filled one out already you do have to fill out a consent form. And that should just be one person whose name I don't know. O_K? Do you want this Adam? Uh sure. Thank you. So uh O_K so should we do agenda items? Uh oh that's a good idea. I shouldn't run the meeting. Uh well I have - I wanna talk about new microphones and wireless stuff. Mmm. And I'm sure Liz and Andreas wanna talk about recognition results. Anything else? I guess - what time do we have to leave? Three thirty? Yeah. Why don't you go first then. Yeah  so. Yeah  good idea. O_K. Um Well  I - I sent out an email s- couple hours ago so um with Andreas' help um Andreas put together a sort of no frills recognizer which is uh gender-dependent but like no adaptation  no cross-word models  no trigrams - a bigram recognizer and that's trained on Switchboard which is telephone conversations. Um and thanks to Don's help wh- who - Don took the first meeting that Jane had transcribed and um you know separated - used the individual channels we segmented it in- into the segments that Jane had used and uh Don sampled that so - so eight K_ um and then we ran up to I guess the first twenty minutes  up to synch time of one two zero zero so is that - that's twenty minutes or so? Um yeah because I guess there's some  and Don can talk to Jane about this  there's some bug in the actual synch time file that Or so. ah uh I'm - we're not sure where it came from but stuff after that was a little messier. Anyway so it's twenty minutes and I actually um Hmm. I - was that - did that - did that recording have the glitch in the middle? I'm puzzled by that. I - oh - oh  I see. Oh there was a glitch somewhere. There's - there's a - yeah  so that actually um Was it twenty minutes in  I thought - I forgot about that. if it was twenty minutes in then I don't know Well it was interesting  suddenly - Well  I mean  they - but I was able to can- transcribe I don't remember when it is. the - the overall error rate when we first ran it was like eighty percent but i- looking at - the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the - it was actually recognized so Yeah  that might be - that might be - that might be my fault. I'm not - Oh no. Wel- Wow. Oh so that was just a parsing O_K. No actually it was - mismatch. yeah i- it was a complicated bug because they were sometimes one off and then sometimes totally random so Oh. yeah  I was pretty certain that it worked up until that time  so That's not good. um Yeah so that's what we have but that - that will be completely gone if this synch time problem O_K. Alright. Yeah. The - So - so we have everything recognized but we scored only the first uh whatever  up to that time to And the only glitch - the glitch yeah. yeah. So you guys know. Yeah. S- Th- the The - the - sorry I haven't seen the email  what was the score? So here's the actual copy of the email um well - wait we should say something about the glitch. He - he can say something about the glitch. Cuz it's - it's - it's - h- it's - it's very small - very small. yeah. oh O_K so does this glitch occur at other - There - there - there's an acoustic glitch that occurs where um the channels get slightly asynchronized Yep. Oh. Mmm. Right. so the - that - that problem has gone away in the original driver believe it or not when the S_S_H key gen ran the driver paused for a fraction of a second Hmm. Hmm. and so the channels get a little asynchronous and so if you listen to it in the middle there's a little part where it starts doing - doing click sounds. And is it only once that that happens? So - But yeah it - right once in the middle. O_K. There's - the previous page has some more information about sort of what was wrong but so - so un- unsurprisingly Adam is the golden voice  you see this here? Um S- O_K so that's actually and it - But that shouldn't affect anything yeah yeah ""bah"" It - y- it's - O_K no - Oh  and - What happens is it actually affects the script that Don - I mean if we know about it then I guess it could always be checked for it but they Huh. Well the acoustic one shouldn't do anything. I agree. I agree. Yeah  I don't know exactly what affected it but I'll - I'll talk to you about it  I'll show you the point. I - I have - But Yeah. It - it had no effect on my transcription  you know  I mean I - I had no trouble hearing it and - and having time bins but Yeah. Yeah. I - I do remember - Mmm. I do remember seeing once the transcriber produce an incorrect X_M_L file where one of the synch numbers was incorrect. there was a - Oh. That's what happened. Well  the - the synch time - the synch numbers have more significant digits than they should  right? There's things that are l- in smaller increments than a frame. Yeah. Oh. There was - Where - where they weren't monotonic. yeah  I mean - Yeah. Oh  interesting. Oh O_K so that's And so then  I mean you look at that and it's got you know more than three significant digits in a synch time then that can't be right so Hmm. Oh. Yeah. yeah sounds like a bug. Mmm. anyway it's - it's just - that's why we only have twenty minutes but there's a significant Non-zero? amount of - Um there are like more - The other one I saw was that it cuz there's a lot of zeros I tacked on just because of the way the script ran  I mean but there were- there was a point. yeah. Yeah that was fine. That - that was O_K. The other one I saw was non- non-monotonic synch times and that definitely indicra- indicates a bug. O_K. Uh. Well that would really be a problem  yeah. So anyway these are just the ones that are the prebug Yeah. for one meeting. Hmm. um and what's - So that's very encouraging. which - this is really encouraging cuz this is free recognition  there's no Yeah. Cool. Mmm. I mean the language model for Switchboard is totally different so you can see some like Trent Lott. this Trent Lott which um I mean these are sort of funny ones  there's a lot of perfect ones and good ones and all the references  I mean you can read them and It'll get those though. when we get more results you can look through and see but I Mm-hmm. and as I said I would like to look at the lattices because it sounded like even the ones it got wrong it sort of got it right? um it's pretty good. Well so I guess we can generate Sounds likes? Mm-hmm. There are a fair number of errors that are  you know where - got the plural S_ wrong or the inflection on the verb wrong. um Yeah  and who cares? And - and there were lots of - of course the ""uh uh""-s  ""in on""-s Mmm  so if - there's - No those are actually ""of uh""-s. Yeah. a lot of the errors I think are out of vocabulary  so is it like P_Z_M is three words  it's P_Z_M  I mean there's nothing Mm-hmm. Mm-hmm. Right. There's no language model for P_Z_M Ri- ri- right. or um Did you say there's no language for P_Z_M? No language model  I mean those - Do you mean - so every time someone says P_Z_M it's an error? Maybe we shouldn't say P_Z_M in these meetings. Well - well there's all kinds of other stuff like Jimlet and Yeah  that's right  Jimlet. I mean um anyway there - Well  we don't even know what that means  so I so but this is really encouraging because Yeah  that's right. so  I mean the bottom line is even though it's not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of - of r- reasonable s- you know Switchboard this is like h- about how well we do on Switchboard-two data with the Switchboard-one trained - mostly trained recognizer and Switchboard-two is - Right. Excellent. got sort of a different population of speakers and a different topic and they're talking about things in the news that happened after Switchboard-one so there was @@ so that's great. Yeah. Yeah so we're in better shape than we were say when we did - had the ninety-three workshop Um and we were all getting like seventy percent error on Switchboard. Mm-hmm. Oh yeah I mean this is really  and thanks to Andreas who  I mean this is a you know Mmm. Well Mmm. Yeah. especially for the very first run  I mean Oh it's the - eh um yeah Yeah. you - the first run I ran of Switchboard I got a hundred twenty percent word error but So and what al- also this means is that um Right. Not Switchboard  uh Broadcast News. Well it's - I mean there's a bunch of things in this note to various people especially I guess um with Jane that - that would help for - since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring. I had to deal with some of it by hand but I think a lot of it can be automated s- by - Oh one thing I guess I didn't get so you know the language model was straight from - from bigram from Switchboard the acoustic models were also from Switchboard or - or Yeah. Yeah. That's amazing. So they didn't have anything from this acoustic data in yet? O_K. Yeah  so that's great. No. And actually - we actually um used Switchboard telephone bandwidth models That's amazing. I was just gonna say  yeah. which I guess Yeah. Well that's - those are the only we- ones there are  I mean so that's the on- that's the only acoustic training data that we have a lot of and I guess Ramana   so a guy at S_R_I said that Yeah. Right. um there's not a huge amount of difference going from - it's - it's not like we probably lose a huge amount but we won't know because we don't have any full band models for s- conversational speech. Right. It's probably not as bad as going f- using full band models on So. telephone band speech right? Oh yeah. Yeah. Right. Right  so it's - so Yeah  but for Broadcast News when we - we played around between the two there wasn't a huge Right  it was not a big deal. Yeah so I wou- so that's good. I should - I should say that - loss. Although combining em worked well. the language model is not just Switchboard it's also - I mean there's uh actually more data is from Broadcast News but with a little less weight Yeah. Uh-huh. Like Trent Lott must have been from I guess Switchboard was before uh. uh because mm-hmm  right. Um By the way just - Good point. for fun we also ran  I mean our complete system starts by doing ge- a gender detection Mm-hmm. so just for the heck of it I ran that And it said a hundred percent male? um and it might be reassuring for everybody to know that it got all the genders right. Yeah so Yeah. Yes. The j- Oh it did? Oh that's - I'm glad. It got all two genders? Yeah but you know Jane and Adam have you kn- about equal performance and uh and that's interesting cuz I think the - their language models are quite different so and I - I'm pretty sure from listening to Eric that  you know given the words he was saying and given his pronunciation that the reason that he's so much worse is the lapel. Right. That makes a lot of sense  yeah. Yeah. So it's nice now if we can just sort of eliminate the lapel one when - Very possible. Yeah I - I - I would bet on that too cuz he certainly in that - when as a - as a burp user he was - he was a pretty uh strong one. when we get new microphones that would be worth it um Sheep. Yeah he - he - he sounded to me just from - he sounded like a  what's it a sheep or a goat? Yeah. A sheep. Baah. Sheep. Sheep  right. Yeah. Sheep is good. Sounded good. Yeah. Right so um Mm-hmm. so I guess the good news is that and - and again this is without a lot of the sort of bells and whistles that we c- can do with the S_R_I system and we'll have more data and we can also start to maybe adapt the language models once we have enough meetings. So this is only twenty minutes of one meeting with no - no I mean clearly there are um with just a small amount of uh actual tailoring at all. meeting transcriptions uh thrown into the language model you can probably do quite a bit better because Yeah. Or just dictionary. the - The voca- the vocabulary especially yeah. Yeah  so. Not that much the vocabulary actually I think - um well we have to see but - Yeah. it's uh - It's pretty good um Have to add P_Z_M and so on but so then And I have to try it on the far field mike yeah. P_Z_M and then there's things like for the transcription I got when someone has a digit in the transcript I don't know if they said  you know one one or eleven and I don't know if they said Tcl or T_C_L. there's things like that where  you know the um we'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and I'm hoping - and this is - this is good news because that means the force alignments should be good and if the force alignments  I mean it's good news anyway but if the force alignments are good we can get all kinds of information. For example about  you know prosodic information and speaker overlaps and so forth directly from the aligned times. Um so that'll be something that actually in order to assess the forced alignment um we need s- some linguists or some people to look at it and say are these boundaries in about the right place. Because it's just gonna give us time marks so. But you know - Well we've done that for one meeting. For forced alignment. Uh oh oh f- not for words I'm sorry just for overlaps is we did it for not - not for words. Ye- right. Right. So this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality and then I was thinking it - Right. So we might want to take twenty minutes and do a closer word level transcription. Maybe actually mark the word boundaries. Oh or - i- have someone look at the alignments uh maybe a linguist who can say um you know roughly if these are O_K and how far away they are. Yeah. Um but I think it's gotta be pretty good because otherwise the word recognition would be really b- crummy. Right  right. It wouldn't necessarily be the other way around  if the wor- word recognition was crummy the alignment might be O_K but if the word recognition is this good the alignment should be pretty good. So that's about it. I wonder if this is a good thing or a bad thing though  I mean if we're pr- I r- That we're starting so well? yeah if we're producing a database that everybody's gonna do well on Oh Don't worry about it w- d- that's that's the close talking mikes. Try it on the P_Z_Ms and - and Yeah  which - I would - which - well n- n- n- n- Yeah  yeah  yeah  yeah. So the real value of the database is these? Yeah  abso- well no but I mean there's still just the w- the percentages and  I mean they're not - a- as we've talked about before there's probably overlaps This i- yeah. This is not that good. there's probably overlaps in - in uh in fair number in Switchboard as well so but - but there's other phenomena  it's a meeting  it's a different thing and there's lots of stuff to learn with the close talking mikes but uh yeah certainly I'd like to see as soon as we could  I mean maybe get some of the glitches out of the way but soon as we could how well it does with say with the P_Z_Ms or maybe even one of the Right. and uh see if it's  you know is it a hundred twenty percent or maybe it's not maybe if with some adaptation you get this down to fifty percent or forty-five percent or something and - and then if for the P_Z_M it's seventy or something like that that's actually something we could sort of work with a little bit Yeah. No I think it's really  I mean this way we least have a baseline we know that for instance the transcripts are very good so once you can get to the words that the recognizer which is a total subset of the things you need to understand the - the text so um yeah they're pretty good so and - and it's converting automatically from the X_M_L to the chopping up the wave forms and so forth it's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in Switchboard so that's good. And um let's see there was one more thing I wanted to - to mention - I can't remember um Sorry can't remember. anyway it's - well it was  I mean I really didn't do this myself so Andreas set up this recognizer and - by the way the recognizer all the files I'm moving to S_R_I and running everything there so Congratulations Yeah. is really great. Yeah  it's really good. I brought back just these result files and people can look at them um so We - we talked about setting up the S_R_I recognizer here. That's - you know if - if there are more machines um uh here plus people can - could run their own uh you know variants of - of - of the recognition runs um certainly doable. Um. Yeah and - well certainly if the recognition as opposed to training  yeah. Seems reasonable. I need t- Hmm. Yeah. I need to ask one question. Yeah. Which is um so this issue of the uh legalistic aspects of the pre-sent- you know pre-adapted - Yeah  well  so what I mean is um the - uh the data that you take into S_R_I  first - first question  you're maintaining it in - in a place that wouldn't be publicly readable that - that kind of stuff  right? U- um From the outside world or By uh people uh who are not associated with this project. It's human subjects issues  I told you about that. Oh. Exactly. Um oh. Well O_K we have n- no names. Although I sh- um That - that's not the issue  it's just the audio data itself  until people have a chance to de- audio data itself? Mm-hmm  exactly. edit it. Uh so well I can - I can protect my directories through there. Right now they're not - they're in the speech group directories which - so I will - I didn't know that actually. Yeah. Great. Yeah so we just have to go through this process of having people approve the transcriptions  say it's O_K. Yeah O_K. Yeah  we had to get them to approve em and then i- cuz - cuz the other question I was gonna ask is if we're having um you know it's Right O_K. but this - this meeting that you have  no problem cuz I - I well I mean I - I speak for myself but - but I think that we didn't do anything that but It's us. well anyway so uh I wouldn't be too concerned about it with respect to that although we should clear it with Eric and Dan of course but these results are based on data which haven't had the uh haven't had the chance to be reviewed by the subjects and I don't know how that stands  I mean if you - if you get fantastic results and it's involving data which - That's true. which later end up being lessened by  you know certain elisions  then I don't know but I wanted to raise that issue  that's all. Well we  I mean once we get all this streamlined it may be sh- it - hopefully it will be fairly quick but we get the transcriptions  people approve them and so on it's just that we're Alright we need to work at a system for doing that approval so that we can send people the transcripts and get back any bleeps that they want Great. Mmm. Yeah. Yeah actually the bleeps are also an issue I thought. It's gonna be a rare thing that there's a bleep for the most part. U- uh actually I had a question about the downsampling  um I don't know who  I mean how this was done but Don did this. is - is there - are there any um issues with downsampling because I know that the recognizer um that we use h- can do it sort of on the fly um so we wouldn't have to have it eh you know do it uh explicitly beforehand. And is there any um i- are there other d- sev- uh- is there more than one way to do the downsampling where one might be better than another? There are lots of w- there are lots of ways to do the downsampling um different filters to O_K. put on  like anti-aliasing stuff. Right. O_K. So - so the - th- I don't think we even know which one I assume you're using syncat to do it? No  I'm using uh S_N Or sound resample? S_N_D uh Re- re- ref- yeah. Resample. Yeah and Dan's archaic acronyms. are resample. R_S_M_P. Yeah  I don't really. Missing all the vowels. I just - yeah I found it. Not all of them. Some of the vowels  almost all the vowels  that's the hard part. So - so the other thing we should try is to just take the original wave forms  I mean segment them but not downsample them. And a few of the consonants. Yeah we could - we could try that and - and Yeah  that's - And - and feed them to - feed them to the S_R_I recognizer and see if - if the S_R_I front-end does something. compare Yeah. I suspect that's sort of premature optimization  but Sure. We can try it. I - I only downsampled them first cuz I was I mean that's just one line - that's one line of code to comment at so Well - yeah Right and - and it doesn't - is no more work for um Mm-hmm. Yeah. Well they're just bigger to transfer  that's why I s- downsampled them before but you know for us. Well but they're only twice as big so Well I mean that was - if it's the same then we can downsample here but if it's - I mean it's - it's just a Although those eighty meg files take a while to copy into my directories so  but no  I mean it's not - i- it wouldn't be a problem if you're interested in it - it would - Yeah. We could try that. Yeah I mean it would be uh you know it would probably take uh about um you know minus the transfer time it would - it would take uh Yeah. you know ten minutes to try and - and - and It's about a fifty minute drive  right? Well it takes more disk space too so I was just - And - and if for some reason we see that it works better then we might investigate why and  you know  what - Mmm. In the front-end we could do that. Yeah. Yeah. So you just train - just different filters and so you're just wondering whether the filter is Yeah  I - Yeah  I can imagine it would be - Right. Right. I mean I guess there's some - So we could try that with this particular twenty minutes of speech and sort of see if there's any differences. You know a- at some point someone might have optimized whatever filtering is done for the actual recognition Hmm. um performance. So in other words Right. right  so It just seems to me that  you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that. I mean so one is a half a percent better than the other I don't think that gives you any information. Well it's just as easy to - to give you the sixteen K_ individual  it was just more disk space you know for storing them so Yep. Are you - are you using uh uh mel cepstrum or P_L_P over there? Mel cepstrum. So probably doesn't matter. Well we could try. Could easily try There's - there's your answer. But - but it wouldn't hurt to try  yeah. That's what I would assume but you never know  you know. so Sure. Just - Mm-hmm. No the reason I say this P_L_P uses uh auto-regressive filtering and uh modeling and so Mm-hmm. it can be sensitive to the kind of filtering that you're doing but uh uh mel cepstrum uh might not - b- you wouldn't expect to be so much but Well we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti- stick them somewhere and I'll rerun it with Yeah  it's - it's really not a problem. Actually  no. Don't stop. Don't stop at that part because Keep going. we're actually using the entire conversation to estimate the speaker parameters  so Yeah. shouldn't use - you should s- you know  get @@ Yeah  I mean I'll - I have to do is eh e- the reference file would stay the same  it's just the individual segments would be approximately twice as long and I could just replace them with the bigger ones in the directory  that's not a problem. O_K. Yeah. Right. Mmm. Right. Right. Yeah. Right. I mean I corrected all - I mean I hand-edited the whole - the whole meeting so that can be run it's just - Once we get the - the bug out. Mmm. One - one question which is I - I had the impression from this - from this meeting Yeah. Mm-hmm. that w- that I transcribed that um that there was already automatic downsampling occurring  is that I thought that in order to Yep. so it was - There's one level that's already happening right here. so it's like there's already down O_K. This is being recorded at forty-eight kilohertz. Oh. Right. And it gets downsampled to sixteen. O_K. Which is more that anybody needs so And that's actually said in your meeting  that's how I know that. I - I It's like are we downsampling to sixteen? Hmm. Oh O_K. That's exactly  and that's how I know it. Yeah. It's a digital audio orientation for the board it's in the monitor so it's Right. Mmm. Thank God it's not more than that. So - Is eight kilohertz - Yeah. And I have no idea what filter it's using  so is - is eighty kilohertz generally accepted as like standard for voice? Telephone. For telephone stuff. Telephone. Yeah that's what I was gonna say  I mean like - so So it's - it's - it's just that they were operating from Switchboard which was a completely telephone database and so that was a standard for that Oh  I see  so. O_K. So sixteen seems to be pretty typical for sixteen s- Right. Sixteen is more common for - for uh with this sort of thing. broadband stuff that isn't - That isn't music. that isn't music and isn't telephone  yeah. And I guess if you're comparing like - uh if you wanna run recognition on the P_Z_M stuff you would want you don't want to downsample the wh- that right? Why is that? I don't know. Well I don- I mean if it's any better No actually I would think that you would - you would get better - you'd get better high frequencies in the local mike. All the way around I'd think. Uh but who knows? I mean we do- we - we - we - we - we wanna find all this stuff out  we don't know. Yeah well we could try it. Yeah. We're gonna have plenty of low frequency on the P_Z_Ms with the fans. O_K. Yeah. Uh yeah. Yeah. Oh yeah there was just one more thing I wanted to say which is totally unrelated to the recognition except that um well - well it's sort of related but um good news also uh I got - well Chuck Fillmore agreed to record meetings but he had too many people in his meetings and that's too bad cuz they're very animated and but uh Jerry also agreed so uh we're starting on - on They're less animated. Well but he has fewer - he - he won't have more than eight and it's a meeting on even deeper understanding  E_D_U  so that sounds interesting. As a compliment to our front-end meeting Dot E_D_U? and um so that's gonna start Monday and one of the things that I was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose gonna transcribe it or - or put a push a button or something when they wanna make a note about ""oh boy you should probably erase those last few"" or uh ""wait I want this not to be recorded now"" or Weren't we gonna uh something like that s- do something with a pad at one point? The cross pads? Yeah  we could do it with the cross pads. Cuz I was thinking you know if - if the person who sets up the meeting isn't there and it's a group that we don't know um and this came up talking to - to Jerry also that you know is there any way for them to indicate - to make sure that the qu- request that they have that they make explicitly get addressed somehow so I don't know if anyone has ideas or - you could even write down ""oh it's about three twenty five and"" - Yeah. Well what I was just suggesting is - is we have these - this cross pad Yeah  and use that. Not a bad idea. just for this purpose and just use that and if we sink it in - That would be great. That be great. The other thing is eh I don't know if you know this or if it's a question for the mail to Dan but is this thing of two eight channel boards a maximum for this setup I don't know. or could we go to a third board? I don't know. I'll send mail to Dan and ask. I - I think that it's the maximum we can do without a lot of effort because it's one board with two Oh it is one board. digital channels. E- eight each. So it - it takes two fibers in to the one board. And so w- I think if we wanna do that - more than that we'd have to have two boards  and then you have the synchronization issue. But that's a question because that would - if it was possible cuz it is i- you know already we have a - a - a group of people in this room that cannot all be miked Right. and it's not just cuz we haven't been to the store  right it's - What is the limit on each of those f- fiber channels  is it the Eight. It just - it's eight channels come in  does it have do with the sampling rate? It's eight. I have no idea. But each - each fiber channel has eight - eight channels and there are two ch- two fibers that go in to the card. It might be a hard limitation  I mean one thing is it - the whole thing as I said is - is all structured in terms of forty-eight kilohertz sampling so that pushes So requirements up a bit but Yeah. I was just wondering if - if that could change. I mean then we'd also have to get another A_D_D and another mixer and all that sort of stuff. If we could drop that. Yeah. So I - I'll send a mail to Dan and ask him. Yeah. O_K on the uh are we done with that? So the oth- topic is uh getting more mikes and different mikes  so I got a quote um We can fit - we have room for one more wireless and the wireless  this unit here is three fifty - three hundred fifty dollars  it - I didn't realize but we also have to get a tuner - the receiver - the other end  that's uh four thirty um Wow. For - for each? I mean the tuner is four thirty for each. and then also Yep. Wow. And we just need one more so - so Yeah at least w- we got the good ones. Yeah. So that's you know something like seven hundred eighty bucks for one more of these. Yeah. O_K. Um and then also um It turns out that the connector that this thing uses is proprietary of Sony Oh. believe it or not and Sony only sells this headset. Mmm. So if we wanna use a different set - headset the solution that the guy suggested and they - apparently lots of people have done is Sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself. And that's the other solution and so the jacks are forty bucks apiece and the - he recommended um a crown C_M three eleven A_E headset for two hundred bucks apiece. There isn't this some sort of thing that plugs in  you actually have to go and do the soldering yourself? Becau- the reason is the only - only thing you can get that will plug into this is this mike No I understand. or just the The reason I ask is these sort of handmade connector. uh wiring jobs fall apart in use so the other thing is to see if we can uh get them to do a custom job and put it together for this. Oh I'm sure they would  they would just charge us  so. Well  and they'd probably want quantity too  they'd Well no they'll just charge us more  so it's - this Mmm. So - so my question is should we go ahead and get na- nine identical head-mounted crown mikes? Not before having one come here and have some people try it out. O_K. Because there's no point in doing that if it's not gonna be any better. So why don't we get one of these with the crown with a different headset? Yeah. And - and see if that works. And see if it's preferable and if it is then we'll get more. Comfort. Yeah. Yeah. Cuz I mean I think the microphones are O_K it's just the - the Right  it's just they're not comfortable to wear. Right. Could make our own handbands and Um  and he said they don't have any of these in stock but they have them in L_A and so it will take about a week to get here. Yeah well it's - Um so O_K to just go order? We're in this for the long term  yeah. Just order it. O_K and who is the contact if I wanna do an invoice cuz I think that's how we did it before. It's a lot of money for a handband. Yeah. Uh we'll do this off-line  yeah. It's a long time to get from L_A. O_K. And then nine channels is the maximum we can do  so. Uh y- right cuz - so one is for the daisy chain so that's fifteen instead of sixteen and there's six on the table so that's nine. Without getting more stuff. Right. Can I ask a really dumb question? Yeah. Probably. Is - is there any way we can have you know like a - a wireless microphone that you pass around to the people who you know the extra people for the times they wanna talk that - I mean - That's a good idea. That's not a dumb question  it's a good idea  yeah. Well I mean - Like uh I'm just not sure how we would handle that in the That's like the Conch. See  look. like you know Jerry Springer thing  you know r- Well but - Like at conferences well but there might be a way to say that there are gonna be these different people so nail the chairs down. um and I don't know identifying somehow? You know I was just thinking of Jerry Springer. Yeah. @@ Yeah  somehow. It's not a bad idea. No that - no - no that's a very - if we can't get another board and even if we can I have a feeling they'll be some work. I mean for the few times that you might wanna have that. The Springer mike. Let's figure that we have eight which are set up and then there's a ninth which is passed around to - A hand-held  yeah. that's a good idea Infinite expansion. Right. Kind of rules out overlap but - but uh Well or also for you know if people are not Yeah. Well we could just hand around the lapel. Uh no - no that's - Rather than get a - do you want a handset? No not the lapel. No. Well I mean is the - is the hand-held really any better? Liz hates the lapel. Yes. O_K. I don't know but I d- I know the lapel is really suboptimal. No it - Is awful? no it depends on the hand-held but hand - many hand-helds are built wi- with sort of uh anti-shock sort of things so that it - it is less uh susceptible to hand noises. Mm-hmm. If you hold the lapel mike i- you just get all k- sorts of junk. Right. I mean the ones they really pass around must be sort of O_K. O_K. so So I wonder if they have one that will hook up. Yeah. They have - What? I wonder if they have one that will hook up to this or whether again we'll have to wire it ourselves. Well  you wouldn't want it to hook there you'd just want it to hook into the receiver in the other room  right? No that's uh - you need a transmitter. What? Is th- isn't that built into the mike? Oh I see. Get a - get a different radio  yeah. Yeah just these ones that they Yeah. pass around with no you know wireless But you need a ra- but it has to correspond to the receiver. Have a little antenna coming out the bottom. It's gonna be much easier to get one of these and just plug in a mike  isn't it? But then the mike has to h- Do you have to hand it around and if you have two pieces of Yeah. No no - Right. @@ so right  so this is a good point  so yeah you have these - these mikes with a little antenna on the end right? O_K. And do you think you would be able to use the same receiver? I don't know. You'll have to check with them  yeah. O_K I'll - I'll ask. Yeah. It's just a frequency. But that's - that's a great idea and then just sort of have that as the - and then you can have groups of twenty people or whatever and - and uh Yeah because there's only I mean as Andreas pointed out actually I think in the large - the larger the group the less Pretty soon. interaction - the less people are talking Mmm  yeah. um over each other - it just - there might be a lot of people that speak once or twice and Right. Um Off you go  yeah. Gotta go. O_K so I guess people who have to leave can leave and do we have anything else to discuss or should we just do digits? I - I thought of some extra - a couple of extra things I'd like to mention. O_K. One of them is to give you a status in terms of the transcriptions so far. So um as of last night uh um I'd assigned twelve hours and they'd finished nine and my goal was to have eleven done by the end of the month  I think that by tomorrow we'll have ten. So they're still working. Uh it's great - I j- and this - I got this email from Jane at like two in the morning or something so it's really great Pretty close  that's good. Yep  that's good. Wow. It's working out  thanks. It's really great. Thanks. And then um also an idea for another meeting  which would be to have the transcribers talk about the data It's sort of a - a little bit - a little bit That's a great idea. Yep  that'd be very interesting. I'd love to hear what they have to say. Super idea. Yeah. That's a great idea cuz I'd like to g- have it recorded so that we can remember all the little things  that's a great idea. Yeah. So if we got them to talk about this meeting  it would be a meta - meta meeting. Yeah. Yeah  exa- exactly I guess - nested several layers  but Now you have eight transcribers and there's ten of us so how do we do this  is the only thing. Or just have them talk amongst themselves. Have them have their own meeting. Well that's what I'm thinking  yeah. And have Have them talk about the data Oh. that would be great. and they - and they've made observations to me like they say uh you know this meeting that we think has so much overlap  in fact it does but there are other groups of similar size that have very little  you know it's part of it's - it's the norm of the group and all that and they have various observations that would be fun  I think. That's a great idea. Yeah. Yeah  I'd like to hear what they s- say. Be great. O_K. So maybe we could - they could have a meeting more or less without us that - to do this and we should record it and then maybe one or two of them could come to one of these meetings and - and could you know could tell us about it. Yeah. Give us a status. Yeah. Oh good. O_K. Yeah. It's - they will get to transcribe their own meeting but they also get paid for having a break and I think that's a good idea  get them involved. What - what That would be weird. yeah that's right. Yeah exactly  yeah. Yeah. Great. Um that's a great idea. I'm really sorry I have to g- Great. Super. no I have to go as well. O_K. And then I wanted to also um say something about the Fiscus uh uh John - John Fiscus visit tomorrow. And Which is to say that w- it'll be from nine to one that I'm going to uh uh offer the organization - allow him to uh adjust it if he wishes but to be basically in three parts  the acoustic part coming first which would be basically the room engineering aspects um other things and he'll be also presenting what NIST is doing and - and uh then uh number two would be sort of a the - the transcription process so this would be a focus on like presegmentation and the modifications to the - the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which uh Dave Gelbart's been doing and then um uh and of course the presegmentation Thilo's been doing and then um the third part would - and again he has some stuff that's i- relevant with respect to NIST and then the third one would be focus on transcription standards so at NIST he's interested in this establishment of a global encoding standard I guess I would say and I want it  you know k- yeah see what they're doing and also present what - what we've chosen as ours and - and discuss that kind of thing. And so but he's only here until until one and actually we're thinking of noon being uh lunch time so basically hoping that we can get as much of this done as possible before noon. S- O_K. And everybody who wants to attend is welcome. So yeah. Oh  where you're gonna meet? Here mostly but I've also reserved the BARCO room um eh to figure out how that works in terms of like maybe having a live demonstration. O_K but the nine o'cl- nine o'clock will be i- be in here. Yeah  O_K. Yeah. Mm-hmm. I assume we're not gonna try to record it? Oh I think that would be hard  yeah. Yeah  I think just adds - Alright. Yeah. Um good. Thank you though  uh-huh. So maybe do digits and Yeah. Unless there's anything else? recess? Yeah. Do digital ones ? Uh O_K. Yeah. Uh should y- we make him wear Andreas' mike or would that just be too confusing? Yeah. No I don't think it's confusing. Well  it doesn't confuse me. When we do this in the key - in the key - in the key it has to indicate that channel change  right? Does it mess up the forms? Uh yeah I just don't know how we would do that  so. Well i- have a time mark. I mean other than free - free form. The on switch is here on the - Yeah. on the top there. O_K. And just clip it to your collar. That's fine. O_K  my name is uh Espen Eriksen. I'm a Norwegian. Um uh this is my second semester at Berkeley. Currently I'm taking uh my first graduate level courses in D_S_P and um when I come back to Norway I'm gonna continue with the - more of a research project work - kind of work. So this semester I'm starting up with a - with a small project through uh Dave Gelbart which I'm taking a course with I got in touch with him and he told me about this project. So with the help of uh Dan Ellis I'm gonna do small project associated to this. What I'm gonna try to do is uh use - use ech- echo cancellation to uh to handle the periods where you have overlapping talk. To try to do something about that. So currently I'm um I'm just reading up on echo cancellation  s- looking into the theory behind that and then uh hopefully I get some results. So it - it's a - it's a project goes over the course of one semester. Great. So I'm just here today to introduce myself. Tell about I'll be - I'll be working on this. And are you staying at Berkeley or is - are you just here a semester? This is my second semester and last. Ah second and last  O_K. So Yeah. He's in the - he's in the cour- two two five D_ course. I leave Yeah  I'm in Morgan's course  yeah. So  yeah. Good. Then you - then you go back to Norway  that's Welcome. Yeah. O_K. We were just talking about something like this yesterday or yeah yesterday with Liz. About doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps  so. Cool. Yeah. O_K  let's do digits. Digits? O_K  this is transcript three four three one three four five O_. O_K. five five five nine one six eight one four three zero three seven seven eight six O_ three O_ eight nine zero zero four zero five zero one four four two four seven seven two five seven eight two six six three four five six zero eight two eight one O_ four eight three two nine nine O_ three one six eight one nine zero nine three zero zero one nine two two three zero five one one two Transcript eh three three nine one dash three four one zero. three four five zero seven one two eight four nine nine seven two six eight eight one O_ six zero one two four two seven three two nine seven five five zero six five four four seven seven eight two eight nine nine O_ one one three three one eight seven two four O_ two three seven two Three three seven one dash three three nine zero. two three O_ nine five two four zero three one eight six five four zero zero one one seven six four two five nine four eight eight nine O_ zero two five two three four five O_ four four two two zero five eight six seven eight zero O_ one six five O_ zero four three two one seven two nine six Transcript number three five one one dash three five three zero. eight O_ three two one O_ O_ seven zero five nine one nine two three six five two four five zero seven five two nine eight three eight two nine three O_ O_ eight seven eight zero six zero one two four one three five three seven six four seven eight Transcript three four nine one dash three five one zero. seven zero nine two five eight four four three O_ five four nine zero eight one five zero two one two three four zero zero eight eight six six four nine six seven five seven seven eight zero seven eight five nine O_ zero two four nine nine eight two zero three five O_ four two eight O_ O_ O_ nine five six seven Transcript three four seven one dash three four nine zero. seven one eight seven seven three nine six O_ eight zero one two four two one three six zero zero five four eight seven five seven two six six one nine one six seven seven eight nine O_ one four two two three seven O_ two four five seven one six Transcript three four five one dash three four seven zero. six seven seven seven eight eight eight seven nine eight four eight five six nine O_ zero two two five two five three O_ three eight four four nine four four one five nine O_ three six eight zero one five seven O_ five eight O_ O_ four seven two six zero five four one five nine two three four five zero And stop. ","The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device. Three intentions were identified: Vista (to view)  Enter (to visit) and Tango (to approach). The structure of the belief-net comprises  firstly  a feature layer  which includes linguistic  discourse and world knowledge information that can be gleaned from the data. It is possible for these variables to form thematic clusters( eg ""entrance""  ""type of object""  ""verb"")  each one with a separate middle layer. These feed  in turn  into the main middle layer  that defines more general hidden variables  such as the tourist/business status of the user. The feature layer can end up being cue-based  while the middle layers task-based. The latter determine the final probability of each intention in the output layer. This first model of the belief-net was built in JavaBayes  since it is a free package  has a graphical interface  and it can take XML files as input. At this stage  all the actual probabilities are ad-hoc and hand-coded. However  there has been progress in the design and organisation of experiments  that will eventually provide data more useful and appropriate for this task. It is necessary for the belief-net to have at least one layer of nodes between the features and the final output. This makes the structure more flexible in terms of coding feature-layer probabilities. Another technique to systematise the work is the thematic clustering of the features  each cluster forming a Bayes-net of each own: for example features like ""admission fee"" and ""opening hours"" can feed into an intermediate ""entrance"" node connecting to the main middle layer. The next stage is to refine the set of feature nodes and identify possible clusters. Although  in theory  traditional AI plan recognition techniques could also be helpful for inferring intentions  the schemas involved are too elaborate for this task. Further work also includes discussing the possible advantages of Bayes-net packages  other than JavaBayes  with experts at ICSI. If they continue using JavaBayes  a script to help with the inputting of probabilities in the nodes is needed  as the in-built method is cumbersome. Finally  it was decided that at least some of the experiments designed for the new data collection initiative will factor in the intentions studied in the current task. The set of cues that form the feature nodes is not well-defined yet. Especially with lexical cues (verbs  modifiers etc)  no one offered specific intuitions as to how they might contribute to the inference of intentions. Other features  like ""admission fee""  may be intuitively linked with one of the outputs (Enter)  however  any probabilities are coded in an ad-hoc fashion and are by no means realistic. Cases like this  where feature and output seem to be linked directly  bring the necessity of a middle layer in the belief-net to question. Nevertheless  not having a middle layer would not allow for shifts in the discourse and would make the setting of probabilities and manipulation of the belief-net clumsy. Some issues with the use of JavaBayes also arose: the addition of new variables in an existing node overwrites all previous settings  and the native text file where the probability tables are set is not easy to read; this makes adding and changing variables and nodes problematic. Finally  it is unclear how much learning can be done on the created nets. There was a demonstration of the structure and the function of a toy version of the belief-net for the intentionality task. The features nodes include things like prosody  discourse  verb choice  ""landmark-iness"" of a building  time of day and whether the admission fee was discussed. The values these nodes take feed into the middle layer nodes identified as hidden variables of the user/device interaction  such as whether the user is on tour  running an errand or in a hurry. These  in turn  help infer whether the user wants to see  enter or simply approach a building. The set of features nodes is derived from linguistic cues  world knowledge and discourse history. SmartKom  although it does not code for intentions as specified in this task  provides a model of the discourse  which can be useful for the detection of features through querying and anaphora resolution. Experiments for the collection of new data will start soon  since someone who will recruit subjects and help run the experiments has already been hired and the designing of the experiments has also progressed significantly. "
"Yeah  I think I got my mike on. O_K. Let's see. three eight eight  seven one  four six two seven six nine two  six four O_  nine seven nine two one  one six  zero two  three zero  nine six eight six one  six four  eight nine three six four O_ eight  five six nine  eight eight zero zero seven  four two  eight two  four four  nine one five  four one five  seven seven  one one nine  seven four eight seven  nine three  four two four zero. O_K. Ami  do yours then we'll open it and I think it'll be enough. Mmm - Doesn't  uh - It should be the other way. Yeah  now it's on. Right. O_K. One five six  seven four one  five six four zero five one  four five three  nine two zero five one three three eight  zero  two five zero eight zero three six  nine  two eight nine six seven one  one nine  eight one nine nine eight  five zero eight  nine eight  four five five  eight three zero seven  seven eight four  eight one seven zero eight three nine  eight  three eight three. O_K. So  we all switched on? We are all switched on  yeah. Alright. Anyway. So  uh  before we get started with the  uh  technical part  I just want to review what I think is happening with the - We are all switched on. our data collection. So - Uh  probably after today  that shouldn't come up in this meeting. Th- this - this is s- should be im- it isn't - There's another thing going on of gathering data  and that's pretty much independent of this. But  uh  I just want to make sure we're all together on this. What we think is gonna happen is that  uh  in parallel starting about now we're gonna get Fey to  where you're working with me and Robert  draft a note that we're gonna send out to various CogSci c- and other classes saying  ""here's an opportunity to be a subject. Contact Fey."" And then there'll be a certain number of um  hours during the week which she will be available and we'll bring in people. Uh  roughly how many  Robert? We d- Do we know? Um  fifty was our - sort of our first - O_K. So  we're looking for a total of fifty people  not necessarily by any means all students but we'll s- we'll start with - with that. In parallel with that  we're gonna need to actually do the script. And  so  I guess there's a plan to have a meeting Friday afternoon Uh  with - uh  Jane  and maybe Liz and whoever  on actually getting the script worked out. But what I'd like to do  if it's O_ K  is to s- to  as I say  start the recruiting in parallel and possibly start running subjects next week. The week after that's Spring Break  and maybe we'll look for them - some subjects next door or i- Yeah . Yeah. Also  Fey will not be here during spring break. So. Oh  O_K  then we won't do it. O_K. So that's easy. Um. So  is - Is that make sense to everybody? Yeah. Also  um  F- both Fey and I will  um  do something of which I may  eh - kindly ask you to - to do the same thing  which is we gonna check out our social infrastructures for possible subjects. Meaning  um  kid children's gymnastic classes  pre-school parents and so forth. They also sometimes have flexible schedules. So  if you happen to be sort of in a non-student social setting  and you know people who may be interested in being subjects - We also considered using the Berkeley High School and their teachers  maybe  and get them interested in That's a good idea. stuff. And  um. So that's as far as our brainstorming was concerned. Oh  yeah. The high school's a great idea. So. But I - I will just make a first draft of the  uh  note  the ""write-up"" note  send it to you and Fey and then - And why don't you also copy Jane on it? And  um  Are we - Have we concurred that  uh  these - these forms are sufficient for us  and necessary? Uh  th- I think they're necessary. This - The permission form. Mmm. Nuh. Uh  there has to be one  and I think we're just gonna use it as it is  and N_. Um You happy with that? Well  yeah. There's one tricky part about  um  they have the right um I- The last paragraph ""if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set."" O_K? Now that  we- had to be included for this other one which might have  uh  meetings  you know  about something. In this case  it doesn't really make sense. Mm-hmm. Um  so what I'd like to do is also have our subjects sign a waiver saying ""I don't want to see the final transcript"". Mm-hmm. And if they don't - If they say ""no  I'm not willing to sign that""  then we'll show them the final transcript. But  um. Yep . Makes sense. That  uh - yeah   so we might actually  um S- i- Jane may say that  ""you know  you can't do this""  uh  ""on the same form  we need a separate form."" But anyway. I'd - I'd - I'd like to  e- e- um  add an- a little thi- eh - a thing for them to initial  saying ""nah  do- I don't want to see the final transcript."" But other than that  that's one's been approved  Mm-hmm. this really is the same project  uh  rec- you know. And so forth. So I think we just go with it. Yeah . Yeah . O_K. So much for the data  except that with Munich everything is fine now. They're gonna transcribe. They're also gonna translate the  uh  German data from the T_V and cinema stuff for Andreas. So. They're - they all seem to be happy now  with that. So. w- c- sh- should we move on to the technical sides? Yep. Well I guess the good - good news of last week was the parser. So  um Bhaskara and I started working on the - the parser. Then Bhaskara went to class and once he came back  um  it was finished. So. It  uh - I didn't measure it  but it was about an hour and ten minutes. Yep. Something like that. And  um - and now it's - We have a complete English parser that does everything the German parser does. Which is not a lot. But - That's the  uh  point. The - uh  that's not a lot. O_K. Yes. Right. And um. What did you end up having to do? I mean  wha- Was there anything Well  if you  eh - We'll show you. interesting about it at all? or are we gonna see that? Yeah  we can show us  right? Well  w- w- We d- The first we did is we - we tried to - to do - change the - the ""laufen"" into ""run""  or ""running""  or ""runs"". Yep. Mm-hmm. And we noticed that whatever we tried to do  it no effect. O_K. And we were puzzled. Mm-hmm. And  uh  the reason was that the parser i- c- completely ignores the verb. Hmm. Interesting parser property. So this sentence - sentence is - parses the p- the same output  um  even if you leave out  um  I see. Yeah. all - all of this. So it's basically feature film and T_V. Today O_K. And the - t- and the time  right? That's what you need. If - if you'd add - add Today and Evening  it'll add Time or not. So it - i- it does look at that. But all the rest is p- simply frosting on the cake  O_K. and it's optional for that parser. True. And - So  you can sho- You - you - Are - are you gonna show us the little templates? S- Yeah. We ar- we can sh- er - I can show you the templates. ""The former end g-"" Oh  I see. Uh-huh. I - I also have it running here  so if I do this now  um  you can see that it parsed the wonderful English sentence  ""Which films are on the cinema today evening?"" Well  that sounds - But  um. Uh do- don't worry about it. It could be No i- "" this evening  which - which films are on the cinema""  or ""running in the cinema  which -"" O_K. uh  ""today evening""  uh i- ""Is anything happening in the cinema this evening?"" O_K. Key words  e- basically. Well Ge- elaborate  or  more or less  uh - Actually  it's a little tricky  in that there's some allowable German orders which aren't allowable English orders and so forth. And it is order-based. So it - it - Isn't it? No. No. Oh. So it - it doe- I- it - These - u- these optional elements  it's - it's actually a set  not a sequence? It is not - Yeah. We were - I was afraid that  um - Oh! So it really is key word matching  basically. Really a se- Um. e- yeah. Mm-hmm. Oh  wow. Um  I mean  these sentences are just silly. I mean  uh  d- these were not the ones we - we actually did it. Hmm. Um. What's an idiomatic of phrasing this? Which films are @@ Are pl- playing at the cinema? showing? playing? Yeah. Tonight? I changed that file  actually  where it's on my account. Actually  you would say  ""which films are on tonight?"" This - this evening? You want to get it? Or - is - di- was it easy to get it? Um. I have no net here. Oh  O_K. Do I? O_K. So. Wonderful parse  same thing. Um. Right. Except that we d- w- we don't have this  uh  time information here now  which is  um - Oh. This - are the reserve. Anyways. So. Um. These are the - sort of the ten different sentence types that the uh - the parser was able to do. And it still is  now in English. Mm-hmm. Yeah. And  um - Sorry. And  um you have already to make it a little bit more elaborate  right? Yeah  I mean I changed those sentences to make it  uh  more  uh  idiomatic. And  of course  you can have i- many variations in those sentences  they will still parse fine. So  in a sense it's pretty broad. O_K. O_K. So  if you want to look at the templates  they're conveniently located in a file  ""template"". Um  and this is what I had to do. I had to change  @@ ""Spielfilm"" to ""film""  uh  ""Film"" to ""movie""  cinem- ""Kino"" to ""cinema"" - to- ""today"" - heu- ""heute"" to ""today""  evening - ""Abend"" to ""evening"" Huh. Capitalized as well Hmm. And  um. Y- i- One thing I was wondering  was  those functions there  are those things that modify the M_-three-L_ basically? Yep. O_K. And that's - that's the next step  but we'll get to that in a second. p- And so this means  um  Oh. ""this"" and ""see"" are not optional. ""Want I like"" is all maybe in there  but may also not be in there. So - so  the point is  if it says "" this "" and "" see ""  it also will work in "" see "" and "" this ""? S- In the other order? Yeah. with those two key words? Should we try it? ""This is the one I want to see"" or whatever. O_K. ""Action watch""  Hmm. whatever. Nothing was specialfi- specified. except that it has some references to audio-visual media here. A_V medium. Yeah. Where it gets that from - It's correct  but I don't know where it gets it from. "" See "". Oh  "" see "". Yeah. I mean it's sort of - Yeah. Yep. O_K. And ""see this"" is exactly the same thing. O_K  so it is set-based. Alright. One thing I was wondering was  those percentage signs  right? So  I mean  why do we even have them? Because - if you didn't have them - Yep. Uh  I'll tell you why. Because it gives a - you a score. Mm-hmm. Oh. And the value of the score is  v- I assume  I guess  the more of these optional things that are actually in there  the higher the r- score O_K. Right. It's a match. So that's the main purpose. Alright. it is. Mm-hmm. O_K. So we - we shouldn't belittle it too much. It's doing something  some things  and it's very flexible. I've just tried to Mm-hmm. Right. be nice. No  no. Fine. Yeah  yeah  yeah  flexible it is. Right - Yeah. But - O_K. Um  let's hope that the generation will not be more difficult  even though the generator is a little bit more complex. Uh but we'll - Mmm  that means we may need two hours and twenty minutes rather than an hour ten minutes  Alright. Right. I hope. And the next thing I would like to be able to do  and it seems like this would not be too difficult either  is to say  ""O_K let's now pretend we actually wanted to not only change the - the mapping of - of  uh  words to the M_-three-L_ but we also wanted to change - add a new sentence type and and make up some - some new M_-three-L_ - s-"" Yep. So- That'd be great. It would be a good exercise to just see See th- whether one can get that to run. Mm-hmm. Yep. And  um  So  that's - Fine  yeah. that's - shouldn't be too tough. Yeah  so where are those - those functions ""Action""  ""Goodbye""  and so on  right? Are they actually  um  Are they going to be called? Um  are they present in the code for the parser? Yeah. I think what it does  it i- i- it does something sort of fancy. It loads um - It has these style sheets and also the  um  schemata. So what it probably does  is it takes the  uh  um - Is this where it is? This is already the X_M_L stuff? This is where it takes its own  um  syntax  and converts it somehow. Um. Where is the uh - What are you looking for? Um  where it actually produces the - the X_M_L out of the  uh  parsed stuff. Oh  O_K. No  this is not it. Uh. I can't find it now. You mean  where the - where the act- how the action ""Goodbye"" maps into something - Yeah. Yeah  where are those constructors defined? Oh. No  that's not it. Nope. Yeah. This is sort of what happens. This is what you would need to - to change - to get the  uh  X_M_L changed. So when it encounts- encounters ""Day""  it will  uh  activate those h- classes in the - in the X_M_L stuff But  um - I saw those actions - uh  the ""Goodbye"" stuff somewhere. Hmm  hmm  hmm  hmm  hmm. Grep for it? Yeah . Let's do that. Oh. Mmm. M_-three-L_ dot D_T_D? Yep. That's just a specification for the X_M_L Yep. format. Well  we'll find that out. So whatever - n- this does - I mean this is  basically  looks l- to me like a function call  right? Hmm? Oh  yeah. And  um - So  whenever it - it encounters ""Goodbye""  which we can make it do in a second  here That function automatically generates an initialized X_M_L structure? I think each of those functions act on the current X_M_L structure  and I- change it in some way  for example  by adding a - y- a l- a field to it  or something. Yeah. They also seem to affect state  cause some of them - Mm-hmm. there were other actions Right. uh  that - that s- seemed to step - state variables somewhere  like the n- s- "" Discourse Status Confirm"". Yep. O_K. So that's going to be a call on the discourse and confirm that it's - W- we- Mm-hmm Oh  you mean that's not going to actually modify the tree  but it's going to change the event. Oh. Oh. I think that's right. I think it's actually - That looks like it's state modification. e- e- mmm Um  well i- When there's a feature. There is a feature called ""Discourse-Status""  Yeah. And so whenever I just say  ""Write""  it will - it will put this in here. Oh  so it always just - Is it - So it - Well  go back  then  cuz it may be that all those th- things  h- while they look like function calls  are just a way of adding exactly that to the X_M_L. Yep. Uh-huh! I'm not - I'm not sure. So  this - e- I'm not sure - e- that - Um - well  we - we'll see  when we say  let's test something  ""Goodbye""  causes it to c- to create basically an ""Action Goodbye-End-Action"". Which is a means of telling the system to shut down. Right. Right. Now  if we know that ""Write"" produces a ""Feature Discourse-Status Confirm Discourse-Status"". So if I now say ""Write  Goodbye "" it should do that. It sho- it creates this  Mm-hmm. Right. ""Confirm Goodbye"". Right there. Yep. But there is some kind of function call  because how does it know to put Goodbye in Content  but  uh  Confirm in Features? So- Oh. It d- it - n- That's because - So  it's not just that it's adding that field. It's Right. O_K. Absolutely. Good point. It's - it's - the - It's under what sub-type you're doing it. Yeah. Mm-hmm. Yeah . It's mystery functions. Well  they're defined somewhere  presumably. Well  sometimes it m- Sometimes  i- Yeah  each is - S- so that's funny. You bury the s- the state in the function When it - Alright. Uh @@ it - Well  it just automatically initializes things that are common  right? So it's just a shorthand. Yeah. For example - Oh  this is German. Sorry. e- So  now  this  it cannot do anymore. Nothing comes out of here. A ""not a number"" is a value. Awesome. So  it doesn't speak German anymore  but it does speak English. And there is  here  a reference - So  this tells us that whatever is - has the I_D "" zero "" is referenced here - by @@ the restriction seed and this is exa- ""I want -"" What was the sentence? ""I want two seats here."" ""need two seats here."" Nuh . ""And where is it playing?"" There should also be a reference to something  maybe. Our d- This is re- um Mmm . Here  we change - and so  we - Here we add something to the Discourse-Status  that the user wants to change something that was sort of done before And  uh - and that  whatever is being changed has something to do with the cinema. So then  whatever takes this M_-three-L_ is what actually changes the state  not the - Yeah  O_K. No  right  the Discourse Maintainer  yeah. Yeah. I see. And it - and it runs around looking for Discourse Status tags  and doing whatever it does with them. And other people ignore those tags. Alright. So  yeah. I definitely think it's - It's worth the exercise of trying to actually add something that isn't there. Hmm? Uh Sort of get a complete understanding of the whole thing. Disc- Yeah  a kid understanding what's going on. Then the next thing we talked about is actually  um  figuring out how to add our own tags  and stuff like that. O_K. Point number two. I got the  uh  M_-three-L_ for the routes today. Uh  so I got some more. This is sort of the uh  um  Hmm. Interesting. It's just going up  it's not going back down. So  this is - um  what I got today is the - the new um M_-three-L_ for um  the Maps  Yep. uh  and with some examples - So  this is the X_M_L and this is sort of what it will look like later on  even though it - you can't see it on - on this resolution. And this is what it - sort of is the - the structure of Map requests  um also not very interesting  and here is the more interesting stuff for us  is the routes  route elements  and  again  as we thought it's really simple. This is sort of the  uh  um  parameters. We have @@ simple "" from objects"" and "" to objects"" and so forth  points of interest along the way - And  um  I asked them whether or not we could  um - First of all  I was little bit - It seemed to me that this m- way of doing it is sort of a stack- a step backwards from the way we've done it before. t- It seems to me that some notions were missing. So these are - these are - S- So these are - these are your friends back at E_M_L. Yep. Who are doing this. So this is not a complicated negotiation. There's - there's not seven committees  or anything  right? No. No  this is very straightforward. Great. So this is just trying to - It's a design thing  not a political thing. Yeah. Once we've - eh - We can just sort of agree on what oughta be done. Exactly. And  um - Good. And  uh - However  the  uh - e- So that you understand  it is really simple. Uh - You - you have a route  and you cut it up in different pieces. And every - every element of that e- r- r- f- of that - Every segment we call a ""route element"". And so  from A_ to B_ we cut up in three different steps  and every step has a "" from object"" where you start  a "" to object"" where y- where you sort of end  and some points of interest along the way. What w- I was sort of missing here  and uh  maybe it was just me being too stupid  is  I didn't sort of get the - the notion of the global goal of the whole route. Really  s- was not straightforward visibly for me. And some other stuff. And I suggested that they should n- be - k- uh  kind enough to do s- two things for us  is one  um  Also allocating  uh  some tags for our Action Schema Enter-Vista-Approach  and - And also  um  since you had suggested that - that  um  we figure out if we ever  for a demo reason  wanted to shortcut directly to the g- G_I_S and the Planner  of how we can do it. Now  what's the state of the art of getting to entrances  um  what's the syntax for that  how get- getting to vista points and calculating those on the spot. And the Approach mode  anyhow  is the default. That's all they do it these days. Wherever you'll find a route planner it n- does nothing but get to the closest point where the street network is Mm-hmm. at minimal distance to the geometric center. @@ So. So  well  let - Now  this is important. Let  uh - I want a- a- Again  outside of m- almost managerial point  um - You're in the midst of this  so you know better. But it seems to me it's probably a good idea to li- uh - minimize the number of uh  change requests we make of them. So it seemed to me  what we ought to do is get our story together. O_K? And think about it some  internally  before asking them to make changes. Mm-hmm. Oh. Does this - does this make sense to you guys? It - I mean you're - you're doing the - the interaction but it seemed to me that what we ought to do is come up with a - uh  something where you  um - And I - I don't know who's mok- working most closely on it. Probably Johno. O_K. Uh  take what they have  send it to everybody saying ""this is what they have  this is what we think we should add""  O_K? and then have a d- a - an iteration within our group saying ""Hmm  well -"" O_K? And get our best idea of what we should add. Mm-hmm. And then go back to them. Is i- or  I don't know does this make sense to you? Or Yeah. Especially if we want - Sort of  what I - my feeling was eh- we - we sort of reserved something that has a r- eh- an O_K label. That's - th- that was my th- first sort of step. Mm-hmm. I- w- No matter how we want to call it  this is sort of our playground. And if we get something in there that is a structure elaborate and - and - and - and - and complex enough to - to - to maybe enable a whole simulation  Right. Right. one of these days  that would be - u- the - the perfect goal. That's right. So. So  Yeah. The problem isn't the short ra- range optimization. It's the sort of - o- one or two year kind of thing. O_K. What are the thl- class of things we think we might try to do in a year or two? How - how would we try to characterize those and what do we want to request now that's leave enough space to do all that stuff? Mm-hmm. Yep. Right. And that re- that requires some thought. Yep. And - so that sounds like a great thing to do as the priority item um  as soon as we can do it. Yep. So y- so you guys will send to the rest of us um a version of um  this  and - the - uh  description - With sugge- yeah  suggested improvements and - Well b- Yeah. So  the - the - uh - Not everyone uh  reads German  so if you'd um Mmm. tu- uh  tur- change the description to  uh  English O_K. and  um  Then - then  yeah. Then  with some sug- s- suggestions about where - where do we go from here? Uh  this - and this  of course  was just the O_K. action end. Uh  at some point we're going to have to worry about the language end. But for the moment just uh  t- for this class of - of things  we might want to try to encompass. And - Then the scope of this is beyond Approach and Vis- or Vista. Yeah  yeah. Oh  yeah  yeah yeah yeah. This is - this is everything that - that  um  you know  um Yeah  yeah. we might want to do in the next couple years. Hmm? So what would - O_K. We don't - I mean  that's an issue. We don't know what  entirely. Uh  yeah. but I'm just - But the - Yeah  O_K. So I just - this X_M_L stuff here just has to do with Source-Path-Goal type stuff  in terms of traveling through Heidelberg. Hmm. Right. Or travel  specifically. So  but this O- Is the domain greater than that? No. I think - I think the i- the idea is O_K. that - Oh. It's beyond Source-Path-Goal  but I think we don't need to get beyond it @@ - tourists in Heidelberg. It seems to me we can get O_K. all the complexity we want in actions and in language without going outside of tourists in Heidelberg. O_K? But you know  i- depending on what people are interested in  one could have  uh  tours  one could have um  explanations of why something is - is  you know  why - why was this done  or - I mean  no - there's no end to the complexity you can build into the - uh  what a tourist in Heidelberg might Mmm. ask. So  at least - unless somebody else wants t- to suggest otherwise I think the general domain we don't have t- to uh  broaden. That is  tourists in Heidelberg. And if there's something somebody comes up with that can't be done that way  then  sure. W- we'll - we'll look at that  but uh I'd be s- I- I'd be surprised at - if there's any - important issue that - that - And  um - I mean if - if you want to uh  push us into reference problems  that would be great. O_K. O_K  so this is - his specialty is - reference  Mm-hmm. and - you know  what - what are these things referring to? Not only anaphora  but  uh  more generally the  uh - this whole issue of  uh  referring expressions  and  what is it that they're actually dealing with in the world? Mm-hmm. And  again  this is li- in the databa- this is also pretty well formed because there is an ontology  and the database  and stuff. So it isn't like  um  you know  the Evening Star or stuff like that. I- i- it - Right. All the entities do have concrete reference. Although th- the To get at them from a language may not be trivial. Right. Right. There aren't really deep mysteries about um  what w- what things the system knows about. Right. And you have both proper names and descriptions and y- and you can ask for it. All those things. Yeah. You have proper names  and descriptions. Mm-hmm. Right. O_K. Nuh. And a l- and a lot - and - and anaphora  and pronouns  and Right. Right. all those things. Now   we hav- the - the whole - Unfortunately  the whole database is  uh  in German. We have just commissioned someone to translate some bits of it  I_E the e- the shortest k- the - the more general descriptions of all the objects and  um  persons and events. So  it's a relational database with persons  events  and  um  objects. And it's - it's quite  um  there. But did y- I - uh - I think there will be great because the reference problem really is not trivial  even if you have such a g- well-defined world. He knows. Ah- he- you are not  uh  throwing uh  uh  carrying owls to Athens. Could you give me an example of a reference problem? so - so l- I can make it more concrete? Well - How do I get to the Powder-Tower? We sort of t- think that our bit in this problem is interesting  but  just to get from Powder-Tower to an object I- I_D in a database is also not really trivial. Or - or if you take something even more scary  um  ""how do I get to the third building after the Tower? the Ple- Powder-Tower?"" Uh  you need some mechanism for Mmm. Yeah. Or  you know  the church across from City Hall  or - Or the re- the restaurant where they wear lederhosen? Or is that - Or the- Right. Yeah  that would be fine. Uniquely. Right. O_K. Yeah. O- or - or tower  or this tower  or that building  or - Right. hmm? O_K. Or you can say ""how -"" you know  ""how do I get back? "" Trying to - Yeah  yeah. O_K. And  again  it's just a question of which of these things  uh  people want to dive into. What  uh  I think I'm gonna try to do  and I guess  pwww! let's say that by the end of spring break  I'll try to come up with some general story about  um  construction grammar  and what constructions we'd use and how all this might fit together. There's this whole framework problem that I'm feeling really uncomfortable about. And I haven't had a chance to think about it seriously. But I - I want to - I want to do that early  rather than late. And you and I will probably have to talk about this some. u- u- u- u- That's what strikes me  that we sort of - the de- g- uh  small - Something  uh  maybe we should address one of these days  is to - That most of the work people actually always do is look at some statements  and - and analyze those. Whether it's abstracts or newspapers and stuff like this. Hmm. But the whole - i- is it - is it really relevant that we are dealing mostly with  sort of  questions? Oh  yeah? Well  I mean yeah  I- d- Uh  you know - And this is - It seems to me that we should maybe at least spend a session or - or brainstorm a little bit about whether that l- this is special case in that sense. Mm-hmm. Um  I don't know. You know - Did we ever find m- metaphorical use in - in questions in - in that sense  really? Yeah. @@ You will. And how soon  I don't know . Oh  yeah. I mean  uh  we could take all the standard metaphor examples and make question versions of them. O_K. Muh- "" Who got kicked out of France?"" Nuh. Yeah  or  you know. ""Wh- why is he - why is he pushing for promotion?"" or  ""who's pushing proof-"" er  just pick - pick any of them and just Right. Nuh. Mm-hmm. do the - eh - So I don't - I don't think  uh  it's at all difficult - Uh  to convert them to question forms that really exist and people say all the time  um - And - sort of - we don't know how to handle them  too. Right? I mean  it's - I d- It - We don't know how to handle the declarative forms  @@ really  and  then  the interrogative forms  ah-oh. Uh. Ooo! Yeah. Nancy  it looked like you were s- Oh. it's just that - that the goals are g- very different to cases - So we had this problem last year when we first thought about this domain  actually  was that most of the things we talked about are our story understanding. Uh  we're gonna have a short discourse and the person talking is trying to  Right. I don't know  give you a statement and tell you something. And here  it's th- Help you create a mental model  blah-blah-blah. Yeah. Yea- eh - y- Yeah  I guess so. And then here  y- you are j- uh  the person is getting information and they or may not be following some larger plan  Yes. you know  that we have to recognize or  you know  infer. And th- th- the - their discourse patterns probably don't follo- follow quite as many logical connec- Yeah. Right. No  I think that's one of things that's interesting  is - is in this sort of over- arching story we - we worked it out for th- as you say  this - the storytelling scenario. Mm-hmm. Mm-hmm. And I think it's really worth thinking through what it looks like. What is the simspec mean  et cetera. Mm-hmm. M- Right. Cuz for a while we were thinking  ""well  how can we change the  um  data to sort of illicit tha- illicit  um  actions that are more like what we are used to?"" But obviously we would rather  you know  try to figure out what's - what's  you know - Well  I don't know. I mean  maybe - maybe that's what we'll do is - is s- u- e- We can do anything we want with it. I mean  once we have fulfilled these requirements  Yep. Mmm - Mm-hmm. Mm-hmm. O_K  and the one for next uh  summer is just half done and then the other half is this  Mm-hmm. um  ""generation thing"" which we think isn't much different. So once that's done  then all the rest of it is  uh  sort of  you know  what we want to do for the research. And we can - w- we can do all sorts of things that don't fit into their framework at all. Th- there's no reason why we're c- we're constrained to do that. Mm-hmm. If we can use all the  uh  execution engines  then we can  you know  really try things that Mm-hmm. would be too - too much pain to do ourselves. But there's no obligation on any of this. So  if we want to turn it into u- understan- standing stories about Heidelberg  we can do that. I mean  that would just be a t- a- um - Or  as a matter of fact  we need - and if we if we'r- eh - take a ten year perspective  we need to do that  because w- e- w- a- Assuming we have this  um  we- we- ta- in that case we actually do have these wonderful stories  and historical anecdotes  and Yeah. Mmm. knights jumping out of windows  and-and-and - tons of stuff. So  th- the database is huge  and if we want to answer a question on that  we actually have to go one step before that  and understand that. Mm-hmm. In order to e- do sensible information extraction. And so  Yeah. Mm-hmm. You might  yeah. Mwa- Mm-hmm. um  this has been a - a - a Deep Map research issue that was - is - is part of the unresolved  and to-do's  and something for the future  is how can we sort of run our our text  our content  through a machine that will enable us  later  to Mm-hmm. retrieve or answer e- questions more sensibly? Mmm. Right. Anyway. S- So  uh - So  uh  I was just going to ask  um  so  Who's going? what is the - the basic thing that - that you are  um  obligated to do  um  uh  by the summer before w- uh y- c- we can move - Ah! O_K. So - eh - Yeah. So  what happened is  there's this  eh  uh - Robert was describing the - There's two packages there's a  uh  quote parser  there's a particular piece of this big system  which  in German  uh  takes these t- sentence templates and produces X_M_L structures. Right. And one of our jobs was to make the English equivalent of that. Right. That  these guys did in a - in a day. Right. The other thing is  at the other end  roughly at the same level  there's something that takes  uh  X_M_ L structures  produces an output X_M_L structure which is instructions for the generator. Right. O_K? And then there's a language generator  and then after that a s- a synthesizer that goes from an X_M_L structure to  uh  language generation  to actual specifications for a synthesizer. Right. Eh  but again  there's one module in which there's one piece that we have to convert to English. Right. Got it. Is that - O_K. And that - But as I say  this is - all along was viewed as a kind of - a m- a minor thing  necessary  but - but not - Right. Right. That's great! O_K? And much more interesting is the fact that  as part of doing this  we - we are  you know  inheriting this system that does all sort- of these other Right. things. Not precisely what we want  and that's - that's wh- where it - it gets difficult. And I - I don't pretend to understand yet what I think we really ought to do. O_K. So  e- enough of that  but I  uh  um  mmm  the e- sort of  Johno and I will take up that responsibility  and  um  get a first draft of that. Now  we have um just  I think two more short things. O_K. Um  y- you guys sort of started fighting  uh  on the Bayes-net ""Noisy-OR"" front? Hmm. Yeah  I thought I should  um  talk a little bit about that  because that might be a good  uh  sort of architecture to have  in general for  uh  problems with  Good! O_K. you know  multiple inputs to a node. Good. And what's the other one? so that - just we know what the d- agenda is? Um  the Wu paper  I think maybe - Oh  yeah. I've got a couple new Wu papers as well. Uh  so I - I've been in contact with Wu  so  probably let's put that off till I - I - till I understand better  uh  what he's doing. It's just a little embarrassing cause all this was in his thesis and I was on his thesis committee  and  so  I r- really knew this at one time. Ugh. But  I - I - It's not only uh Is - Part of what I haven't figured out yet is - is how all this goes together. So I'll dig up some more stuff from Dekai. And - so why don't we just do the  uh - O_K. So - should I - Is there a white board here that I can use? Yeah. You could - Uh - Yeah. Or shall I just use this? squealing sound? It's probably just as easy. I- Yeah. Yeah. You can put the microphone in your pocket. Hey! I was envying you and your pocket cause I don't have one. It was a quick one  huh ? That's why they invented ""pocket T_'s"". They have clips! Huh. exactly Yeah. So  um - Recall that  uh  we want to have this kind of structure in our Bayes-nets. Namely  that  um - You have these nodes that have several bands  right? So - Does I mean  they sort of - the typical example is that  um  these are all a bunch of cues for something  and this is a certain effect that we'd like to conclude. So  uh - Like  let's just look at the case when  um  this is actually the - the final action  right? So this is like  uh  you know  Y- touch  or - Sorry. Uh E_- EVA @@ Yeah  E_- E_V_A   right? Yeah. Enter  V- View  Approach  right? W- what was this? It - i- i- i- ehhh  i- ehhh. So  this is - Wri- write it out for- for - Yeah. Enter  I mean - View  Approach. O_K. Right. Right. So  I mean  we'd like to - take all these various cues  right? So this one might be  say  uh - Like the army. Yeah. New terminology? I haven't heard that before. Well  let me pick a random one and say  uh - Hmm? I don't know  it could be  like - This isn't the way it really is  but let me say - that  suppose someone mentioned  uh  admission fees Ah  it takes too long. Try - let me just say ""Landmark"". If the thing is a landmark  you know  um - then there's another thing that says if - um - if it's closed or not  at the moment. Alright  so you have nodes. Right? And the  uh  problem that we were having was that  you know  given N_nodes  there's ""two to the N"" Given N_nodes  and furthermore  the fact that there's three things here  we need to specify ""three times""  uh  ""two to the N"" probabilities. Right? That's assuming these are all binary  which f- they may not be. For example  they could be ""time of day""  in which case we could  uh  say  you know  ""Morning  afternoon  evening  night"". So  this could be more So  it's a lot  anyway. And  that's a lot of probabilities to put here  which is kind of a pain. So Noisy-ORs are a way to  uh  sort of deal with this. Um Where should I put this? So  the idea is that  um  Let's call these  uh  C_one  C_two  C_three  and C_four  and E_  for Cause and Effect  I guess. The idea is to have these intermediate nodes. Right. Well  actually  the idea  first of all  is that each of these things has a - quote-unquote distinguished state  which means that this is the state in which we don't really know anything about it. So - right? So  for example  if we don't really know if the thing is a landmark or not  Or  i- if that just doesn't seem relevant  then that would be th- sort of the Disting- the Distinguish state. It's a really  you know  if there is something for the person talking about the admission fee  you know  if they didn't talk about it  that would be the Distinguish state. S- so  this is a fanciful way of saying ""default""? So - Yeah  yeah. That's just what they - the word they used in that paper. O_K. Mm-hmm. So  the idea is that  um  you have these intermediate nodes  right? E_one  E_two  E_three and E_four? So  this is the Heckerman paper you're working with? Good. Yeah. So The idea is that  each of these E_I - is - represents what this would be - if all the other ones were in the distinguish state. Right? So  for example  suppose that the person - I mean  suppose the thing that they talked about is a landmark. But none of the other - sort of cues really apply. Then  this would be - W- The this would just represent the probability distribution of this  assuming that this cue is turned on and the other ones just didn't apply? So  you know  if it is a landmark  and no- none of the other things really ap- applicable  then - this would represent the probability distribution. So maybe in this case - Maybe we just t- k- Maybe we decide that  if the thing's a landmark and we don't know anything else  then we're gonna conclude that  um - They want to view it with probability  you know  point four. They want to enter it with probability  uh - with probability point five and they want to approach it probability point one  say - Right? So we come up with these l- little tables for each of those O_K. And the final thing is that  um - this is a deterministic function of these  so we don't need to specify any probabilities. We just have to  um  say what function this is  right? So we can let this be  um - G_ of E_one comma E_two. E_three  E_four. Right? and our example G_ would be  um  a majority vote? Right? Well. O_K  so th- so the important point - is - W- not what the G_ function is. The important point is - that - Um - There is a - a - a general kind of idea of shortcutting the full C_P_T. Th- c- the full conditional probability table - with some function. O_K? Which y- w- you choose appropriately for each case. So  depending on what your situation is  there are different functions which are most appropriate. And - So I gave - eh - Bhaskara a copy of this  eh - sort of ""ninety-two"" paper. D- and you got one  Robert. I don't know who else has seen it. Mm-hmm. There's - I mean - yeah. it's Heckerman and Breese. It's short. It's short. Yeah. So  I- u- w- Um  yo- uh - you - Have you read it yet? Uh  you can - Yeah  you should take a look at it  I guess. O_K  so you should take a look. Nancy  I'm sure you read it at some point in life. O_K I - yeah. I - I think so  yeah. O_K. Yeah  @@ . And - so  you other guys can decide how interested - Anyway. So the paper isn't th- isn't real hard. And - O_K. Uh - One of the questions just come at Bhaskara is  ""How much of this does JavaBayes support?"" Yeah  it's a good question. Um The - so what we want  is basically JavaBayes to support deterministic  uh  functions. Right. And  um - In a sense it sup- we can make it supported by  um  manually  uh  entering  you know  probabilities that are one and zeros  right? Right. So the little handout that - The little thing that I sent - I sent a message saying  uh  here is a way to take - One thing you could do  which is kind of s- in a way  stupid  is take this deterministic function  and use it to build the C_P_T. So  if Ba- JavaBayes won't do it for you  Mmm. that you can convert all that into what the C_P_T would be. Um - and  what I sent out about a week ago  was an idea of how to do that  for  um  evidence combination. So one of - one function that you could use as your ""G_ function"" is an e- e- Evidence-Combining. So you just take the - uh  if each of th- if each of the ones has its own little table like that  then you could take the  uh  strength of each of those  times its little table  and you'd add up the total evidence for ""V_""  ""E_""  and ""A_"". Mmm. I don't think you can do this  because - Mm-hmm. Yep. G_ is a function from that to that. Right. Right? So there's no numbers. There's just - quadruplets of - well  N_duplets of  uh  E_Vs. I- i- i- No  no - But I'm saying is - There - There is a w- I mean  if y- if - if you decide what's - what is appropriate  is probablistic evidence combination  you can write a function that does it. It's a pui- it's actually one of the examples he's got in there. But  anyway  s- skipping - skipping the question of exactly which functions - now is it clear that you might like to be able to shortcut the whole conditional probability table. I mean  in some - it seems very plausible in some sense  where we will be likely to not be - observe some of the stuff. Cuz we don't have the a- access to the information. Oops  sorry. Right. That's one of the problems  is  W- Is - is  Where would th- Where would it all come from? Yeah. So. Is - Oh  right. W- would not be ab- able to observe Mmm. What? I- if it's a - a - a discar- Discourse Initial Phrase  we will have nothing in the discourse history. So  if - if we ever want to wonder what was mention- Oh - Oh. A- are you saying that we'll not be able to observe certain nodes? That's fine. That is sort of orthogonal thing. Yeah  so there's - there's two separate things  Robert. The f- the - the - the Bayes-nets in general are quite good at saying  ""if you have no current information about this variable just take the prior for that."" O_K? Th- that's what they're real good at. So  if you don't have any information about the discourse  you just use your priors of - of whatever - eh- the - discourse - uh  eh  basically whatever w- it's - Probabilistically  whatever it would be. And it's - it's sort of not a great estimate  but - Mm-hmm. it's the best one you have  and  so forth. So that  they're good at. But the other problem is  how do you fill in all these numbers? Mm-hmm. Yeah. And I think that's the one he was getting at. Yeah. So  specifically in this case you have to - f- have this many numbers  whereas in this case you just have to have three for this  three for this  three for this. Right? So you have to have just Mm-hmm. three N_? So  this is much smaller than that. Asymptotically. Mm-hmm. Yeah. Right. Well  pretty quickly. U- yeah  yeah. So  you don't need da- data enough to cover - uh  nearly as much stuff. I mean - I don't know. So  really  i- What a - A Noisy-OR seems to kind of ""neural-net-acize"" these Bayes-nets? Eh - well- to- some- No  no. So  ""Noisy-OR"" is a funny way of referring to this  because the Noisy-OR is only one instance. Yeah. This isn't a Noisy-OR anymore. That one actually isn't a Noisy-OR. So we'll have to think of Yeah. of a way t- t- it's a Noisy-arg-max or a Noisy-whatever. Yeah  whatever. Yeah. So - Eh - Um Well  my point was more that we just - eh - With the neural net  right  eh  things come in  you have a function that combines them and - Yeah  it - it - Tha- that's true. It is a- is also more neural-net-like  although - Uh  it isn't necessarily sum - uh  s- you know  sum of weights or anything like that. Right. I mean i- You could have  uh  like the Noisy-OR function  really is one that's essentially says  uh  take the max. Well  the ""OR"". Same. Right. I guess you're right. Yeah. Uh But anyway. So - And  I thi- I think that's the standard way people get around the - uh There are a couple other ones. There are ways of breaking this up into s- to - to subnets and stuff like that. But  um The I think we definitely - I think it's a great idea tha- to - to pursue that. Yep. So Wha- still sort of leaves one question. It - I mean you - you can always uh - see easily that - that I'm not grasping everything correctly  but what seemed attractive to me in im- uh in the last discussion we had  was that we find out a means of - of getting these point four  point five  point one  of C_four  not because  you know  A_ is a Landmark or not  but we - we - we label this whatever object type  and if it's a garden  it's point three  point four  point two. If it's a castle  it's point eight  point one  point one. If it's  uh  a town hall  it's point two  point three  point five. Right. And so forth. And we don't want to write this down - necessarily every time for something but  uh - It'll be students - Where else would it be stored? That's the question. let's see. Well  in the beginning  we'll write up a flat file. We know we have twenty object types and we'll write it down in a flat file. Oh. Yeah. No. So  i- is- Well  let me say something  guys  cuz there's not - There's a pretty point about this we might as well get in right now. Mm-hmm. Which is - The hierarchy that s- comes with the ontology is just what you want for this. So that - Uh  if you know about it - let's say  a particular town hall - that  it's one that is a monument  then  that would be stored there. If you don't  you look up the hierarchy  Eh - so  you - you - you may or - So  then you'd have this little vector of  um  you know  Approach Mode or E_V_A Mode. Let's - O_K  so we have the E_V_A vector for - for various kinds of landmarks. If you know it for a specific landmark you put it there. If you don't  you just go up the hierarchy to the first place you find one. O_K. So  is the idea to put it in the ontology? Absolutely. O_K. Uh  or  link to - or - but - but in any case - i- View it logically as being in the ontology. It's part of what you know about - a - an object  is its E_V_A vector. O_K. Mm-hmm. And  if yo- As I say  if you know about a specific object  you put it there. This is part of what Dekai was doing. So  when we get to Wu  Right. The- e- We'll see w- what he says about that. And  then if you - If it isn't there  it's higher  and if you don't know anything except that it's a b- it's - it's a - building  then up at the highest thing  you have the pr- what amounts to a prior. If you don't know anything else about a building  uh  you just take whatever your crude approximation is up at that level  which might be equal  or whatever it is. Right. Yeah. So  that's a very pretty relationship between these local vectors and the ontology. And it seems to me the obvious thing to do  unless we find a reason to do something different. Yeah. Does this make sense to you? Bhask- ? So - Yeah. So  we are - but we - we're not doing the ontology  so we have to get to whoever is doing the - u- ultimately  Indeed. So  that's another thing we're gonna need to do  is - is  to  we have to get them to - either - We're gonna need some way to either get a p- tag in the ontology  or add fields  or - some way to associate - Or  w- It may be that all we can do is  um  some of our own hash tables that it - Th- the - th- you know  there's always a way to do that. It's a just a question of - i- Yeah  hash on object name to  you know  uh  the probabilities or whatever. th- Yeah. e- Right. And  so  i- uh - But it's  uh - Well  it strikes me as a What For- If we get the mechanism  that will be sort of the wonderful part. And then  how to make it work is - is the second part  in the sense that - I mean  m- the guy who was doing the ontology - eh  eh  s- ap- apologized that i- it will take him another through - two to three days because they're having really trouble getting the upper level straight  and right now. The reason is  given the craw bet uh  the - the - the projects that all carry their own taxonomy and  on all history  they're really trying to build one top level ontology ft- that covers all the E_M_L projects  and that's  uh  uh  sort of a tough cookie  a little bit tougher than they figured. I could have told them s- so. Uh. Right. Yeah. But  nevertheless  it's going to be there by n- by  uh  next Monday and I will show you what's - what some examples from that for towers  and stuff. And  um  what I don't think is ever going to be in the ontology  is sort of  you know  the likelihood of  eh  people entering r- town halls  and looking at town halls  and approaching town halls  especially since we are b- dealing with a case-based  not an instance-based ontology. So  there will be nothing on - on that town hall  or on the Berkeley town hall  or on the Heidelberg town hall  it'll just be information on town halls. Well  they - they - they - How ar- What are they gonna do with instances? I mean  you - y- But what - Well  that's - Hhh. That's - that's al- different question. I mean  th- the - first  they had to make a design question  ""do we take ontologies that have instances? or just one that does not  that just has the types?"" O_K. And  so  since the d- decision was on types  on a d- simply type-based  we now have to hook it up to instances. I mean this is one - But what i- What is SmartKom gonna do about that? Cuz  they have instances all the time. Yeah  but the ontology is really not a SmartKom thing  in - in and of itself. That's more something that I kicked loose in - in E_M_L. So it's a completely E_M_L thing. But - Uh - uh - SmartKom's gonna need an ontology. Yes  u- a w- a lot of people are aware of that. I understand  but is anybody doing anything about it? Um - O_K. It's a political problem. We won't worry about it. No  but - th- the r- eh - I th- I still think that there is enough information in there. For example  whether - O_K. So  th- it will know about the twenty object types there are in the world. Let's assume there are only twenty object types in this world. And it will know if any of those have institutional meanings. So  in a sense  ""I"" used as Institutions for some s- in some sense or the other. Which makes them - enterable. Right? In a sense. You know. Yeah. Anyway. So we may have to - This is with the whole thing  we may have to build another data stru- Yep. Yep. Conceptually  we know what should be done. When we see what people have done  it may turn out that the easiest thing to do is to build a - a separate thing that - that just pools i- i- Like  i- i- it - it may be  that  the - the instance - w- That we have to build our own instance  uh  Yeah  it's - Right  we can just assume - things  that  with their types  and then it goes off to the ontology once you have its type. So we build a little data structure And so what we would do in that case  is  in our instance gadget have our E_V_As. And if we- d- there isn't one we'd get the type and then have the E_V_As for the type. So we'd have our own little  uh  E_V_A tree. Yeah. Right. And then  for other  uh  vectors that we need. So  we'd have our own little things so that whenever we needed one  we'd just use the ontology to get the type  Mm-hmm. Mm-hmm. and then would hash or whatever we do to say  ""ah! If it's that type of thing  and we want its E_V_A vector  pppt-pppt! it's that. "" So  I- I think we can handle that. And then - But  the combination functions  and whether we can put those in Java Bayes  and all that sort of stuff  is  uh - is the bigger deal. Yeah. I think that's where we have to get technically clever. Um - We could just steal the classes in JavaBayes and then interface to them with our own code. Well  I me- ye eh  yeah  the - That requires understanding the classes in JavaBayes  I guess. Yeah  I mean  it's  uh  e- e- e- e- e- cute. I mean  you've been around enough to - I mean - Just? Well  it depends on - I mean  there's this huge package which - which may or may not be consistent and - you know. But  yeah  we could look at it. Well  I was j- O_K. Yeah. Yeah. It's b- It - It's an inter- sort of a kind of a - it - The thing is  it's kind of an interpreter and i- i- it expects its data structures to be in a given form  and if you say  ""hey  we're gonna make a different kind of data structure to stick in there -"" Well  no  but that just means there's a protocol  right? That you could - It may or may not. I don't know. That's the question is ""to what extent does it allow us to put in these G_ functions?"" And I don't know. Well  no  but - I mean - What I uh the - So you could have four different Bayes-nets that you're running  and then run your own - write your own function that would take the output of those four  and make your own ""G_ function""  is what I was saying. Yeah  that's fine if it's - if it comes only at the end. But suppose you want it embedded? Well  then you'd have to break all of your Bayes-nets into smaller Bayes-nets  with all the - Oh  that - Yeah  that's a truly horrible way to do d- it. One would hope - Yeah  but I'm just - Mm-hmm. Yeah  yeah  yeah  yeah  yeah  you bet . But  at that point you may say  ""hey  Java Bayes isn't the only package in town. Let's see if there's another package that's  eh  more civilized about this."" @@ . Now  Srini Mmm. is worth talking to on this  cuz he said that he actually did hack some combining functions into JavaBayes. Ah! But he doesn't remember - at least when I talked to him  he didn't remember whether it was an e- an easy thing  a natural thing  or whether he had to do some violence to it to make it work. Uh. But he did do it. Yeah. I don't see why the  uh  combining f- functions have to be directly hacked into JavaBayes. I mean  they're used to create tables so we can just make our own little functions that create tables in X_M_L. Well  I say that's one way to do it  is - is to just convert it int- into a - into a C_P_ T that you zip - It's blown up  and is a - it's  uh - it's huge  but - it doesn't require any Mm-hmm. data fitting or complication. Yeah. I don't think - I mean  the fact that it blown u- blows up is a huge issue in the sense that - I mean  O_K. So say it blows up  right? So there's  like  the you know  ten  f- ten  fifteen  uh  things. It's gonna be like  two to the - that  which isn't so bad. I- I understand. I'm just saying tha- that w- That was wi- that was my note. The little note I sent said that. Mm-hmm. It said  ""Here's the way you'd take the logical f- G_ function and turn it into a C_P_T."" Mm-hmm. I mean that - the Max- the Evidence-Combining function. So we could do that. And maybe that's what we'll do. But  um don't know. So  I will  e- e- before next week  uh  @@ p- push - push some more on - on this stuff that Dekai Wu did  and try to understand it. Uh  you'll make a couple of more copies of the Heckerman paper to give p- Sure. Yeah  I - I would like a copy  y- y- yeah . to people? O_K. O_K. O_K. And  um I think - O_K. And I- I'll - I'll think s- through this  uh  eh - getting EVA vectors dynamically out of ontologies one more time because I s- I - I - I'm not quite sure whether we all think of the same thing or not  here. Well  you and I should talk about it. Yeah  uh-huh. O_K. Alright  great! And  Robert  thank you for coming in under - He - he's been sick  Robert. Und. Mm-hmm. I was thinking maybe we should just cough into the microphone and see if they can't - th- see if they can handle it. Yep. Sure. Um - is this  uh - ",This should just give a general sense of anything that happens     in the meeting that you think would be a useful summary for the     target user:  generally speaking  why are they meeting and     what do they talk about? In most of the meetings  the group will make some decisions     wrt the problems they discuss. In some meetings  there may be some open problems      or problems they come up with. In a group research meeting  they will introduce what they have done      ie  progress or achievements so far. 
"Yeah. O_K  we're on. So  I think this is gonna be a pretty short meeting because I have four agenda items  three of them were requested by Jane who is not gonna be at the meeting today. So. The uh first was transcription status. Does anyone besides Jane know what the transcription status is? Um  sort of  I do  peripherally. Um - Is that English? Well first of all with I_B_M I got a note from Brian yesterday saying that they That's our system. finally made the tape for Ugh! the thing that we sent them a week or week and a half ago and that it's gone out to the transcribers and hopefully next week we'll have the transcription back from that. Um - C- can I have a pen? Jane seems to be um moving right along on the transcriptions from the ICSI side. She's assigned  I think probably five or six Yeah  I think we're up to M_R thirteen or something. m- more meetings. Yeah  so um  I guess she's hired some new transcribers and - Mmm. Which meetings is she transcribing? Speaking - Um well we've - we've run out of E_D_Us because a certain number of them are um  sort of O_K. awaiting to go to I_B_M. For I_B_M  yeah. O_K. Hmm. and the rest are in process being transcribed uh here. So we're doing some in parallel. So does she have transcribers right now who are basically sitting idle because there's no data back from Yep. No. No  no. We haven't done that process. So. They'r- they're doing the full transcription process. Oh no no. No. We're not waiting on them. I_B_M no? Oh. Oh  O_K. Yeah. So they're just doing their own thing until - Because I - We're doing it in parallel  yeah. O_K. I need to ask Jane whether it's - it would be O_K for her - um  s- some of her people to transcribe uh some of the initial data we got from the SmartKom data collection  which is these short like five or seven minute sessions. Yep. Um and we want it - You know  we need - The - Again  we - we have a similar uh logistic set-up where we are supposed to send the data to Munich and get it transcribed and get it back. Right. But to get going we would like some of the data transcribed right away so we can get started. Yep  sounds familiar. And so um I wanted to ask Jane if - if uh  you know  maybe one of their transcribers could - could do - I mean since these are very short  that should really be uh  Mm-hmm. um - There's only two channels. So it's only - Yeah. As the synthesis doesn't have to be transcribed I think. So. It's - Yeah. It's only two - Right  s- Yeah. So - So it's basically one channel to transcribe. And it's - One session is only uh like seven - So that should have ma- many fewer - And it's also not uh- a bunch of interruptions with people and all that  right? So. Yeah. Right. And some of it is read speech  so we could give them the - the thing that they're reading and they just may - Make sure it's right. And so um  Yep. um  I guess since she's - I was gonna ask her but since she's not around I - maybe I'll - Yeah  well it certainly seems - Uh if - if that's O_K with you to - to  you know  Yeah. get that stuff uh - to ask her for that  then I'll do that. Yeah  if we're held up on this other stuff a little bit in order to encompass that  that's O_K because I- I- um  I mean I still have high hopes that the- that the I_B_M pipeline'll work out for us  so it's - Yeah. O_K  yeah. Yeah. Alrighty. Oh  yeah  and also related to the transcription stuff  so I've been trying to keep a web page uh up to date f- showing what the current status is of the trans- of all the things we've collected and what stage each meeting is in  in terms of whether it's - Can you mail that out to the list? Mm-hmm  yeah I will. I - That's the thing that I sent out just to foo people saying can you update these pages and so that's where I'm putting it but I'll - Oh  O_K  O_K. I'll send it out to the list telling people to look at it. Yeah  I haven't done that. So. I have lots of stuff to add that's just in my own directory. I'll try to get to that. Yeah. O_K. So Jane also wanted to talk about participant approval  but I don't really think there's much to talk about. I'm just gonna do it. And uh  if anyone objects too much then they can do it instead. You are going to - I'm gonna send out to the participants  uh  with links to web pages which contain the transcripts and allow them to suggest edits. And then bleep them out. O_K. For the ones that we have. So but it's just transcripts  not the - not the audio? Um - Nope  they'll have access to the audio also. O_K  yeah  yep. Ah. I mean that's my intention. Because the transcripts might not be right. So you want people to be able to listen to them. Yeah. So - Yeah. So  um the audio that they're gonna have access to  will that be the uncompressed version? Or will you have scripts that like uncompress the various pieces and - Oh  that's a good point. That's a good point. Yeah  it's - it's probably going to have to be the uncompressed versions because  uh  uh  it takes too long to do random access decompression. Hmm. Yeah  I was just wondering because we're uh running out of the un-backed-up disk space on Well  that was the other point. Yep  that's another agenda item. Oh  was that another one? O_K. I'll wait. So  uh - But that is a good point so we'll get to that  too. Um  DARPA demo status  not much to say. The back-end stuff is working out fine. It's more or less ready to go. I've added some stuff that uh indes- indexes by the meeting type M_R  E_D_U  et cetera and also by the user I_D. So that the front-end can then do filtering based on that as well. Uh - The back-end is uh  going more slowly as I s- I think I said before just cuz I'm not much of a Tcl-T_K programmer. And uh Dave Gelbart says he's a little too busy. So I think Don and I are gonna work on that and - and you and I can just talk about it off-line more. Right. But uh the back-end was pretty smooth. So I think  we'll have something. It may not be as - Oh- As pretty as we might like  but we'll have something. I wondered whe- when we would reach Dave's saturation point. He's sort of been - been volunteering for everything and and uh - Yeah. Mm-hmm. O_ K. Finally said he was too busy. I guess we reached it. Yeah  he - he actually - he volunteered but then he s- then he retracted it. So. Oh well. Um - And  also um  I was just showing Andreas  I got um an X_Waves kind of display  and I don't know how much more we can do with it - with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom so  right now it's just an X_Waves and then you have three windows but I don't know  it looked pretty nice and I'm sure it - think it has potential for Oh  cool. For a demo? Yeah  sounds good. a little something  yeah  for a demo. So - O_K  so again  the issue is - For July  the issue's gonna be what can we fit into a Windows machine  uh  and so on  but - Oh. O_K. So it might just be slides. Yeah  O_K. Well  we'll see  um - Well - Yeah. I've been putting together uh Transcriber things for Windows so i- And I installed it on Dave Gelbart's P_C and it worked just fine. So hopefully that will work. Really? So is that - Because there's some people um - It would be cool if we could uh get that to work uh at - at S_R_I because the um - Yeah. Yep. Well we have m- m- We have more Windows machines to run the - Transcriber is Tcl-T_K  very generic with Snack  so basically anything you can get Snack to run on  it will work. Yeah. Right. Yeah. Yeah but - But the problem is the version Transcriber works with  the Snack version  is one point six whatever and that's not anymore supported. It's not on - on the web page anymore. But I just wrote an email to - to the author of - to the Snack author and he sent me to one point six whatever library and so it works. Well I thought it was packaged with Transcriber? Yeah  but then you can't add our patches and then Oh. the - the new version is - is totally different a- and in - yeah  in terms of - of the source code. You - you can't find the Tcl files anymore. It's some whatever wrapped thing and you can't - you can't access that so Ah. Mmm. you have to install - First install Tcl then install Snack and then install the Transcriber thing and then do the patches. Yeah. Patch. Ugh! I - I wonder if - if we should contribute our changes back to the authors so that they maintain those changes along - We have? Oh. Yeah. We have - Yeah b- it's just hasn't made it into the release yet. Oh  O_K. So did you um put the uh - the N_T version out on the uh Meeting Recorder page? Or - No  I haven't done that yet. I'm - oh Nope. But I definitely will do that. So  can some of the stuff that Don's talking about somehow fit into this Uh  mean you just have a set of numbers that are associated with the - Yeah. Yeah  it's basically ASCII files or binary files  whatever representation. Just three different - It's a waveform and So - just a stylized pitch vector basically so it's - So - So - Well - I mean we could do it in Matl- I mean you could do it in a number of different places I'm sure. But - But it would be cool if the Transcriber interface had like another window for the - you know  maybe above the waveform where it would show some arbitrary Yep. Yeah. valued function that is - that is you know time synchron- ti- Yeah  that'd be very cool. Yes. It'd be easy enough to add that. Again it's - it's It's more Tcl-T_ K programming. So someone who's familiar with Tcl-T_K has to do it  but uh  it wouldn't be hard to do. ti- time synchronous with the waveform. Yeah. Right. Right. But it would almost be like having another waveform displayed. S- Right. Mm-hmm. Yep. Yep. Yeah. Yeah  maybe we could l- look into that. Yeah. But it - it seems to me that And - I c- It doesn't seem like having that real time is that necessary. So yo- It seems to me you could do images. Um What do you mean by real time? Do you mean like - Like being able to scroll through it and stuff for the demo. O_K. Is that what you mean? Yeah. Yeah  jus- Yeah. It just seems to me jus- It would be cool to see it - It would be cool like to see - to hear it and see it  and see the pitch contours also. And to hear it. Yeah. Yeah. Yeah. Sure  but I don't think - I - You can do all that just statically in PowerPoint. I think it would lose - Yeah  I mean y- Just record the audio clip and show an image and I think that's - Right  right. I just thought if you meant slides I thought you meant like just like um view graphs or something. You know  wh- Yeah. So. Uh  no  we're talking about on the computer and - and um  I think when we were talking about this before we had littl- this little demo meeting  we sort of set up a range of different degrees of liveness that you could have Right. and  the more live  the better  but uh  given the crunch of time  we may have to retreat from it to some extent. So I think - For a lot of reasons  I think it would be very nice to have this Transcriber interface be able to show some other interesting signal along with it so it'd be a good thing to get in there. But  Mm-hmm. um - Anyway  jus- just looking for ways that we could actually show what you're doing  uh  Mm-hmm. in - to people. Cuz a lot of this stuff  particularly for Communicator  uh certainly a significant chunk of the things that we waved our arms about th- originally had t- had to do with prosodics It'd be nice to show that we can actually get them and Mm-hmm. Mmm. see them. And the last i- item on the agenda is disk issues yet again. So  we're doing O_K on backed up. We're - We're only about thirty percent on the second disk. So  uh  we have a little bit of time before that becomes critical  but we are like ninety five percent  ninety eight percent on the scratch disks for the expanded meetings. Yeah. And  my original intention was like we would just delete them as we needed more space  but unfortunately we're in the position where we have to deal with all the meeting data all at once  in a lot of different ways. Yeah. Oh there's a lot of transcribers  too. Yeah  there're a lot of transcribers  so all of those need to be expanded  and then people are doing chunking and I want to do uh  uh  Yeah. Mm-hmm. An- Right. uh  the permission forms  so I want those to be live  so there's a lot of data that has to be around. Um - And Jane was gonna talk to  uh  Dave Johnson about it. One of the things I was thinking is we - we just got these hundred - alright  excuse me - ten  uh SPARC-Blade Did they come in? SUN-Blades. They came in but they're not set up yet. And so it seems to me we could hang scratch disk on those SUN-Blades. Yeah. They came in the other day. Yeah. Oh. because they'll be in the machine room  they'll be on the fast connection to the rest of the machines. And if we just need un-backed-up space  we could just hang disks off them. Well  is there - Why not just hang them off of Abbott  is there a - Yeah. Because there's no more room in the disk racks on Abbott. Ah. Ah  I see. Weren't we gonna get - Well  maybe it should get another rack. But you still need to store the disks somehow. Well  but the SUN-Blades have spare drive bays. So - Just put them in. You can put two - Oh you mean you put them inside the pizza boxes for the - Internal. Yeah. Sure. Yeah. Oh. Cuz the SUN - uh  these SUN-Blades take commodity hard drives. So you can just go out and buy a P_C hard drive and stick it in. Mmm. But if Abbott is going to be our disk server it - it - file server it seems like we would want to get it  uh  a second disk rack or something. Plus we're talking about buying a second dis- uh  file server. Well  I mean there are lots of long term solutions. What I'm looking for is where do we s- expand the next meeting? Yep. I see Oh  I see. Well  for the next meeting you might be out of luck with those ten  mightn't you? Uh  you know Dave Johnson is gone for  like  ten days  Oh  I didn't know he had left already. Uh  well  tonight. Oh  oh well. You mean he won't set up the - mmm. How much space do you need for these? I don't know. I don't know what his schedule is. I'm just saying he's gone. You - we need about a gig per meeting. I - I thi- Yep. I have um - I have an eighteen gig drive hanging off of my computer. Alright! What's your computer's name? So - You had an eighteen gigabyte drive. Uh  Samosa. Yeah  I had. Well it's about - I think there's about twelve gig left. So it - And you have an X_ drives installed? O_K. Yeah. So  I didn't realize it was so critical. I mean I'm not doing anything on it right now until I get new meetings to transcri- or that are - new transcriptions coming in I really can't do anything. And you're o- you're offering? O_K. I - I jus- I just gave Thilo some - about ten gigs  the last ten gigs of space that there was on - on uh Abbott. Um not that I can't do anything  I jus- Uh - And uh - So but that - But - Which one was that  X_ G_? O_K. X_G. X_G. Yeah. X_G? That's also where we store the - The uh Hub-five training set waveforms  right? Oops. No. I don't think that's on X_G. On X_G is only Carmen and Du- and Stephane's disk. But that won't be getting any bigger  will it? Right. It's - Yeah. But I've also been storing - I've been storing the feature files there and I guess I can s- start deleting some because we now know what the best features are and we won't be using the old ones anymore. Well - Yeah  I do- I don't think it was on X_G. I th- I have a lot of space  though. Uh - Isn't that X_H? I have a lot of space and it's not - it's n- There's very little uh - Yeah not for long. But I mean it's not going f- It's not being used often at all. Not - not for long. Oh that's X_A - Oh that's X_ - Maybe I'm confu- Oh no I'm sorry. But I'm using X_H - H_  too. So. Yeah  it's probably - Probably only about four gig is on X_ - on your X_ drive  but we'll definitely take it up if you - Oh O_K. I th- I think you're right. It's X_H and D_ - The b- I'm also using D_G I got that confused. O_K. I think it's about four or five gig cuz I have four meetings on there  three or four meetings. Great. So. We need - O_K  so that will get us through the next couple days. We need another gigaquad. Yep. At least. O_K. There should - I d- There should just be a b- I should have a button. Just press - Press each meeting saying ""we need more disk space"" ""this week"". Skip the rest of the conversation. The ""more disk space"" button? Yep. Well we've collected so far something like uh sixty-five meetings. And - And how much does each meeting take? And it's about a gig uncompressed. It's - It's a little bit more as I usually don't - do not uncompress the - all of the P_Z_M and the P_D_A things. So. Is a little more? Right  yeah so if you uncompressed everything it's even more. U- Uh compressed how much are they? Like - It's - Yeah. One point five or something. Half a gig. For all of them. About half? Yeah. Yeah. Yep. So we're definitely are storing you know  all of those. So there's what thirty some gig So- so- So maybe there's a hundred gig or something. Or - of just meetings so far? Mm-hmm. I mean. Cuz we - we have the uncompressed around also. So it's like - Right. Right. Well we - We haven't uncompressed all the meetings  but - Yeah. I would like to. Yeah. Well I mean it's - the- they really are cheap. I mean it's just a question of figuring out where they should be and hanging them  but Right. Yep. But uh  we could - You know  if you want to get four disks  get four disks. I mean it's - it's small - I mean these things ar- are just a few hundred dollars. Yeah. Well I sent that message out to  I guess  you and Dave asking for - if we could get some disk. I s- I sent this out Yeah. And put it where? Right. a - a day ago but - and Dave didn't respond so I don- I don't know how the whole process works. I mean does he just go out and get them and - if it's O_K  and - Yep. So I was assuming he was gonna take over that. But he's probably too busy given that he's leaving. Yeah  I think you need a direct conversation with him. And just say an-e- just ask him that  you know  wha- what should you do. And in my answer back was ""are you sure you just want one?"" So I mean I think Yeah. that what you want to do is plan ahead a little bit and figure ""well  here's what we pi- figure on doing for the next few months"". Wa- a- I know what they want. The sysadmins would prefer to have one external drive per machine. So they don't want to stack up external drives. Yeah. Um - And then they want everything else in the machine room. Right. So the question is where are you gonna hang them? Mm-hmm. I don't know what the space situation is in the machine room. Right. So. Right. So this is a question that's pretty hard to solve without talking to Dave  cuz it - Th- The - I think part of the reason why Dave can't get the - the new machines up is because he doesn't have room in the machine room right now. So he has to re- arrange a bunch of stuff. One - Mmm. Yep. One - One On- One thing to in- to um t- to do when you need to conserve space is I bet there are still some old  uh  like  nine gig disks  uh  around and you can probably consolidate them onto larger disks and - and you know recover the space. Yep. Yeah. No. I think Dave - Dave knows all these things  of course. An- and so  he always has a- a lot of plans of things that he's gonna do to make things better in many ways an- and runs out of time. Right. Mm-hmm. But I - I know that generally their first priority has been for backed up disk. And so I think what he's been concentrating on is uh Mmm. the back - the back up system  rather than on new disk. So. Mmm. Well. So. But this - this is a very specific question for me. Basically  we can easily get Which - one to four disks  I mean you just go out and get four and we've got the money for it  it's no big deal. Uh  but the question is where they go  and I don't think we can solve that here  you just have to ask him. Maybe we can put some disks in the - in that back room there. Yeah really. Attach to - Popcorn. To the machine that collects the data. So then you could  at least temporarily  store stuff there. The only - Yeah? Hmm. Yeah  it's just - It's not on the net  so it's a little awkward It's not - What do you mean it's not on the net? It's not bad. It's behind lots of fire walls that don't allow any services through except S_S_H Yep. Oh because it's - because it's an ACIRI machine? Oh  oh oh. Yeah. And also on the list is to get it into the normal ICSI net  but Who knows when that will happen? That might be a good But that can't be that hard. I mean - short term solution  though. No  the - the problem with that apparently is that they don't currently have a wire running to that back room that goes anywhere near one of the ICSI routers. Oh  hhh. So  they actually have to run a wire somewhere. @@ Yeah. Yeah  e- again  you know  any one of these things is certainly not a big deal. If there was a person dedicated to doing it they would happen pretty easily but it's - it's - jus- every- ever- everybody - everybody has a - has - But Dave has to do all of them. Well all of us have long lists of different things we're doing. But at any rate I think that there's a - there's a longer term thing and there's immediate need and I think we need a - a conversation with - Uh  maybe - maybe after - after tea or something you and I can go down and - and talk to him about it Just say ""wha- you know  what should we do right now?"" How long is David gonna be gone? Uh  eleven days or something? Oh my! Yeah basically tomorrow and all of the week after. And that's all I have. Um - Let's see. The only oth- thing - other thing I was gonna add was that um - uh  I talked briefly to Mari and uh we had both been busy with other things so we haven't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the Friday after next. And I - I - I wanted to make it  um after the next one of these meetings  so something that we wanna do next meeting is - is uh to put together um  a kind of reasonable list for ourselves of what is it  um  that we've done. I mean just sort of bulletize I mean o- e- do- do- I can - I can dream up text but this is basically gonna lead to the annual report. So Um - If w- Mm-hmm. This is the fifteenth? Um  that would So just a week from tomorrow? O_K. Yeah. Yeah. So  uh  we can - This - So that's an - Is this gotta be in the morning? Um - Or - Because you know I - Fridays I have to leave uh like around uh two. So if it could be before that would be be- No  no but I - I - I don't need other folks for the meeting. I can do it. A- A- All I'm saying is that on - Oh  O_K  alright. Oh I'm sorry  I misunderstood. I thought you are - Yeah so what I meant was on the me- this meeting O_K. if I wa- something I - I - I'm making a major thing in the agenda is I wanna help in getting together a list of what it is that we've done so I can tell her. Alright. Mm-hmm. I think I have a pretty good idea but - but um - O_K. Uh  and then the next day uh  late in the day I'll be having that - that discussion with her. Mmm. Um. So. Um - Uh - One thing - I mean - we - in past meetings we had um also a- you know various - variously talked about the um work that w- uh was happening sort of on the - on the recognition side um but isn't necessarily Mm-hmm. related to meetings uh specifically. So. Um. And I wondered whether we should maybe have um a separate meeting and between you know  whoever's interested in that because I feel that uh there's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh - Think so? Well  it's that - It's just gonna be ver- very boring for people who are not you know  sort of really interested in the details of the recognition system. I'm interested. Me too. Well  O_K  so how many - how many people here would not be interested in uh - in a meeting about recognition? w- Jane may not be. Jane  I think. Well I know - Well  Jane an- Yep. Well you mean in a separate meeting or ha- ha- talking about it in this - No. If we talked about it in this meeting. He's wondering how much overlap there will be. Yeah  so you're su- So. O_K. So  uh  uh  Liz and Jane probably. O_K  so we're gonna have a guy's meeting. Uh. Good thing Liz isn't here. Real - Uh  if you wanna put it that way. Watch a ball game? Wh- Don't listen to this  Liz. Yeah  real - real - real men ""Real men do decoding"" or something like that. Right. Uh. I mean it- it's sort of - Yeah. I mean when - when the talk is about data collection stuff  sometimes I've - The - Nod off? you know  I - I'm bored. So it's I c- I can sympathize with them not wanting to - It's cuz y- you have a - i- to - to be uh - you know - If - I cou- you know - this could - So you need a better developed feminine side. I'm not sure I wanna - There's probably gonna be a lot of ""bleeps"" in this meeting. Yeah  I would as- I would guess. Uh. Yeah and - Um. I think it must be uh nearing the end of the week. Um. Yeah. I - You know  I - I've heard some comments about like this. That m- could be. I mean the - Um. Mm-hmm. And we don't have to do it every week. We could do it every other week or so. You know  whatev- or whenever we feel like we - Could we - Right  I was - Why don't we alternate this meeting every other week? Or just alternate the focus. U- Tha- That's what I mean. Yeah  so on even weeks have basic on data. Yeah. We could do that  yeah. Yeah. I - I - Personally I'd - I'm not in favor of more meetings. Um. Right. Because  uh. You know. I am. Oh sor- But I do- I don't - I mean a lot of times lately it seems like we don't really have enough for a full meeting on Meeting Recorder. So if we did that - Right. Well  except that we keep going for our full time. Yep. Well  cuz we get into these other topics. Yeah. We feel - We feel obligated to collect more data. Yeah. Yeah. Ugh. So if we could alternate the focus of the meeting - I don't. Let's read digits and go. Why don't we just start with that. And then if we find  you know we're just not getting enough done  there's all these topics not coming up  then we can expand into another meeting. But I - I think that's a great idea. ummh. ummh. O_K. Mm-hmm. Uh. So uh. Um. Let's chat about it with Liz and Jane when we get a chance  see what they think and - Mm-hmm. Yeah that would be good. I mean Andreas and I have various talks in the halls and there's lots of Mm-hmm. things  you know  details and stuff that would I think people'd be interested in and I'd - you know  where do we go from here kind of things and - So  it would be good. Yeah  and you're - you're attending the uh - the front-end meeting as well as the others so you have - you have probably one of the best - you and I  I guess are the main ones who sort of see the bridge between the two. We are doing recognition in both of them. So. Bridge. Mm-hmm. Mm-hmm. Right. Uh. So um. O_K? So - so we could talk a little bit about that now if - if there's some time. No  no that would be for next week. Um I jus- So the latest result was that um um yot I tested the uh - the sort of final version of the P_L_P configuration um on development test data for - for this year's Hub-five test set. Mm-hmm. And the recognition performance was exactly  and I mean exactly up to the - you know  the first decimal  same as with the uh Mel Cepstra front-end. Mmm. For both females and males? Yes. Oh! Uh  well i- there was a little bit of a - i- overall. They - They were - The males I think were slightly better and the females were slightly worse but nothing really. I mean definitely not significant. Mm-hmm. Mm-hmm. Mm-hmm. And then the really nice thing was that if - if we combine the two systems we get a one and a half percent improvement. Wow. So. Just with ROVER? t- With N_best ROVER  which is like our new and improved version of ROVER. Mm-hmm. Which u- actually uses the whole N_best list from both systems to mmm  uh c- combine that. So except - I mean the only key difference between the two really is the kind of smoothing at the end which is the auto-regressive versus the Yeah. cepstral truncation. O_K. And  the - But a percent and a half? That's - Yeah  it's pretty impressive. And - And so uh after I told the - my uh colleagues at S_R_I about that  you know  now they definitely want to  you know  uh  have a - Next time we have an evaluation they want to do uh  you know  basically a- at least the system combination. Um  and  you know  why not? Uh. So. Sure  why not? We clearly gotta add a few more features  though. Uh w- what do you mean? More features in the sense of front-end features or in the sense of just bells and whistles? No  uh front-end features. You know we did P_L_P and Mel Cepstra. Let's  you know  try RASTA and M_S_G  and - Oh I mean - Yeah. Well Right. So  we cou- Yeah. That's - the - the the - There's one thing uh - I mean you don't want to overdo it because y- every front-end - You know  if you - you know you basically multiply your effort by N_  where N_ is a number of different Oh. systems and - Um. So. Mm-hmm. So one - one compromise would be to - only to have the - everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that's a fairly painless um thing. So. Mmm. An- Do you think we'd still get the one and a half uh - I - I think so. Yeah. Maybe a little less because at that point the error rates are lower and so if - You know  maybe it's only one percent or something but that would still be worthwhile doing. Mm-hmm. So. Um Jus- You know  just wanted to let you know that that's working out very nicely. Cool. And then we had some results on digits  uh  with um - We - We - So this was uh really - really sort of just to get Dave going with his um experiments. And so  Mm-hmm. uh. But as a result  um  you know  we were sort of wondering why is the Hub-five system doing so well on the digits. And the reason is basically there's a whole bunch of read speech data in the Hub- five training set. And you c- Right. Right. Including digits I gather  yeah. And - Not all of - No it's actually  digits is only a maybe a fifth of it. The rest is - is read - is read TIMIT data and uh ATIS data and Wall Street Journal and stuff like that. A fifth of it is how much? Right. But a fi- a fifth is how much? A fifth would be maybe uh two hours something. Yeah  so I mean that's actually not that different from the amount of training that there was. So. Right. But it definitely helps to have the other read data in there because we're doing - Oh yeah w- You know the error rate is half of what you do if you train only on ti- uh TIMIT - uh not TIMIT uh T_I- digits  which is only what two hours something? Mm-hmm. Right. I don't know. So. Uh  more read speech data definitely helps. And you can leave out all the conversational data with no performance penalty. That's e- That was e- Right  right. Yeah that was the interesting thing. Because - because uh  it was apparent if you put in a bunch more data it would be better  but - but uh. Right. Well is there even more read speech data around? Oh  yeah. So we only - for the Hub-five training  we're only using uh a fairly small subset of the Macrophone database. Mm-hmm. Um  so  you could beef that up and probably do even better. I could also put in uh Mm-hmm. focus condition zero from Hub-four from Broadcast News  which is mostly prepared speech. It's not exactly read speech but it's pretty darn close. Yeah. Yeah. Right. Well  I mean that's plenty of read speech data. I mean  Wall Street Journal  uh  take one example. Yeah. That's right. But um. So  you know that might be useful for the people who train the - the digit recognizers to - to use uh something other than T_I-digits. Yeah. Well they been using TIMIT. O_K. That - Uh. They - they uh - they experimented for a while with a bunch of different databases with French and Spanish and so forth cuz they're multilingual tests and - and uh  Mm-hmm. um  - and actually the best results they got wa- were uh using TIMIT. Hmm. Uh - But uh - which - So that's what they're - they're using now. But - but yeah certainly if we  Mmm. um - If we knew what the structure of what we're doing there was. I mean there's still a bunch of messing around with different kinds of uh noise robustness algorithms. So we don't know exactly which combination we're gonna be going with. Mm-hmm. Mm-hmm. Once we know  then - the trainable parts of it - it'd be great to run lots of - lots of stuff through. Mm-hmm. Right. Well  that was that. And then I th- guess Chuck and I had some discussions about how to proceed with the tandem uh system and - You wanna - You wanna see where that stands ? @@ Well  I'm - Yeah  so Andreas uh brought over the uh alignments that the S_R_I system uses. And so I'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with. And uh so then I'll train the net. And. An- And one side effect of that would be that it's - um that the phone set would change. So the M_L_P would be trained on I think only forty-six or forty-eight - forty-eight phones? Right. Eight. Mm-hmm. Uh which is smaller than the um than the phone set that - that we've been using so far. Yeah. And that - that - that will probably help  actually  because So it's a little different? um the fewer dimensions uh e- the less trouble probably with the - as far as just the um  um - Just - You know we want to try things like deltas on the tandem features. And so you h- have to multiply everything by two or three. And so  you know  fewer dimensions in the phone set would be actually helpful just from a logistics point of view. Sure. Although we - I mean  it's not that many fewer and - and - and we take a K_L_T anyway so we could - Yeah. Right. Exactly. So - so that was the other thing. And then we wanted to s- just limit it to maybe uh something on the same order of dimensions as we use in a standard um front-end. So that would mean just doing the top I don't know ten or twelve or something of the K_L_T Yeah  and I think - and we sh- again check - we should check with Stephane. My impression was that when we did that before that had very little - uh he didn't lose very much. dimensions. Right. By just taking the top whatever? Yep. Yeah yeah. But then - And then something - Once we have the new M_L_ P trained up  uh one thing I wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know  those features uh and uh retrain M_L_P and also the you know  the dictionary that we use for the Hub- five system. And the b- And the base u- starting off with the base of the alignments that you got from i- from a pretty decent system. Exactly. Right. Yeah. So Yeah. that would basically give us a  um  more - hopefully a - a better system um because - you know  compared to what Eric did a while ago  where he trained up  I think  a system based on Broadcast News and then uh tra- retraining it on Switchboard or s- uh and - Yeah. But he - I think he d- he didn't - he probably didn't use all the training data that was available. And his dictionary probably wasn't as tuned to um conversational speech as - as the - as ours is. So. That's - That's certainly one thing  yeah. Uh. And the dictionary made a huge difference. Uh. We - we made some Yeah. improvements to the dictionary's uh - to the dictionary about two years ago which resulted in a - uh something like a four percent absolute error rate reduction on Switchboard  which - Well the other thing is  dipping deep into history and into uh our resource management days  Mm-hmm. when we were collaborating with S_R_I before  uh Mmm. Mm-hmm. it was - I think  it is was a really key uh starting point for us that we actually got our alignment. When we were working together we got our initial alignments from Decipher  Mm-hmm. uh at the time. Uh. Yeah. Yeah. And. Later we got away from it because - because once we had decent systems going Mm-hmm. then it was - it was typically better to use our own systems cuz they were self- consistent but - but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate. Uh. But that was a - that was a good - good - good way to start. Yeah. And we're not quite that bad with our - our Switchboard systems but it was - they certainly aren't as good as S_R_I's  so - O_K. Yeah. W- What is the performance on s- the best Switchboard system that we've done? Right. Roughly? Well  the hybrid system we never got better than about fifty percent error. And uh it was - I think there's just a whole lot of things that uh no one ever had time for. We never did really fix up the dictionary. Uh we always had a list of a half dozen things that we were gonna do and - and a lot of them were pretty simple and we never did. Yeah. Mmm. But that w- Even that - that number - Uh  we never did an- never did any adaptation uh  we never did any - Right. And - And that number I think was on Switchboard-one data  right? Where the error rate now is in the twenties. So  um. Yeah. Yeah. So we were - Yeah. We were That's yet s- probably at least a factor or two off. Right. Yeah. So it would be - So it would be good t- to sort of r- re- uh - just at least to give us an idea of how well the hybrid system would do. Yeah. Yeah. But I think - again it's - Yeah. It's the conver- it's the s- conversational speech bit. Because our - our Broadcast News system is actually pretty good. He knows . Mm-hmm. Right. And the other thing that that would help us to evaluate is to see how well the M_L_ P is trained up. Right? Because it's a pretty good um Mm-hmm. indicator of that. So it's sort of a sanity check of the M_L_ P outputs before we go ahead and train up the - uh you know  use them as a basis for the tandem system. Mm-hmm. Yeah. It'll still probably be worse. I mean  it's - it'd be context independent and so on. But. No. Sure. Should we - Should we bother with um using the net Not - But - before doing uh embedded training? I mean should - should we even use that? Or should I just go straight to - Oh oh that's a good question. Yeah  we - we weren't sure whether it's worth to just use the alignments um from the S_R_ I recognizer or whether to actually go through one or more iterations of embedded training where you realign. Try it. You run it? Keep - keep both versions? See which one's better? Uh  yeah. I mean. I think I agree with Ad- I mean basically you would then - You proceed with the embedded training. It's gonna take you a while to train at this net anyway. And while it's training you may as well test the one you have and see how it did. Mm-hmm. Mm-hmm. Right. O_K. Mmm. Alright. I could make arguments either way. You know  it's - Sort of given up guessing. But - But so I - Well but i- But in your experience I mean uh have you seen big improvements in s- on some tasks with embedded training? Or was it sort of small-ish uh improvements that you got- Uh well. It depended on the task. I mean I think in this one I would sort of expect it to be important because we're coming from Right. uh  alignments that were achieved with an extremely different system. That are from another - Right. Right. Although  Uh. I mean we've done it with - When we were combining with the Cambridge recurrent neural net  embedded training made it worse. Which I've never figured out. Right. But I mean i- I think it's a bug. So you - you started training with outputs from a - with alignments that were generated by the Cambridge uh system? Yep. And then - Uh. Hmm. Yeah. Yeah. Well  that might probably just - Hmm. That was probably because your initial system - I mean your system was ba- worse than Cambridge's. And you - Um. Was it? I don't think it was. No they were - they were comparable. It wasn't? No. Really? They were very close. Yeah. That's weird. Excuse me? That's - That's weird. That's what I said. Oh! No I mean it's weird that it did - I'm sorry. It's w- It's weird that it got worse. That's ambiguous. Um. No. Uh. Tha- u- we- we've see- I mean - and wi- with the numbers - O_G_I numbers task we've seen a number of times people doing embedded trainings and things not getting better. Oh actually it's not that weird because we have seen - We have seen cases where acoustic - retraining the acoustic models after some other change made matters worse rather than better. Yeah. It just - Yeah. But I- But I would - I would suspect that something that - that had um a very different Um feature set  for instance - I mean they were using pretty diff- similar feature sets to us. Yep. I - I would expect that something that had a different feature set would - would uh benefit from - Mm-hmm. What about uh hidden unit size on this. Oh. Oh  wait a minute  and the other thing uh  sorry  it was - the other thing is that what was in common to the Cambridge system and our system is they both were training posteriors. Right. So I mean  uh  that's another pretty big difference and Ah yeah. That's another big difference. uh  one bac- at least - Back at - You mean with soft targets? Or - ? Sorry  I'm sor- I missed - What - What's the key issue here? Oh  that uh both the Cambridge system and our system were - were training posteriors. And if we're - we're coming from alignments coming from the S_R_I system  it's a likelihood-based system. So - so that's another difference. I mean. You know  there's diffe- different front-end Yeah. different - different uh  um  training criterion - Uh  I would think that in a- that an embedded uh embedded uh training would have at least a good shot of improving it some more. But we don't know. Mm-hmm. O_K. You gonna say something? Yeah. I was wondering uh you know what size net I should - Anybody have any intuitions or suggestions? Uh  how much training data? Well  I was gonna start off with the small train set. And how - How many hours is that? That's why I was - I - I'm not sure how much that is. Uh  I think that has about - Well i- you'd - would be gender-dependent training  right? So - So I think it's - uh that's about Gender-dependent  yeah. mmm  something like thirty hours. Thirty hours. Thirty hours per gender. I'm not sure what this'll mean. In the small training set? I - I think so. I'll - Hello? Excuse me? It's definitely less than a hundred - You know  it's more like - Alright. like thirty forty hours something like that. Wrong number. They called to tell us that? Yeah. Yeah. Um. So. Uh. I mean  I didn't want to do too big  just - after run- Right. So At least a couple thousand hidden units. Mm-hmm. I mean. It's - it's th- the thing I'll - I'll think about it a little more but it - it'd be toss up between two thousand and four thousand. Mmm. You definitely wouldn't want the eight thousand. It's m- It's more than - And a thousand is too small? Oh let me think about it  but I think that - that uh th- at some point there's diminishing returns. Mm-hmm. I mean it doesn't actually get worse  typically  but it - but - but there is diminishing returns and you're doubling the amount of time. Mm-hmm. Remember you'll have a smaller output layer so there's gonna be fewer parameters there. And then - But not by a lot. Not by much. Fifty s- Fifty four to forty eight? Vast majority is from the input unit. O_K. Yeah. Yeah. Yeah. It'll have a very tiny effect. Right  because you used the context windows and so the input to hidden is much  much larger. Yeah. Oh I see  I see  yeah  of course. Yeah. It's negligible  O_K. Yeah. Yeah  so it's - it'd be way  way less than ten percent of the difference. Uh-huh. Uh. There's uh - How bi- how big Let's see. What am I trying to think of? The - The net that - that we did use already uh was eight thousand hidden units and that's the one that Eric trained up. Right. And that was trained up on uh like a hundred and forty hours of - of speech. Was that gender- dependent or independent? Gender- dependent. Oh. So that would be like trained on s- sixty or seventy hours. Mm-hmm. So  uh  yeah definitely not the one thousand uh - two thousand fr- I mean the four thousand will be better and the two thousand will be almost - will be faster and almost as good. So. It'll be faster. Yeah. Maybe I'll start off with two thousand just Mm-hmm. Yeah. to see. O_K. O_K. Yeah  thirty hours is like a hundred and ten thousand uh seconds. Uh  so that's like eleven - eleven million frames. And a two thousand hidden unit net is uh I guess about seven  eight hundred thousand parameters. So that's probably - That's probably fine. I mean a four thousand is well within the range that you could benefit from but the two thousand'd be faster so - Right. I actually have to go. So. Alright. Uncle Bernie's rule is ten to one. Bernie Woodrow's Rule of - yeah - Uncle Bernie - yeah. Yeah. I figured. Read your digits. Yes sir. We're just waiting for you to leave. @@ Anything else? Nah. Since we have nothing to talk about we only talked for an hour. So. O_K. If - yeah that's right. Yeah. Uh  well  we started late. Uh transcript L_ one seven seven three  zero one five  four seven  five four eight  eight seven  zero seven zero  uh  eight nine  zero eight seven  seven two eight six  five four seven  six one eight two seven nine  four six seven  nine eight four four two six four nine  two O_ eight nine  two six eight two one seven  seven seven  three zero  one seven  four four one eight seven  nine two four  eight nine O_ six five six  nine seven one  three three seven six. Transcript L_ dash one seven eight zero four nine  nine six four  three three zero seven five  two eight one  six seven  eight nine seven  one zero four  seven nine  seven one  nine five  three one one zero one  eight eight  three six one three four seven six  nine nine  four two five nine three three  zero one  four zero  five seven  three eight four nine eight  six seven  zero nine five four zero zero nine three seven four nine seven. Transcript L_ one seven nine. six nine one  two three three  three six seven two six  one one  zero one  eight nine  zero nine six O_ six  seven nine  eight three four six four O_ three  two two six  four six nine six five two  five two seven  six four zero six two eight two  nine zero four  zero zero two five five eight O_ five  five three seven two  five three O_ two six seven one two  four  two four five. Transcript L_ ninety eight. nine zero  six zero  five four  four six  one eight four eight two nine  four three two four  three five seven eight seven nine six  four four four  three zero two five six one five two  three  four three four one six  three three  nine three  five four  zero seven seven one one  zero eight four  nine zero one one four seven four  nine eight  nine six zero eight one two five  three six eight  six six one one. Transcript L_ dash one three nine. zero nine five  three four five  five nine seven one nine  seven nine five  one two  four nine three  eight five four  two eight  seven four  six one  five three one three six eight  nine  nine eight eight eight five nine nine  one  one eight seven six two five one  six zero six five  zero eight six one six eight zero  two one nine  seven zero nine nine eight two  nine four nine  four seven seven. de-ba-de. de-ba-de @@ That's all folks! ","A test run of the data collection design was very successful. The group decided to hire the ""wizard"" and continue with the refinement of the design and recruitment of subjects. On the other hand  there was a presentation of a new version of the belief-net for the Vista/Enter/Tango mode task. It is not a working net yet  but identifying clusters of features that define the output mode provides a visual aid for further work. There are potential problems from a combinatorics perspective. These can be tackled either with technical adjustments or through careful knowledge engineering. A base solution for the task would be to simply add some extra action-mode rules in the SmartKom system. Action modes  however  can be inferred more efficiently by feeding a collection of features -from the ontology  discourse history  parsing  etc.- into Bayes-nets that would replace those rules. Ideally  the results of this small task will give insights into the function of linguistic deep understanding. For instance  the final combination of features used in the current study may form a representation of the ontology  general enough to employ in any task that includes trajectors and paths. Although the data collection test went well and it was decided to hire the ""wizard""  there are minor amendments in the procedure to be carried out (shortenting the preparatory reading  numbering tasks etc). A presentation of the data collection design should be included in the forthcoming meeting with other research groups  along with some account of the system design and the use of belief-nets. The structure of the latter was a major issue during the meeting. Their input vector is to be provided by information extracted from the various modules of the system  such as the ontology and discourse history  using standard rule-based methods. The output action essentially provides additional semantic parameters for the X-schema  and  in turn  may trigger the collection of more features from the data. The feature extraction could be carried out by a software tool checking object (feature) trees and filling them with appropriate values. For this concept to be put to work  further refinement of the belief-net variables is necessary  with particular attention on the combinatorics involved. After the trial run of the experiment  some minor issues  like the length of the preliminary reading and the need to order the tasks given to the subjects  were highlighted. It is also possible that the pool of subjects ends up comprising almost entirely of students; more variation in the sample is needed. From a system design perspective  the progress so far has shown that the combinatorics of the Bayes-net even for a simple task  like the choice of Vista/Enter/Tango mode  could render it unmanageable. The belief-net presented in the meeting is not a working Bayes-net. Consequently  it is as yet unclear what the decision nodes in the net are  and what values these can take. Even if those were decided  how to extract the necessary information from the data  would still be an open issue. Looking at the bigger picture  the current task is yet to provide insights into more general ways to achieve linguistic deep understanding. With these intricacies in mind  it is not easy to put together a presentation of the project cohesive and attractive enough for the other research groups in the institute. The first trial run of the experiments was very successful. After reading some information on a city  the subject  acting as a tourist  has to ask for information over a phoneline in order to carry out certain tasks. A ""wizard"" on the other side of the line pretends to be a computer system for half of the duration. For the second half the subject is aware of communicating with another human. In parallel to the data collection  there was further work on the belief-net for the inferences currently studied. The features determining the output mode (Vista  Enter or Tango) of the belief-net have been grouped in categories: Trajector  Landmark  Source  Path  Goal  Parse  Prosody  World knowledge  Discourse and Context. Every particular feature  like ""time of day""  ""being in a hurry""  ""business or tourism""  etc  will fit into on these categories. Although the presented net is not a working Bayes-net yet  it serves as a visual aid and stepping stone for the work to follow. "
"O_K. @@ Adam  what is the mike that  uh  Jeremy's wearing? It's the ear-plug mike. That's good. Ear-plug. Is that a wireless  or - ? No. Oh. It's wired. Oh! Is that - Does that mean you can't hear anything during the meeting? It's old-school. What? Huh? What? Huh? Should we  uh  close the door  maybe? So it's - Yeah. It - it's a fairly good mike  actually. Huh. Well  I shouldn't say it's a good mike. All I really know is that the signal level is O_K. I don't know if it's a - the quality. Well  that's a Ugh! necessary - So I didn't send out agenda items because until five minutes ago we only had one agenda item and now we have two. So. And  uh. O_K. So  just to repeat the thing bef- that we said last week  it was there's this suggestion of alternating weeks on more  uh  automatic speech recognition related or not? Was that sort of the division? Right. So which week are we in? Well - We haven't really started  but I thought we more - we more or less did Meeting Recorder stuff last week  so I thought we could do  uh - I thought we had a thing about speech recognition last week too. Yeah. But I figure also if they're short agenda items  we could also do a little bit of each. So. Yeah. I seem to be having difficulty getting this adjusted. Here we go. O_K. So  uh  as most of you should know  I did send out the consent form thingies and  uh  so far no one has made any - Ach! any comments on them. So  no on- no one has bleeped out anything. Um. So. Yeah. @@ Um. I don't expect anyone to. But. So  w- what follows? At some point y- you go around and get people to sign something? No. We had spoken w- about this before and we had decided that they have - they only needed to sign once. Yeah  but I've forgotten. And the agreement that they already signed simply said that we would give them an opportunity. So as long as we do that  we're covered. And how long of an opportunity did you tell them? Uh  July fifteenth. July fifteenth. Oh  so they have a- plenty of time  and y- Yep. Given that it's that long  um  um - Why was that date chosen? You just felt you wanted to - ? Jane told me July fifteenth. So  that's what I set it. Oh  O_K. Oh. I just meant that that was the release date that you had on the data. @@ Oh. I - I didn't understand that there was I  uh - something specific. You - y- you had - I thought - I don't - I had heard July fifteenth  so that's what I put. So. No  the only - th- the only mention I recall about that was just that July fifteenth or so is when Mm-hmm. this meeting starts. That's right. That's why. Oh  I see. You said you wanted it to be available then. I didn't mean it to be the hard deadline. It's fine with me if it is  or we cou- But I thought it might be good to remind people two weeks prior to that O_K. Right. w- in case  uh - you know  ""by the way this is your last -"" Right. Uh. Yeah. We probably should have talked about it  cuz i- because if we wanna be able to give it to people July fifteenth  if somebody's gonna come back and say ""O_K  I don't want this and this and this used""  uh  clearly we need some time to respond to that. Right? Yeah. As I said  we - I just got one date and that's the one I used. So. But I can send a follow-up. I mean  it's almost all us. Damn! Yeah. Yeah. I mean the people who are in the meeti- this meeting was  uh  these - the meetings that - in - are in set one. Was my - was my response O_K? I just wrote you - replied to the email saying they're all fine. That's right. Right. I mean  that's fine. O_K  good. I - we don't - My understanding of what we had agreed upon when we had spoken about this months ago was that  That makes it easy. uh  we don't actually need a reply. We just need to tell them that they can do it if they want. O_K. I just didn't remember  but - And so no reply is no changes. And he's got it so that the default thing you see when you look at the page is ""O_K"". O_K. So that's very clear all the way down the page  ""O_K"". And they have two options they can change it to. One of them is ""censor""  and the other one is ""incorrect"". Is it - is - your word is ""incorrect""? Which means also we get feedback on if um  there's something that they w- Right. that needs to be adjusted  because  I mean  these are very highly technical things. I mean  it's an added  uh  level of checking on the accuracy of the transcription  as I see it. But in any case  people can agree to things that are wrong. So. Well - Yeah. The reason I did that it was just so that people would not censor - not ask to have stuff removed because it was transcribed incorrectly  And the reason I liked it was because - as opposed to  uh - was because it  um - it gives them the option of  uh  being able to correct it. Right. Approve it and correct it. And um. So  you have it nicely set up so they email you and  uh - When they submit the form  it gets processed and emailed to me. Mm-hmm. Mm-hmm. And I wanted to say the meetings that are involved in that set are Robustness and Meeting Recorder. So. The German ones will be ready for next week. Those are three - three of those. A different set of people. And we can impose - The German ones? Uh  well. Yeah. Those - uh - N_S_A. O_K. I spoke loosely. The - the German  French - Sorry  the German  Dutch  and Spanish ones. Spanish. Yeah. Mm-hmm. Oh  those are the N_S_A meetings? Those are - The non-native - Yeah. Uh-huh. German  Dutch  Swiss and Spanish. Oh  oh! O_K . That's - that's - that's r- The all non-native - Mm-hmm. Uh-huh. O_K. I'd - I d- Yeah. It's the other group. I- It was the network - network services group. Yeah. O_K. Uh-huh. Yeah  exactly. Yeah. I didn't mean to isolate them. Otherwise known as the German  Dutch  and Spanish. Yeah. Sorry. It was - it was not the best characterization. But what - Mm-hmm. what I meant to say was that it's the other group that's not - n- no m- no overlap with our present members. And then maybe it'd be good to set an explicit deadline  something like a week before that  uh  J- July fifteenth date  or two weeks before. I mean  I would suggest we discuss - I mean  if we're going to have a policy on it  that we discuss the length of time that we want to give people  Mm-hmm. so that we have a uniform thing. So  tha- that's a month  which is fine. I mean  it seems - Well  the only thing I said in the email is that the data is going to be released on the fifteenth. I didn't give any other deadline. Twelve hours. Mm-hmm. So my feeling is if someone after the fifteenth says  ""wow I suddenly found something""  we'll delete it from our record. We just won't delete it from whatever's already been released. Hmm. That's a little bit difficult. What else can we do? Yeah. If someone says ""hey  look  I found something in this meeting and it's libelous and I want it removed"". What can we do? We have to remove it. Well. That's true. I - I agree with that part  but I think that it would - it  uh - we need to have  uh  a - a - a message to them very clearly that beyond this date  you can't make additional changes. I mean  um  I - I - i- I think that somebody might request something even though we say that. But I think it's good to at least start some place like that. So if we agreed  Mm-hmm. Good. O_K  how long is a reasonable amount of time for people to have - if we say two weeks  or if we say a month  I think we should just say that - say that  you know  i- a- as um  ""per the - the - the  uh  page you signed  you have the ability to look over this stuff"" and so forth ""and  uh  because we w-"" these  uh - I would - I would imagine some sort of generic thing that would say ""because we  uh  will continually be making these things available to other researchers  uh  this can't be open-ended and so  uh  uh  please give us back your response within this am- you know  within this amount of time""  whatever time we agree upon. @@ Well  did you read the email and look at the pages I sent? Did I? No  I haven't yet. No  just - No. O_K  well why don't you do that and then make comments on what you want me to change? No  no. I'm not saying that you should change anything. I- I'm - what I'm - what I'm - I'm trying to spark a discussion hopefully among people who have read it so that - that you can - you can  uh  decide on something. So I'm not telling you what to decide. Mm-hmm. Mm-hmm. I'm just saying you should decide something  and then - I already did decide something  and that's what's in the email. And if you disagree with it  why don't you read it and give me comments on it? O_K. Yeah  yeah. O_K  so - Yeah. Well - @@ I - I think that there's one missing line. Well  the one thing that I did read and that you just repeated to me was that you gave the specific date of July fifteenth. Mm-hmm. And you also just said that the reason you said that was because someone said it to you. Right. So what I'm telling you is that what you should do is come up with a length of time that you guys think is enough and you should use that rather than this date that you just got from somewhere. That's all I'm saying. O_K. O_K? I ha- I have one question. This is in the summer period and presumably people may be out of town. But we can make the assumption  can't we? that  um  they will be receiving email  uh  most of the month. Right? Because if someone - It - well  it - well  you're right. Sometimes somebody will be away and  uh  you know  there's  uh - for any length of time that you uh  choose there is some person sometime who will not end up reading it. O_K. That's - it's  you know  just a certain risk to take. S- so maybe when - Am I on  by the way? I don't know. Oh. Hello? Hello? You should be. @@ You should be channel B_. Oh  O_K. Alright. So. The  um - Maybe we should say in - w- you know  when the whole thing starts  when they sign the - the agreement that - you know  specify exactly uh  what  you know  how - how they will be contacted and they can  you know - they can be asked to give a phone number and an email address  or both. And  um  then - We did that  I - I believe. Right. So. Yeah. A- And  then  you know  say very clearly that if they don't - if we don't hear from them  you know  as Morgan suggested  by a certain time or after a certain period after we contact them that is implicitly giving their agreement. Well  they've already signed a form. @@ Right. And the form says - And nobody - nobody really reads it anyway. So. And the s- and the form was Says that. Right. Well  if that's i- tha- if that's already - if - approved by Human Subjects  so  eh  that's gonna be a little hard to modify. Uh  the f- Well  the form - Well  the form doesn't say  if - uh  you know  ""if you don't respond by X_ number of days or X_ number of weeks -"" I see. Uh - Oh  O_K. So what does it say about the - the - the process of - of  uh - It doesn't have a time limit. y- the review process? That you'll be provided access to the transcripts and then  uh  allowed to remove things that you'd like to remove  Oh  O_K. Hmm. before it goes to the general - uh  larger audience. Right. Oh. Here. You can read what you already signed. There you go. I guess when I read it  um - O_K . I'm not as diligent as Chuck  but I had the feeling I should probably respond and tell Adam  like  ""I got this and I will do it by this date  and if you don't hear from me by then -"" You know  in other words responding to your email once  Right. right away  saying ""as soon as you get this could you please respond."" And then if you - if the person thinks they'll need more time because they're out of town or whatever  they can tell you at that point? Because - Oh  I just - I didn't wanna do that  because I don't wanna have a discussion with every person if I can avoid it. Well  it's - So what I wanted to do was just send it out and say ""on the fifteenth  the data is released  if you wanna do something about it  do something about it  but that's it"". Mm-hmm. I - I kind of like this. Yeah. Well - O_K. So  we're assuming that - Well  that's - that would be great if - but you should probably have a legal person look at this and make sure it's O_K. Because if you - if you  uh  do this and you - then there's a dispute later and  uh  some - you know  someone who understands these matters concludes that they didn't have  uh  you know  enough opportunity to actually exercise their - their right - Or they - they might never have gotten the email  because although they signed this  they don't know by which date to expect your email. And so someone whose machine is down or whatever - I mean  Mm-hmm. we have no - in- internally we know that people are there  but we have no confirmation that they got the mail. Well  O_K. l- Let me - Let me reverse this. So let's say someone - I send this out  and someone doesn't respond. Do we delete every meeting that they were in? I don't think so. Well  then - No. It - we're hoping that doesn't happen  but that's why there's such a thing as registered mail or - That will happen. That will happen. Right. That will absolutely happen. Because people don't read their email  or they'll read and say ""I don't care about that  I'm not gonna delete anything"" and they don- just won't reply to it. Maybe - uh  do we have mailing addresses for these people? No. We have what they put on the speaker form  which was just generic contact information. No. Well - Oh. Most - But the ones that we're dealing with now are all local  except the ones who - I mean  we - we're totally in contact with all the ones in those two groups. Well  then - Mmm. O_K. So maybe  uh  I - you know  that's not that many people and if I - if  uh - i- i- there is an advantage to having them admit - and if I can help with - with processing that  I will. It's - it's - there is an advantage to having them be on record as having received the mail and indicating - Yeah. I mean I thought we had discussed this  like  a year ago. And so it seems like this is a little odd for it to be coming up yet again. Yes  we did. You're right. Well  I - you know. But sometimes - So. Well  we - we haven't experienced it before. Right? So - That's right. You'll either wonder at the beginning or you'll wonder at the end. Need to get it right. I mean  there's no way to get around - I- It's pretty much the same am- amount of work except for an additional email just saying they got the email. And maybe it's better legally to Yeah. wonder before - you know  a little bit earlier than - Well - It's much easier to explain this way. T- t- to have it on record. O_K. Well  why don't you talk t- Morgan  can you talk to our lawyer about it  and find out what the status is on this? Cuz I don't wanna do something that we don't need to. Because Yeah  but w- Mmm. what - I'm telling you  people won't respond to the email. No matter what you do  you- there're gonna be people who you're gonna have to make a lot of effort to get in contact with. I mean  i- it's k- Well  then we make the effort. Hmm. And do we want to spend that effort? It's kind of like signing up for a mailing list. They have opt in and opt out. And there are two different ways. I mean  and either way works probably  I mean. We make the effort. Except I really think in this case - I - I'm agr- I agree with Liz  that we need to be in the clear and not have to after the fact say ""oh  but I assumed""  and ""oh  I'm sorry that your email address was just accumulating mail without notifying you""  you know. If this is a purely administrative task  we can actually have administration do it. Oh  excellent. But the thing is that  you know  I - I - I think  without going through a whole expensive thing with our lawyers  from my previous conversations with them  my - my sense very much is that we would want something on record as indicating that they actually were aware of this. Yes. Well  we had talked about this before and I thought that we had Mm-hmm. even gone by the lawyers asking about that and they said you have to s- they've already signed away the f- with that form - that they've already signed once. I don't remember that this issue of the time period allowed for response was ever covered. Yeah. @@ Yeah. We never really talked about that. O_K. Or the date at which they would be receiving the email Or - or how they would indicate - Yeah. from you. They probably forgot all about it. Yeah. We certainly didn't talk  uh  about - with them at all about  uh  the manner of them being - We do it like with these - made the  uh  uh  materials available. That was something that was sort of just within our implementation. We can use it - we can use a - O_K. a ploy like they use to  um - you know  that when they serve  like - uh  uh  uh - uh  you know  like dead-beat dads  they - they - they make it look like they won something in the lottery and then they open the envelope and that - And they're served. Right? Because - and then the - the - the - the thing is served. So you just make it  you know  ""oh  you won - you know  go to this web site and you've  uh - you're -"" That's why you never open these things that come in the mail. That one. Right. Well  it's just  we've gone from one extreme to the other  where Yeah. Right. No  it- I - it might - at one point  a few months ago  Morgan was - you were saying let's not do anything  and now we're - Well  it doesn't matter. i- i- it - it might well be the case - it might - we're saying we have to follow up each person and get a signature? I mean  what are we gonna doing here? Right. It might well be the case that - that this is perfectly - Well . you know  this is enough to give us a basis t- to just  eh  assume their consent if they don't reply. But  I'm not - you know  me not being a lawyer  I wouldn't Mm-hmm. just wanna do that without having the - the expert  uh  opinion on that. And how many people? Al- altogether we've got twenty people. These people are people who read their email almost all the time. Then I think we had better find out  so that we can find a - Yeah. Let me look at this again. Right. I - I really don't see that it's a problem. I - I think that it's a common courtesy to ask them - For - for th- uh  to expect for them to  uh  be able to have @@ us try to contact them  u- just in case they hadn't gotten their email. I think they'd appreciate it. Yeah. My - Adam  my - my view before was about the nature of what was - of the presentation  Mm-hmm. of - of how my - my - the things that we're questioning were along the lines of how easy - uh  h- how m- how much implication would there be that it's likely you're going to be changing something  as opposed to - That was the kind of dispute I was making before. Mm-hmm. Mm-hmm. I remember that. But  um  the attorneys  I - uh  I can guarantee you  the attorneys will always come back with - and we have to decide how stringent we want to be in these things  but they will always come back with saying that  um  you need to - you want to have someth- some paper trail or - which includes electronic trail - that they have  uh  in fact O_ K'd it. Mm-hmm. So  um  I think that if you f- i- if we send the email as you have and if there's half the people  say  who don't respond at all by  you know  some period of time  we can just make a list of these people and hand it to  uh - you know  just give it to me and I'll hand it to administrative staff or whatever  and they'll just call them up and say  you know  ""have you - Right. Is - is this O_K? And would you please mail - you know  mail Adam that it is  if i- if it  you know  is or not."" So  you know  we can - we can do that. The other thing that there's a psychological effect that - at least for most people  that if they've responded to your email saying ""yes  I will do it"" or ""yes  I got your email""  they're more likely to actually do it later than to just ignore it. Mm-hmm. And of course we don't want them to bleep things out  but it - it's a little bit better if we're getting the - their  uh  final response  once they've answered you once than if they never answer you'd at al- at all. That's how these mailing houses work. So  I mean  it's not completely lost work because it might benefit us in terms of getting responses. Mm-hmm. You know  an official O_K from somebody is better than no answer  even if they responded that they got your email. And they're probably more likely to do that once they've responded that they got the email. I also think they'd just simply appreciate it. I think it's a good - a good way of - of fostering goodwill among our subjects. Well  our participants. I think the main thing is - I mean  what lawyers do is they always look at worst cases. So they s- so - so - Tha- that's what they're paid to do. Sending lots of spam. Yep. And so  it is certainly possible that  uh  somebody's server would be down or something and they wouldn't actually hear from us  and then they find this thing is in there and we've already distributed it to someone. So  what it says in there  in fact  is that they will be given an opportunity to blah-blah-blah  Mm-hmm. but if in fact - if we sent them something or we thought we sent them something but they didn't actually receive it for some reason  um  then we haven't given them that. Well  so how far do we have to go? Do we need to get someone's signature? Or  is email enough? Do we have to have it notarized? I mean - I- i- i- em- email is enough. O_K. Yeah. I mean  I've been through this - I mean  I'm not a lawyer  but I've been through these things a f- things f- like this a few times with lawyers now so I - I Mm-hmm. I- I'm pretty comfortable with that. Do you track  um  when people log in Uh. If they submit the form  I get it. to look at the - ? Uh-huh. If they don't submit the form  it goes in the general web log. But that's not sufficient. Hmm. Right? Cuz if someone just visits the web site that doesn't imply anything in particular. Except that you know they got the mail. Mm-hmm. That's right. I - I could get you on the notify list if you want me to. Right. I'm already on it. For that directory? O_K  great. Mm-hmm. So again  hopefully  um  this shouldn't be quite as odious a problem either way  uh  in any of the extremes we've talked about because uh  we're talking a pretty small number of people. W- For this set  I'm not worried  because we basically know everyone on it. Mm-hmm. Hmm. Mm-hmm. You know  they're all more or less here or it's - it's Eric and Dan and so on. But for some of the others  you're talking about visitors who are gone from ICSI  Mm-hmm. whose email addresses may or may not work  Oh. Mm-hmm. and - So what are we gonna do when we run into someone that we can't get in touch with? I don't think  uh - They're so recent  these visitors. I - and - and I - they're also so - Mm-hmm. Mm-hmm. They're prominent enough that they're easy to find through - I - I mean  I - I w- I'll be able to - if you have any trouble finding them  I really think I could find them. Other methods? O_K. Yeah. Cuz it - what it - what it really does promise here is that we will ask their permission. Um  and I think  you know  if you go into a room and close the door and - and ask their permission and they're not there  it doesn't seem that that's the intent of  uh  meaning here. So. Well  the qu- the question is just whether - how active it has to be. I mean  because they - they filled out a contact information and that's where I'm sending the information. Right. And so far everyone has done email. There isn't anyone who did  uh  any other contact method. Well  the way ICSI goes  people  uh  who  uh  were here ten years ago still have acc- have forwards to other accounts and so on. So it's unusual that - that they  uh - Yeah. So my original impression was that that was sufficient  that if they give us contact information and that contact information isn't accurate Yeah. Then they just come back. All my files were still here. Yeah. that we fulfilled our burden. Same as us. So if we get to a boundary case like that then maybe I will call the attorney about it. But  you know  hopefully we won't need to. I just - O_K. I d- I just don't think we will. Alright. For all the reasons that we've discussed. So we'll - we'll see if we do or not. Yep. And we'll see how many people respond to that email. Yeah. So far  two people have. So. Yeah. I think very few people will and - and - and  you know  people - people see long emails about things that they don't think is gonna be high priority  they typically  uh  don't - don't read it  or half read it. Right. Cuz people are swamped. But - And actually  um  I - I - didn't anticipate this so I - that's why I didn't give this comment  and it - I - this discussion has made me think it might be nice to have a follow-up email within the next couple of days saying ""by the way  you know  we wanna hear back from you by X_ date and please -""  and then add what Liz said - ""please  uh  respond to - please indicate you received this mail."" Uh  or e- well  maybe even additionally  uh  um  ""Even if you've decided you have no changes you'd like to make  if you could Respond to the email. Yep. tell us that "". Yeah. Mm-hmm. It is the first time through the cycle. Right. That would - that would definitely work on me. You know  it makes you feel m- like  um  if you were gonna p- if you're predicting that you might not answer  you have a chance now to say that. Whereas  I - I mean  I would be much more likely myself  given all my email  t- to respond at that point  saying ""you know what  I'm probably not gonna get to it"" or whatever  And the other th- rather than just having seen the email  thinking I might get to it  and never really  Yeah. I was - uh  pushing myself to actually do it until it's too late. I was thinking that it also lets them know that they don't have to go to the page to accept this. Right. R- Right. That's true. Right. I mean  I - I - Yeah. So that way they could - they can see from that email that if they just write back and say ""I got it  no changes""  they're off the hook. They don't have to go to the web page and - Yeah. I mean  the other thing I've learned from dealing with - dealing with people sending in reviews and so forth  uh  is  um  Yeah. That's true. if you say ""you've got three months to do this review""  um  people do it  you know  two and seven eighths months from now. If you say ""you've got three weeks to do this review""  they do - do it  you know  two and seven eighths weeks from now - they do the review. Right. And  um - So  if we make it a little less time  I don't think it'll be that much - Well  and also if we want it ready by the fifteenth  that means we better give them deadline of the first  if we have any prayer of actually getting everyone to respond in time. There's the responding part and there's also what if  uh  I mean  I hope this doesn't happen  what if there are a bunch of deletions that have to get put in and changes? Then Right. we actually have to deal with that if we want it to - Mm-hmm. Some lead time. Ugh! Disk space  oh my god! I hadn't thought about that. By the way  has - has Jeremy signed the form? O_K. That for every meeting - any meeting which has any bleeps in it we need yet another copy of. Oh. Just that channel. Oh  no. We have to do - Can't you just do that channel? No  of course not. You need all the channels. Yeah. You have to do all of them  Oh. as well as all of these. Do you have to do the other close-talking? Yeah. Wow. Yes. Absolutely. There's a lot of cross-talk. You have to do all - You could just do it in that time period  though  but I guess it's a pain. Well - Well  but you have to copy the whole file. Right? Because we're gonna be releasing the whole file. Yeah. Yeah. You're right. Well - I - you know  I think at a certain point  that copy that has the deletions will become the master copy. Yeah. It's just I hate deleting any data. So I - I don't want - I really would rather make a copy of it  rather than Are you del- are you bleeping it by adding? bleep it out and then - Overlapping. So  it's - it's exactly a censor bleep. So what I really think is ""bleep"" and then I want to - I- I- I- I understand  but is - is it summing signals or do you delete the old one and put the new one in? I delete the old one  put the new one in. There's nothing left of the original signal. Oh  O_K. Cuz - Oh. Cuz if you were summing  you could - No. But anyway - Yeah. Yeah. It would be qui- quite easy to get it back again. But - And then w- I was gonna say also that the- they don't have to stay on the system  as you know  cuz - cuz the - the ones - Then someday we can sell the unedited versions. Yeah. Say again? Once it's been successfully bleeped  can't you rely on the - ? Or we'll tell people the frequency of the beep and then they could subtract the beep out. Encrypt it. You can hide it. Yeah. Oh  yeah. Can't you rely on the archiving to preserve the older version? Right. Exactly. I see. Yeah  that's true. Yeah. Yep  that's true. It wouldn't be that hard See  this is good. I wanted to create some side conversations in these meetings. So - Yeah. You could encrypt it  to hide it. O_K. You can use spread spectrum. Hide it. Yeah  there you go. you know  with a - with a two hundred bit - thousand bit  uh - Uh-huh. Here we go. Yeah. Yeah. Cuz we don't have enough asides. I have an idea. You reverse the signal  so it - it lets people say what they said backwards. There you go. Then you have  like  subliminal  uh  messages  like. Backwards. But  ha- you've seen the - this - the speech recognition system that reversed very short segments. Did you read that paper? Yeah. It wouldn't work. The speech recognizer still works. No. Yeah. And if you do it backward then - Yeah. H_- good old H_M_M. No  it's backward-forward. That's cuz they use forward-backward. Forward but backward. That's right. Good point. A point. Uh. Well  I'm sorry if I sound a little peeved about this whole thing. It's just we've had meeting after meeting after meeting a- on this and it seems like we've never gotten it resolved. Well  but we never also - we've also never done it. Hmm. Uh. So. Yeah. If it makes - So. This is the first cycle. There're bound to be some glitches the first time through. And  uh - and I'm sorry responding without  uh  having much knowledge  but the thing is  uh  I am  like  one of these people who gets a gazillion mails and - and stuff comes in as Well  and that's exactly why I did it the way I did it  which is the default is if you do nothing we're gonna release it. Because  Yeah. you know  I have my stack of emails of to d- to be done  that  you know  fifty or sixty long  and the ones at the top I'm never gonna get to. Right. And  uh So - so - Move them to the bottom. So - so the only thing we're missing is - is some way to respond to easily to say  uh  ""O_K  go ahead"" or something. Yeah. Yeah  right. So  i- this is gonna mean - Just re-mail them to yourself and then they're at the bottom. Yeah. Yeah. That's actually definitely a good point. The m- email doesn't specify Yeah. that you can just reply to the email  as op- as opposed to going to the form and - In - Mm-hmm. Right. And it also doesn't give a - a specific - I didn't think of it. S- I think it's a good idea - an ex- explicit time by which this will be considered Yeah  release. definite. And - and it has to be a time earlier than that endpoint. Yeah. It's converging. This - um  I've seen this recently. Uh  I got email  and it - Yeah. That's right. i- if I use a MIME-capable mail reader  it actually says  you know  click on this button to confirm receipt of the - of the mail. Hmm. Oh  that's interesting. So - You - you can - A lot of mailers support return receipt. But it doesn't confirm that they've read it. It's like certified mail. Could do that. Right. No  no  no. This is different. This is not - So  I - I know  you can tell  you know  the  uh  mail delivery agent to - to confirm that the mail was delivered to your mailbox. But - but  no. This was different. Mmm. Right. Ins- in the mail  there was a - Oh  just a button. Oh  yeah. uh  th- there was a button that when you clicked on it  it would send  uh  you know  a actual acknowledgement to the sender that you had actually looked at the mail. Yeah. Unfor- Yeah  we could do that. But I hate that. But it o- but it only works for  you know  MIME-capable - you know  if you use Netscape or something like that for your n- Yeah. You might as well just respond to the mail. I mean And - And we actually need a third thing. It's not that you've looked at it  it's that you've looked at it and - and - and agree with one of the possible actions. Right? Right. No  no. You can do that. You know  you can put this button anywhere you want  and you can put it the bottom of the message and say ""here  by - you know  by clicking on this  I - I agree - Oh? Oh  I see. uh  you know  I acknowledge -"" That i- i- my first-born children are yours  and - Yeah. Yeah. Quick question. Are  um - Well  I could put a U_R_L in there without any difficulty and even pretty simple MIME readers can do that. So. But why shouldn't they just email back? I don't see there's a problem. It's very nice. I - I like the high-tech aspect of it  but I think - Yeah. Reply. Yeah. Right. Yeah. No  no  no. I actually don't. I'm just saying that I appreciate it. Well  I - cuz I use a text mail reader. if ev- but I'm - Don't you use V_I for your mai- ? Yeah. Wow. That's - that's my guy. Alright. You - you read email in V_I? Yeah. Yeah. I like V_I. So - I - i- There's these logos that you can put at the bottom of your web page  like ""powered by V_I"". Yeah. Wow. Anyway  quick question. How m- You could put wed bugs in the email. I see. Yeah. Like  there were three meetings this time  or so- or how many? Six? Six. But  no- of different people. So I guess if you're in both these types of meetings  you'd have a lot. But - How - I mean  it also depends on how many - Like  if we release - this time it's a fairly small number of meetings  but what if we release  like  twenty-five meetings to people? Well  what my s- expectation is  is that we'll send out one of these emails every time a meeting has been checked and is ready. In th- I don't know. Oh. Oh  O_K. So this time was just the first chunk. O_K. So. Tha- that was my intention. It's just - yeah - that we just happened to have a bunch all at once. Well  that's a good idea. I mean  maybe - Is that the way it's gonna be  you think  Jane? I agree with you. It's - we could do it  uh - I- I could - I'd be happy with either way  batch-wise - What I was thinking - Uh  so this one - That was exactly right  that we had a - uh  uh - I - I had wanted to get the entire set of twelve hours ready. Don't have it. But  uh  this was the biggest clump I could do by a time where I thought it was reasonable. People would be able to check it and still have it ready by then. Mm-hmm. My  um - I was thinking that with the N_S_A meetings  I'd like - there are three of them  and they're - uh  I - I will have them done by Monday. Uh  unfortunately the time is later and I don't know how that's gonna work out  but I thought it'd be good to have that released as a clump  too  because then  you know  they're - they - they have a - it- it's in a category  it's not quite so distracting to them  is what I was thinking  and it's all in one chu- But after that  when we're caught up a bit on this process  then  um  I could imagine sending them out periodically as they become available. O_K. I could do it either way. I mean  it's a question of how distracting it is to the people who have to do the checking. We heard anything from I_B_M? at all ? Uh. Let's see. We - Yeah  right. So we got the transcript back from that one meeting. Everything seemed fine. Adam had a script that will put everything back together and there was - Well  there was one small problem but it was a simple thing to fix. And then  um  we  uh - I sent him a pointer to three more. And so he's off and working on those. Yeah. Now we haven't actually had anyone go through that meeting  to see whether the transcript is correct and to see how much was missed and all that sort of stuff. So at some point we need to do that. Yeah. That's on my list. Well  that's on my list. Yeah. It's gonna have to go through our regular I mean  the one thing I noticed is it did miss a lot of backchannels. There are a fair number of ""yeahs"" and ""uh-huhs"" that - it's just - that aren't in there. process. So. Hmm. But I think - Yeah. Like you said  I mean  that's - that's gonna be our standard proc- that's what the transcribers are gonna be spending most of their time doing  I would imagine  once - once we - Mm-hmm. Mm-hmm  mm-hmm. Yes  absolutely. Yeah. It's gonna - One question about the backchannels. Do you suppose that was because they weren't caught by the pre-segmenter? Yes  absolutely. Absolutely. Oh  interesting. Oh  interesting. O_K. Yeah. They're - they're not in the segmented. It's not that the I_B_M people didn't do it. O_K. O_K. Just they didn't get marked. O_K. So maybe when the detector for that gets better or something - I w- I - There's another issue which is this - we've been  uh  contacted by University of Washington now  of course  to  um - We sent them the transcripts that correspond to those six meetings and they're downloading the audio files. So they'll be doing that. Chuck's - Chuck's  uh  put that in. Mm-hmm. Yeah  I pointed them to the set that Andreas put  uh  on the web so th- if they want to compare directly with his results they can. And  um  then once  uh  th- we can also point them at the  um  uh  the original meetings and they can grab those  too  with S_C_P. Wait. So you put the reference files - ? No  no. They d- they wanted the audio. Jane sent them the  uh  transcripts. Or the - ? No  I mean of the transcripts. Um. Well  we can talk about it off-line. There's another meeting in here  what  at four? Mm-hmm. Right? Yeah  so we have to finish by three forty-five. D- d- So  does Washi- does - does U_W wanna u- do this - wanna use this data for recognition or for something else? Uh  for recognition. I think they're doing w- didn't they want to do language modeling on  you know  recognition-compatible transcripts or - ? Oh. Oh. I see. Yeah. This is to show you  uh  some of the things that turn up during the checking procedure. Um @@ So  this is from one of the N_S_A meetings and  uh  i- if you're familiar with the diff format  the arrow to the left is what it was  and the arrow to the right is what it was changed to. So  um. And now the first one. ""O_K. So  then we started a weekly meeting. The last time  uh -"" And the transcriber thought ""little too much"" But  uh  @@ really  um  it was ""we learned too much""  which makes more sense syntactically as well. And these - the parentheses were f- from - Then - Oh  this - that's the convention for indicating uncertain. So the transcriber was right. U- uncertains. S- You know  she was uncertain about that. So she's right to be uncertain. O_K. Oh. O_K. And it's also a g- a good indication of the - of that. The next one. This was about  uh  Claudia and she'd been really b- busy with stuff  such as waivers. Uh  O_K. Um  next one. Um. This was an interesting one. So the original was ""So that's not - so Claudia's not the bad master here""  and then he laughs  but it really ""web master"". Web master. Oh. Uh-oh. And then you see another type of uncertainty which is  you know  they just didn't know what to make out of that. Yep. So instead of ""split upon unknown""  it's ""split in principle"". Jane  these are from I_B_M? The top lines? Spit upon? No  no. These are - these are our local transcriptions of the N_S_A meetings. The transcribers - transcriber's version ver- versus the checked version. No  these are ours. Oh. Oh  I see. My - my checked version  after I go through it. O_K. Um  then you get down here. Um. Sometimes some speakers will insert foreign language terms. That's the next example  the next one. The  uh  version beyond this is - So instead of saying ""or""  especially those words   "" also"" and ""oder"" and some other ones. Those sneak in. Um  the next one - Discourse markers. That's cool. Discourse markers. S- Sorry  what? Discourse markers. Yeah. Yeah. Discourse markers? Sure. Sure  sure  sure. And it's - and it makes sense cuz it's  like  below this - it's a little subliminal there. Yeah. Yeah  yeah. Um. O_K  the next one  uh  this is a term. The problem with terminology. Description with th- the transcriber has ""X_ as an advance"". But really it's ""Q_S in advance"". I mean  I - I've benefited from some of these  uh  cross-group meetings. O_K  then you got  um  uh  instead of ""from something-or-other cards""  it's ""for multicast"". And instead of "" ANN system related""  it's "" end system related"". This was changed to an acronym initially and it should- shouldn't have been. And then  you can see here ""G_P_S"" was misinterpreted. It's just totally understanda- This is - this is a lot of jargon. Um  and the final one  the transcriber had th- ""in the core network itself or the exit unknown  not the internet unknown"". And it - it comes through as ""in the core network itself of the access provider  not the internet backbone core "". Now this is a lot of terminology. Mmm. And they're generally extremely good  but  you know in this - this area it really does pay to  um - to double check and I'm hoping that when the checked versions are run through the recognizer that you'll see s- substantial improvements in performance cuz the - you know  there're a lot of these in there. Yeah. So how often - ? Yeah  but I bet - I bet they're acoustically challenging parts anyway  though. Mmm. No  actually no. Huh-uh. Oh  really? Uh  it's - Oh  so it's just jargon. It's jargon. Yeah. I mean this is - cuz  you know you don't realize in daily life how much you have top-down influences in what you're hearing. Well  but - And it's jar- it's jargon coupled with a foreign accent. But - but - But we don't - I mean  our language model right now doesn't know about these words anyhow. So  you know  un- until you actually get a decent language model  @@ Adam's right. You probably won't notice a difference. Yeah. It probably won't do any better. But it's - I mean  it's definitely good that these are fixed. I mean  obviously. Well  also from the standpoint of getting people's approval  cuz if someone sees a page full of Yeah. uh  um  barely decipherable w- you know  sentences  and then is asked to approve of it or not  it's  uh  uh - Did I say that? Yeah. Yeah. That would be a shame if people said ""well  I don't approve it because the - it's not what I said"". Yeah. O_K. Well  that's exactly why I put the extra option in  Exactly. That's why we discussed that. is that I was afraid people would say  ""let's censor that because it's wrong ""  and I don't want them to do that. Yeah. Yeah. Yeah. And then I also - the final thing I have for transcription is that I made a purchase of some other headphones because of the problem of low gain in the originals. C- And - and they very much appro- they mu- much prefer the new ones  and actually I - I mean  I - I think that there will be fewer things to correct because of the - the choice. We'd originally chosen  uh  Yeah. very expensive head- headsets but  um  they're just not as good as these  um  Ugh! in this - with this respect to this particular task. Well  return the old ones. It's probably impedance matching problems. But - I don't know exactly  but we chose them because that's what's been used here by prominent projects in transcription. So it i- we had every reason to think they would work. Sorry  what? Could be. Mm-hmm. So you have spare headsets? You have spare headsets? They're just earphones. They're not headsets. They're not microphones. No  no. I mean  just earphones? Right. Um  because I  uh  I could use one on my workstation  just to t- because sometimes I have to listen to audio files and I don't have to b- go borrow it from someone and - We have actua- actually I have - W- Well  the thing is  that if we have four people come to work for a day  I was - I was hanging on to the others Oh  O_K. for  eh - for spares  but I can tell you what I recommend. No  but you'd - If you - Yeah  w- we should get it. Sure. No problem. I just - But if you need it  just get it. Come on. Right. Yeah. If you need it. Yeah. Yeah. They're - they're - they're - they're pretty inexpensive. Yeah. Yeah  I still - I still need to get a pair  too. It'd just have to be a s- a separate order - an added order. Yeah  that - We should order a cou- uh  t- I'm using one of these. Yeah. two or three or four  actually. We have - I think I have a pair that I brought from home  but it's f- just for music listening and it's not - Nnn. Yeah. No. Just - just - just - just buy them. Sh- Just get the model number and - Where do you buy these from? Like - ? Just buy them. Yeah. Cambridge SoundWorks  just down the street. You just b- go and b- Oh. Yeah. They always have them in stock. Yeah. Anyway. That'd be a good idea. W- uh  could you email out the brand? Yeah. Oh  sure. Yeah. O_K. Cuz I think - sounds like people are interested. So. Yeah. Definitely. Yeah. It's made a difference in - in how easy. Yeah. I realized something I should talk about. So what's the other thing on the agenda actually ? Uh  the only one was Don wanted to  uh  talk about disk space yet again. Yeah. u- It's short. I mean  if you wanna go  we can just throw it in at the end. No  no. Why don't you - why don't you go ahead since it's short. Um  well  uh. Oh  I thought you meant the disk space. Yeah  we know disk space is short. The disk space was short. Yeah. That's what I thought too. That's a great ambiguity. Yeah. It's one of these - it's - it's social and  uh  discourse level and - It's - Yeah. I- i- i- it- i- Yeah  it's great. Yeah  double - double - Sorry. See  if I had that little scratch-pad  I would have made an X_ there. Yeah  it was really goo- Thank you  thank you. Uh  well  we'll give you one then. Yeah. Um. So  um  without thinking about it  when I offered up my hard drive last week - Oh  no. It was while I was out of town. Um  this is always a suspect phrase. But  um  no. I  uh - I realized that we're going to be doing a lot of experiments  um  o- for this  uh  paper we're writing  so we're probably gonna need a lot more - We're probably gonna need that disk space that we had on that eighteen gig hard drive. But  um  we also have someone else coming in that's gonna help us out with some stuff. So - We've just ordered a hundred gigabytes. I think we need  like  another eighteen gig disk to be safe. O_K. We just need to - Well  we're getting three thirty - thirty-sixes. So. O_K. Right? That are going into the main f- file server. So. O_K. Markham's ordering and they should be coming in soon. W- Well. So - so - Soon? Yeah. I mean  I guess the thing is is  all I need is to hang it off  like  the person who's coming in  Sonali's  computer. Oh  so - so  you mean the d- the internal - the disks on the machines that we just got? Whew. Or we can move them. No. Or extra disk? These are gonna go onto Abbott. Ne- new disks. Onto Abbott  the file server. So are we gonna move the stuff off of my hard drive onto that when those come in? O_K. That's fine. Oh  oh. O_K. On - Yeah. Once they come in. Sure. Uh  i- Do - when - when is this planned for roughly? They should be - I - I imagine next week or something. O_K. So - If you're - if you're desperate  I have some space on my drive. O_K. I think if I'm - But I - I vacillate between no space free and a few gig free. So. Yeah. Yeah. I think I can find something if I'm desperate and  um  in the meantime I'll just hold out. That was the only thing I wanted to bring up. O_K. It should be soon. We - we should - O_K. So there's another hundred gig. So. Alright. Great. Mm-hmm. O_K. It's great to be able to do it  just say ""oh yeah  a hundred gig  no big deal"". That's it. Good. Yeah. Yeah. A hundred gig here  a hundred gig there. It's eventually Well  each meeting is like a gig or something  so it's really - Yeah. real disk space. Yeah. Um. Yeah. I was just going to comment that I- I'm going to  uh  be on the phone with Mari tomorrow  late afternoon. We're supposed to Oh  yeah. get together and talk about  uh  where we are on things. Uh  there's this meeting coming up  uh  and there's also an annual report. Now  I never actually - I - I was asking about this. I don't really quite understand this. She was re- she was referring to it as - I think this actually didn't just come from her  but this is what  uh  DARPA had asked for. Um  she's referring to it as the an- annual report for the fiscal year. But of course the fiscal year starts in October  so I don't quite understand w- w- why we do an annual report that She's either really late or really early. we're writing in July. Huh. Or she's getting a good early start. Uh  I think basically it- it's none of those. It's that the meeting is in July so they - so DARPA just said do an annual report. So. So. So anyway  I'll be putting together stuff. I'll do it  uh  you know  as much as I can without bothering people  just by looking at - at papers and status reports. I mean  the status reports you do are very helpful. Hmm. Uh  so I can grab stuff there. And if  uh - if I have some questions I'll - When we remember to fill them out. Yeah. If people could do it as soon as - as you can  if you haven't done one si- recently. Uh. Uh  but  you know  I'm - I'm sure before it's all done  I'll end up bugging people for - for more clarification about stuff. Um. But  um  I don't know  I guess - I guess I know pretty much what people have been doing. We have these meetings and - and there's the status reports. Uh. But  um. Um. Yeah. So that wasn't a long one. Just to tell you that. And if something hasn't  uh - I'll be talking to her late tomorrow afternoon  and if something hasn't been in a status report and you think it's important thing to mention on this kind of thing  uh  uh  just pop me a one-liner and - and - and I'll - I'll have it in front of me for the phone conversation. O_K. Uh. I guess  uh  you- you're still pecking away at the demos and all that  probably. Yep. And Don is gonna be helping out with that. So. Oh  that's right. O_K. Did you wanna talk about that this afternoon? Um. Not here  but later today? We should probably talk off-line about when we're gonna talk off-line. O_K. O_K. O_K. Yeah  I might want to get updated about it in about a week cuz  um  I'm actually gonna have a - a few days off the following week  a- after the - after the picnic. So. Oh  O_K. That's all I had. So we were gonna do sort of status of speech transcription - automatic transcription  but we're kind of running late. So. How long does it take you to save the data? Fifteen minutes. So. Yeah. If you wanna do a quick Yeah. ten minute - Guess we should stop  like  twenty of at the latest. We - we have another meeting coming in that they wanna record. So. Uh - And there's the digits to do. So maybe - may- maybe - maybe - We could. Yeah. Well  we can skip the digits. Fi- five minute report or something. It's up to you. I don't - Yeah  yeah. Well  I would love to hear about it  especially since - Whatever you want. What do you have to say? I'm interested  so - Yeah. Well  I'm gonna be on the phone tomorrow  so this is just a good example of the sort of thing I'd like to hear about. Wait. Why is everybody looking at me? Sorry. I don't know. Cuz he looked at you and says you're sketching. What? Uh. I'm not sure what you were referring to. Who's - ? I - I - I - I'm not - actually  I'm not sure what - ? Are we supposed to have done something? No. We were just talking before about alternating the subject of the meeting. Oh. Alternating. Uh-huh. And this week we were gonna try to do t- automatic transcription status. I wasn't here last week. Sorry. Oh! Oh. We did that last week. Right? But we sort of failed. Hhh. No. I thought we did. Did we? O_K. Yeah. We did. O_K. So now - now we have the schedule. So next week we'll do automatic transcription status  plus anything that's real timely. O_K. Oh. O_K. O_K. O_K. Whew! Whew! Good update. Sorry. That was - Dodged that bullet. Yeah. Nicely done  Liz. A woman of few words. But - but lots of prosody. O_K. O_K. Uh  I mean  we - we really haven't done anything. Th- Excuse me? Sorry. Well  since last week. Yeah  we're - I mean  the - the next thing on our agenda is to go back and look at the  um - the automatic alignments because  uh  I got some - @@ I - I - I learned from Thilo what data we can use as a benchmark to see how well we're doing on automatic alignments of the background speech - or  of the foreground speech with background speech. So. Yeah. But  we haven't actually - And then  uh  I guess  the new data that Don will start to process - the  um - when he can get these - You know  before we were working with these segments that were all synchronous and that caused a lot of problems because you have Mmm. Oh. Right  right. timed sp- at - on either side. Mm-hmm. And so that's sort of a stage-two of trying the same kinds of alignments with the tighter boundaries with them is really the next step. Right. I'll be interested. We did get our  um - I guess  good news. We got our abstract accepted for this conference  um - workshop  ISCA workshop  in  um  uh  New Jersey. And we sent in a very poor abstract  but they - very poor  very quick. Um  but we're hoping to have a paper for that as well  which should be an interesting - When's it due? The t- paper isn't due until August. The abstracts were already due. So it's that kind of workshop. Mm-hmm. But  I mean  the good news is that that will have sort of the European experts in prosody - sort of a different crowd  and I think we're the only people working on prosody in meetings so far  so that should be interesting. What's the name of the meeting? Uh  it's It's called Prosody to - ISCA Workshop on Prosody in Speech Recognition and Understanding  or something like that - some generic - Mm-hmm. Good. Uh  so it's focused on using prosody in automatic systems and there's a - um  a web page Y- you going to  uh  Eurospeech? for it. Yeah. Yeah. I don't have a paper but I'd kinda like to go  if I could. Is that alright? We'll discuss it. My - my - my car - my car needs a good wash  by the way. O_K. I guess that's ""no"". Funny @@ O_K. Well  that th- Hey  if that's what it takes  that's fine with me. Um. I'll pick up your dry-cleaning  too. Right. Should we do digits? Yeah. Uh. Transcript L_ one eight three nine  five zero zero  one four  four nine five  one four one  four seven  nine two  O_ six  eight eight eight nine three  four O_ seven  O_ five three seven three two six  five eight seven  nine nine seven nine six  seven O_  three nine  four four  three three two six seven  O_ five six  seven one two six five O_ six  six four  seven one six one two zero  two two  nine four  O_ one - Correction. O_ five  four four Can I go next? Because I have to leave  actually. Yep. Go for it. Um  transcript  uh  L_ one eight four six eight six  six eight  two two six one two one  three two  nine five  three O_  eight one seven five one nine  seven eight one one  one four one zero nine six  two seven  three seven  two seven  one nine six four O_ two  O_ eight six O_  four four seven three seven three three  four four  eight O_ seven five two five four O_  four nine seven two  six five three seven O_ three  seven three  six one  four two  six O_ Transcript L_ dash one eight five eight zero four  one six  eight zero nine three two seven one  three seven seven  seven four seven one three seven four  nine  five zero nine nine  seven six zero  one nine  seven nine seven  five eight nine seven  nine nine  three zero zero nine two seven four  seven two one  nine one four one nine one seven one  six  two eight six one  five eight three  one nine  three six four  four Transcript - transcript L_ one eight seven nine  three six nine  six zero  seven five zero  zero eight nine five three  six nine nine seven  eight three nine zero zero  seven eight four  two nine  zero five five  one Hmm! six eight seven nine  four  two four six one zero four nine  seven  nine eight six three one seven  four seven  eight seven three six one eight  eight zero  seven six  four three  eight four nine two seven one  six four four six  six one two eight Transcript L_ one eight eight two three O_  three eight three  three one seven two eight six  five nine eight  O_ nine two five two five  O_ six six  four five nine one O_ O_ O_  four two one  seven three three six nine one five  O_ three  three eight four six seven eight  nine five  three four  five seven  three O_ five seven four  two three seven  four three five five nine  two three  four six  O_ four  five three Transcript L_ dash one eight zero eight O_ seven  three nine  three eight three seven one nine eight eight  four  nine nine six one nine one six  zero two two nine  two two nine four zero seven four three  six  seven two seven seven four  seven three  two seven  seven nine  one four seven six five  zero seven  one four four three eight nine zero  eight five eight  two eight five four one three  four two five  nine five seven two Transcript L_ dash one eight one one one  six one  two three  eight five  eight eight six six two four  nine nine nine nine  seven two zero four four  nine six three  five seven  two five zero  seven six four  seven zero  six three  one one  zero seven nine zero eight  eight eight zero  nine five nine five three three  seven one one  four eight five four six one nine zero  seven one eight zero  two four four two two two three eight  six three three eight  eight one one four Transcript L_ one eight two. Thanks. zero zero six six  three  three five two four four two  one one six  three one five nine three three  O_ five  seven two eight O_ six three two  O_ four eight  two zero two seven two f- two O_ five. So- So - Sorry. seven  two zero five  five four  four eight five  three one  six six seven  seven four  five five six  three six seven four  six one  eight one five nine eight zero  two five  nine two  seven three  one six Thank you. So you get to be the one who has all the paper rustling. Right? Yeah  exactly! I mean  with the distractions  I was having trouble focusing. But. ","The initial task of the EDU group is to work on inferring intentions through context. In the navigational paradigm used for the task  these intentions are to ""see"" to ""enter"" or to ""get to the closest point of"" a building. There will be purpose-designed experiments carried out. However  the starting point is  through the use of existing data  to determine possible linguistic  discourse or situation features that define intentionality. These may include the type of building  time of day  particular phrases used or whether the user is a tourist or a native. Initially  these features will be hand-coded  but the goal is to find ways of extracting them automatically from the XML data. Consequently  they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated. A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them. Inferring intentions in a navigational context is an appropriate task both in project and real-world terms. Its goals are clearly defined and contributre to a smarter system. Although there are some preliminary data to work on  task-specific experiments and recordings will take place. The XML format is going to be used has not been defined  although the SmartKom data can be used as a foundation. In the first instance  the group will have to decide on the software package to be used for the creation and manipulation of the belief-nets. Stability and ease-of-use -in addition to ability to handle XML- of the package are the focus at this stage  instead of the ability to handle large amounts of data. Experts in Bayes nets within ICSI can be consulted on the matter. The decision will be presented in the next meeting along with a first schema of the belief-nets themselves. Possible intermediate nodes can be added to the nets after this. The hypothesis that a set of features from which intentions can be derived exists has to be assessed  before moving on to how to extract these features from the data automatically. Curent navigation systems do not provide for the user's particular intentions when asking for directions. They always compute the shortest path between source and destination. The SmartKom parser  for example  does not mark up data with features adequate for the inference of these intentions. Although it is understandable that language  discourse and situation features will play a role in how they are weighed  the exact nature of those features is unclear. Also hard to evaluate at this stage  is how the assumed features will combine in a belief-net  in order to provide the conditional probabilities of the users' intentions. Even if these problems are solved  extracting the features from the data may prove to be a bottleneck. The existing data are appropriate only for preliminary work  as they don't include intention-related information. On the other hand  the details of the experiments that will have to be designed to get more appropriate data are not clearcut and are yet to be settled. When asking for directions  a user of a navigational device may wish to either view  enter or simply approach a building. This was identified as an initial problem to be tackled through ""deep understanding""-type inferences. There is a set of data to start work on from previous work. Similarly  the SmartKom data-format and an ontology developed for the tourist domain (both in XML-standard formats) can be used as groundwork for defining the features  which indicate the user's intentions. For the creation and management of the belief-nets necessary for the task  there are readily available packages -such as JavaBayes- and tools that can provide the infrastructure for a prototype system. "
"Starts - No. No. No. That's a different thing. There's another - I don't know. It starts with a P_ or something. I forget the word for it  Oh. but it's - it's um Typically when you - you're ab- r- starting around forty for most people  it starts to harden and then it's just harder for the lens to Oh. shift things and th- the - the symptom is typically that you - Uh-huh. you have to hold stuff uh uh further away to - Yeah. to see it. In fact  uh m- my brother's a gerontological psychologist and he - he uh came up with an - an uh - a uh body age test which uh gets down to sort of only three measurements that are good enough st- statistical predictors of all the rest of it. And one of them is - is the distance Yeah. that you have to hold it at. Give someone a piece of paper and then they - Yeah. We're - we're live by the way  so we've got a good intro here Oh. Oh. Yeah. About how old I am. O_K. Yep. We can edit that out if you want. Oh  that's optional. No  that's O_K. Mm-hmm. O_K. So. You know . This time the form discussion should be very short  right? It also should be later. O_K. Because Jane uh is not here yet. Good point. And uh she'll be most interested in that. Uh  she's probably least involved in the signal-processing stuff so maybe we can just - just uh  I don't think we should go though an elaborate thing  but um uh Jose and I were just talking about the uh uh  speech e- energy thing  The @@ - Yeah. and I uh - We didn't talk about the derivatives. But I think  you know  the - the - i- if I can - if you don't mind my - my speaking for you for a bit  um Uh. Right now  that he's not really showing any kind of uh distinction  but uh - but we discussed a couple of the possible things that uh he can look at. Um. And uh one is that uh this is all in log energy and log energy is basically compressing the distances uh between things. Um Another is that he needs to play with the - the different uh uh temporal sizes. He was - he - he was taking everything over two hundred milliseconds uh  and uh he's going to vary that number and also look at moving windows  as we discussed before. Um And uh - and the other thing is that the - yeah doing the - subtracting off the mean and the variance in the - uh and dividing it by the standard deviation in the log domain  may not be the right thing to do. Hi. Yeah. Hi Jane! We just started. Could you take that mike there? Are these the long term means? Like  over the whole - I mean  the means of what? Thanks. Uh B- Between - All the frames in the conversation? Or of things that - between - No. Between - No. Neither. It's uh between the pauses uh for some segment. Oh. And so i- i- his - his - He's making the constraint it has to be at least two hundred milliseconds. Oh. And so you take that. And then he's - he's uh measuring at the frame level - still at the frame level  Right. of what - and then - and then just uh normalizing with that larger amount. um and - But one thing he was pointing out is when he - he looked at a bunch of examples in log domain  it is actually pretty hard to see the change. And you can sort of see that  because of j- of just putting it on the board that Yep. if you sort of have log-X_ plus log- X_   Yeah  maybe it's not log distributed . that's the log of X_ plus the log of two and it's just  you know  it - it diminishes the effect of having two of them. Mmm. Yeah. @@ But you could do like a C_D_ F there instead? I mean  we don't know that the distribution here is Um. Yes  right. normally. So - So just some kind of a simple - So what I was suggesting to him is that - Actually  a P_D_F . But  you know  uh P_D_F But  either way. Yeah. Yeah. Yeah. Yeah  eith- eith- uh Something like that where it's sort of data driven. B- Yeah  but I think also u- I think a good first indicator is when the - the - the researcher looks at examples of the data and can not see a change in how big the - the signal is  Yeah. when the two speaker - Then  that's a problem right there. Yeah. Oh yeah. So. I think you should at least be able  doing casual looking and can get the sense  "" Hey  there's something there. "" and then you can play around with the measures. Oh yeah. Yeah. And when he's looking in the log domain he's not really seeing it. So. And when he's looking in straight energy he is  so that's a good place to start. Yeah. Um. So that was - that was the discussion we just had. Um. The other thing Actually we ca- had a question for Adam in this. How - Uh  when you did the sampling? uh over the speech segments or s- or sampling over the - the individual channels in order to do the e- uh the amplitude equalization  did you do it over just the entire - everything in the mike channels? You didn't try to find speech? No  I just took over the entire s- uh entire channel um sampled ten minutes randomly. Right  O_K. So then that means that someone who didn't speak very much would be largely represented by silence. Yep. And someone who would - who would be - So the normalization factor probably is i- i- i- Yeah  this was quite quick and dirty  and it was just for listening. is - is - Yeah. Yeah. O_K. And for listening it seems to work really well. Yeah. Yeah. Yeah. So. Yeah. But that's - Right. So th- But  it's not - Yeah. Not a good measure. O_K. So yeah there - there - there - There's a good chance then given that different people do talk different amounts that there is - Yeah. Yeah. there - there is still a lot more to be gained from gain norm- normalization with some Mmm. Yes  absolutely. sort if - if we can figure out a way to do it. Yeah. Uh. But we were agreed that in addition to that uh there should be s- stuff related to pitch and harmonics and so forth. Yeah. So we didn't talk at all about uh the other derivatives  but uh again just - just looking at - Uh  I think uh Liz has a very good point  that in fact it would be much more graphic just to show - Yeah. Well  actually  you do have some distributions here  Yeah. uh for these cases. You have some histograms  Yeah. um and uh  they don't look very separate. uh separated. This is the - the first derivate of log of frame energy What - Yeah. Yeah. uh without any kind of normalization. Yeah. Log energy. These the- Sorry. These are the - the first experiments uh with comment uh Frame energy. Except that it's hard to judge this because the - they're not normalized. It's just number of frames. Yeah. Yeah. Yeah. Yeah. But yeah  even so. W- I mean  what I meant is  even if you use linear  you know  raw ""Number"" - measures  like raw energy or whatever  maybe we shouldn't make any assumptions about the distribution's shape  and just use - you know  use the distribution to model the - the mean  or what- y- you know  rather than the mean take some - Yeah. But - And so in - in these he's got Yeah. that. He's got some pictures. Yeah. But he doesn't - he doesn't in the - he- i- just in derivatives  Yeah. but not in the - Oh. but he d- Right. So  we don't know what they look like on the  tsk - but he doesn't - doesn't - But he didn't h- have it for the energy. For the raw. He had it for the derivatives. Yeah. So. Yeah. I mean  there might be something there. I don't know. Huh. Yeah. Interesting Here I - I Oh that - yeah that's a good q- in - did - did you have this sort of thing  for just the - just the l- r- uh the - the unnormalized No log energy? I - I - I haven't the result O_K. Yeah. So she - she's right. That's a - but it's the - it's the - the - the following. Well it might be just good to know what it looks like. Cuz - Yeah. That's - Huh? That's uh cuz I'd mentioned scatter plots before but she's right  I mean  even before you get the scatter plots  just looking at a single feature Yeah. uh  looking at the distribution  is a good thing to do. Catal- uh - Combining the different possibilities of uh the parameters. I - I - I - I mean the - the - the scatter plot combining eh different n- two combination. combination of two  of energy and derivate - Yeah  but - but what she's saying is  which is right  is le- I mean  let's start with the - Before we get complicated  let's start with the most basic wh- thing  which is we're arguing that if you take energy - uh if you look at the energy  that  when two people are speaking at the same time  usually there'll be more energy than when one is right? Yeah. That's - that sort of hypothesis. And the first way you'd look at that  That's right. uh s- she's  you know  absolutely right  is that you would just take a look at the distribution of those two things  Yeah. much as you've plotted them here  You know  but just - but just - Yeah. just uh do it - Well in this case you have three. You have the silence  and that - that's fine. Yeah. So  uh with three colors or three shades or whatever  just - just look at those distributions. Yeah. And then  given that as a base  you can see if that gets improved  you know  or - or - or worsened by the - looking at regular energy  looking at log energy  we were just proposing that maybe it's - you know  it's harder to see with the log energy  Yeah. um and uh also these different normalizations  does a particular choice of normalization make it better? But I had maybe made it too complicated by suggesting early on  that you look at scatter plots because that's looking at a distribution in two dimensions. Yeah. Let's start off just in one  Yeah. uh  with this feature. Yeah. I think that's probably the most basic thing  before anything very complicated. Yeah. Yeah. Um And then we- w- I think we're agreed that I agree  yeah. pitch-related things are - are - are going to be a - a really likely candidate Uh-huh. to help. Um O_K. But since - uh your intuition from looking at some of the data  is that when you looked at the regular energy  that it did in fact usually go up  when two people were talking  Yeah. Yeah. Yeah  yeah  yeah. that's - eh you know  you should be able to come up with a measure which will match your intuition. And she's right  that a - that having a - But - having - having this table  with a whole bunch of things  with the standard deviation  the variance and so forth  Uh-huh. it's - it's - it's harder to interpret than just looking at the - Yeah. But - the same kind of picture you have here. It - it's curious but uh I f- I found it in the - in the mixed file  in one channel that eh in several - oh e- eh several times eh you have an speaker talking alone Mm-hmm. with a high level of energy Mm-hmm. eh in the middle eh a zone of overlapping Mm-hmm. with mmm less energy and eh come with another speaker with high energy and the Mm-hmm. overlapping zone has eh less energy. Yeah. So there'll be some cases for which - Because there reach very many @@ Right. But  the qu- So - So they'll be - This is - I w- want to point to visual things  But I mean they - there'll be time - There'll be overlap between the distributions  but the question is  Yeah. ""If it's a reasonable feature at all  there's some separation."" Yeah. Especially locally. So. Locally. And the other thing is I- just locally   yeah. Mm-hmm. And - Sorry. I - I was just going to say that - that right now we're just exploring. What you would imagine eventually  is that you'll feed all of these features into some Yeah. discriminative system. Yeah. Yeah. And so even if - if one of the features does a good job at one type of overlap  another feature might do a good job at another type of overlap. Yeah. Yeah. Yeah  this is the - Right. I mean the - the reason I had suggested the scatter f- p- features is I used to do this a lot  when we had thirteen or fifteen or twenty features to look at. um Because something is a good feature uh by itself  you don't really know how it'll behave in combination and so it's nice to have as many - as many together at the same time as possible in uh in some reasonable visual form. There's cool graphic things people have had sometimes to put together three or four in some funny - funny way. But it's true that you shouldn't do any of that unless you know that the individual ones  at least  have - Yeah. have some uh - Well  especially for normalizing. I mean  some hope Mm-hmm. it's really important to pick a normalization that matches the distribution for that feature. Mm-hmm. And it may not be the same for all the types of overlaps or the windows may not be the same. e- Actually  I was wondering  right now you're taking a - all of the speech  from the whole meeting  and you're trying to find points of overlap  but we don't really know which speaker is overlapping with which speaker  right? Right. Yeah. So I mean another way would just be to take the speech from just  say  Morgan  And just Jane and then just their overlaps  like - but by hand  by cheating  and looking at you know  if you can detect something that way  because if we can't do it that way  there's no No prayer. good way that we're going to be able to do it. That - You know  there might be something helpful and cleaner about looking at just individuals and then that combination alone. Yeah. Plus  I think it Mm-hmm. has more elegant - e- The m- the right model will be easier to see that way. So if - I don't know  if you go through and you find Yeah. Adam  cuz he has a lot of overlaps and some other speaker who also has e- enough speech and just sort of look at those Yeah. three cases of Adam and the other person and the overlaps  maybe - and just look at the distributions  maybe there is a clear Yeah. Uh-huh. pattern but we just can't see it because there's too many combinations of - of people Yeah. that can overlap. I had the same intuition last - last - last week. So. Yeah. Just seems sort of complex. I think it's - to start with it's s- your - your idea of simplifying  starting with something that you can see eh you know without the extra layers of - Right. Cuz if energy doesn't matter there  like - I don't think this is true  but what if To study individual? Sorry  what? Hmm? To study individual? Well  you - you - you don't have to study everybody individually but The - the - the - Well  to study the simplest case But - just simple case and to get rid of extra - Consider - the one that has the lot of data associated with it. Right. Cuz what if it's the case and I don't think this is true - That was a great overlap by the way. What if it's the case that when two people overlap they equate their - you know  there's a conservation of energy and everybody - both people talk more softly? I don't think this happens at all. Or - or what if what if the equipment - Or they get louder. what if the equipment adjusts somehow  there's some equalizing in there? Yeah or - Uh  I mean. no we don't have that. But. Well  but - O_K. But I think that's what I was saying about different types of Saturation. overlap. There are - there are different types  and within those types  like as Jose was saying  that sounded like a backchannel overlap  meaning the kind that's a friendly encouragement  like ""Mm-hmm.""  ""Great!""  ""Yeah!"" Yeah. And it doesn't take - you don't take the floor. Um  but  some of those  as you showed  I think can be discriminated by the duration of the overlap. Yeah. So. It - Actually the s- new student  Don  who um Adam has met  and he was at one of our meetings - He's getting his feet wet and then he'll be starting again in mid-January. He's interested in trying to distinguish the types of overlap. I don't know if he's talked with you yet. Yeah. But in sort of honing in on these different types and - I don't consi- Now I don't consider that possibility. This is a s- a general studio of the overlapping So maybe - Yeah. we're studying the - So it might be something that we can Well I - help by categorizing some of them and then  i- I - I - I would s- you know  look at that. actually still recommend that he do the overall thing because it would be the quickest thing for him to do. He could - You see  he already has all his stuff in place  he has the histogram mechanism  Yeah. he has the stuff that subtracts out - and all he has to do is change it uh uh from - from log to plain energy and plot the histogram and look at it. And then he should go on and do the other stuff Yeah. bec- but - Yeah  no. I didn't mean that - But this will - that - for you to do that  but I was thinking if - if Don and I are trying to get categories and we label some data for you  and we say this is what we think is going - Mm-hmm. Mm-hmm. So you don't have to worry about it. And here's the three types of overlaps. And we'll - we'll do the labeling for you. Yeah. Yeah. Hm- hmm. Um. Consider different class of overlap? Yeah  that we would be working on anyway. If there's time. Yeah. Then maybe you can try some different things for those three cases  and see if that helps  or - Yeah. This is the thing I - I comment with you before  that uh we have a great variation of th- situation of overlapping. Mm-hmm. And the behavior for energy is  uh log energy  is not uh the same all the time. Mm-hmm. And - But I guess I was just saying that - that right now uh from the means that you gave  I don't have any sense of whether even  you know  there are any significant number of cases for which there is distinct - and I would imagine there should be Yeah. some - you know  there should be - The distributions should be somewhat separated. Yeah. Uh and I - I would still guess that if they are not separated at all  Yeah. that there's some - there's - there's most likely something wrong in the way that we're measuring it. Yeah. Yeah. Um  but um For instance  I mean I wouldn't expect that it was very common overall  that when two people were talking at the same time  that it would - that it really was lower  although sometimes  as you say  it would. Yeah. Yeah. Yeah  no  that was - That was a jok- So. So. or a sort of  Yeah. a case where - where you would never know that unless you actually I mean. No. It could - it probably does happen sometimes. Yeah. go and look at Right. Yeah. Yeah. two individuals. So. Yeah. Mind if I turned that light off? The flickering is annoying me. O_K. It might the case  though  that the significant energy  just as Jose was saying  comes in the non-backchannel cases. Because in back- Most people when they're talking don't change their own energy when they get a backchannel  cuz they're not really predicting the backchannel. Mm-hmm. And sometimes it's a nod and sometimes it's an ""mm-hmm"". And the ""mm-hmm "" is really usually very low energy. Yeah. Yeah. So maybe those don't actually have much difference in energy. But all the other cases might. e- and the backchannels are sort of easy to spot s- in terms of their words or - I mean  just listen to it. So. Yeah. e- But - and - and again what they - what difference there was would kind of be lost in taking the log  so  Well  it would be lost no matter what you do. It just - as well. Yeah. Mmm  no  if it's - if i- if it's - Tone Well  it won't be as big. I mean  even if you take the log  you can - your model just has a more sensitive measures. So. Yeah. Sure  but tone might be very Yeah  you're ""mm-hmm"" tone is going to be very different. Yeah. Right. Right. You could imagine doing specialized ones for different types of backchannels  if you could - if you had a good model for it. Your ""mm-hmm"" detector. If - if you're - a- I guess my point is  if you're doing essentially a linear separation  taking the log first does in fact make it harder to separate. Right. Yeah. So it's - So  uh if you i- i- So i- if there - if there close to things it does Yeah. it's a nonlinear operation that does in fact change the distinction. If you're doing a non- if you're doing some fancy thing then - then yeah. And right now we're essentially doing this linear thing by looking across here and - and saying we're going to cut it here. Um and that - that's the indicator that we're getting. But anyway  yeah  we're not disagreeing on any of this  we should look at it more uh - more finely  but uh uh I think that - This often happens  you do fairly complicated things  and then you stand back from them and you realize that you haven't done something simple. So uh  if you generated something like that just for the energy and see  and then  a- a- a- as - as Liz says  when they g- have uh uh smaller um  more coherent groups to look at  that would be another interesting thing later. Uh-huh. Uh-huh. And then that should give us some indication - between those  should give us some indication of whether there's anything to be achieved f- from energy at all. And then you can move on to the uh uh more pitch related stuff. Mm-hmm. I - I - I think this is a good idea. O_K. Not consider the log Mm-hmm. energy. Yeah. @@ But then the - Have you started looking at the pitch related stuff at all  or - ? The - ? Pitch related? Harmonicity and so on? I - I'm preparing the - the program but I don't - I don't begin Preparing to - because eh Yeah. I saw your email and I agree with you Yeah. it's better to - I suppose it's better to - to consider the - the energy this kind of parameter Oh  that's not what I meant. bef- No  no. I - I - I - I - Well  we certainly should see this but I - I - I - I think that the harm- I certainly wasn't saying this was better than the harmonicity and pitch related things I was just saying I - I go on with the - with the Yeah. pitch  aha! O_K. Yeah  I was just saying - I - I - I - I understood uh that eh I - I had to finish by the moment with the and - and concentrate my - my energy in that problem. O_K. O_K. O_K. But I think  like  all these derivatives and second derivatives and all these other very fancy things  I think I would just sort of look at the energy and then get into the harmonicity as - as O_K. I go on a suggestion. with the pitch. Uh O_K. So maybe uh since w- we're trying to uh compress the meeting  um  I know Adam had some form stuff he wanted to talk about and did you have some? I wanted to ask just s- something on the end of this top- topic. So  when I presented my results about the uh distribution of overlaps and the speakers and the profiles of the speakers  Uh-huh. at the bottom of that I did have a proposal  and I had plan to go through with it  of - of co- coding the types of overlaps that people were involved in s- just with reference to speaker style so  Oh. you know  with reference - and you know I said that on my - in my summary  that That'd be great. Yeah  I remem- Right. you know so it's like people may have different amounts of being overlapped with or overlapping but that in itself is not informative without knowing what types of overlaps they're involved in so I was planning to do a taxonomy of types overlaps with reference to that. That would be great. That would be really great. Yeah. So  but it you know it's like Hmm. it sounds like you also have uh something in that direction. Is - is it - We have nothing - You know  basically  we got his environment set up. He's - he's a double-E_ you know. So. It's mostly that  if we had to label it ourselves  we - we would or we'd have to  to get started  but if - It - it would be much better if you can do it. You'd be much better at doing it also because you know  I - I'm not - Interesting. I don't have a good feel for how they should be sorted out  and I really didn't wanna go into that if I didn't have to. So if - If you're w- willing to do that or - or - Well maybe we can O_K. It would be interesting  though  to talk  maybe not at the meeting  Yeah. but at some other time about what are the classes. Mm-hmm. Yeah. Yeah. Mm-hmm. I think that's a research effort in and of itself  Yeah  it would be interesting. because you can read the literature  but I don't know how it'll turn out and  Yeah. It seems like we also s- with reference to a purpose  too  that we we'd want to have them coded. I would think it's interesting  yeah. You know  it's always an interesting question. Yeah. That'd be great. Yeah. Yep. That'd be really great. And we'd still have some funding O_K. I can do that. uh- uh- for this project  like probably  if we had to hire some - like an undergrad  because uh Don is being hhh. covered half time on something else - Mm-hmm. I mean  he - we're not paying him the full R_A-ship for - all the time. So. um If we got it to where we wanted - we needed someone to do that - I don't think there's really enough data where - where - Mm-hmm. Yeah  I see this as a prototype  Yeah. to use the only the - Yeah. the already transcribed meeting as just a prototype. I - I think a- a- another parameter we c- we - But - we can consider is eh the duration. Mm-hmm. Another e- e- m- besides eh the - the class of overlap  the duration. Because is possible eh some s- s- um eh some classes eh has eh a type of a duration  eh  a duration very short Mm-hmm. uh when we have - Yeah  definitely. Yeah  maybe - It may be correlated. we have overlapping with speech. Is possible Mm-hmm. to have. And it's interesting  I think  to consider the - the window of normalization  normalization window. Eh because eh if we have a type of  a kind of eh overlap  eh backchannel overlap  with a short duration  is possible eh to normali- i- i- that if we normalize eh with eh eh consider only the - the eh window eh by the left eh ri- eh side on the right side overlapping with a - a very eh oh a small window eh the - if the fit of normalization is eh mmm bigger eh in that overlapping zone eh very short Mm-hmm. Yeah  that's true. The window shouldn't be larger than the backchannel. I - I me- I - I understand. I mean that you have Yeah. eh you have a backchannel  eh  eh - you have a overlapping zone very short and you consider eh n- eh all the channel to normalize Mm-hmm. this very short eh - Mm-hmm. for example ""mmm mm-hmm hmm"" eh And the energy is not eh height eh I think if you consider all the channel to normalize and the channel is mmm bigger Mm-hmm. eh eh eh compared with the - with the overlapping eh duration  eh the effect is mmm stronger eh that I - I mean the - the e- effect of the normalization eh with the mean and the - and the variance Mm-hmm. eh is different that if you consider only a window compared eh with the n- the duration of overlapping. Not - You - you want it around the overlapping part. You want it to include something that's not in overlapping but - Yeah. Yeah. Yeah. Mm-hmm. but uh I - I don't know. Is - s- Yeah. Well it's a sliding window  right? So if you take the - the measure If - Mm-hmm. Yeah. in the center of the overlapped piece  Yeah. you know  there'd better be some- something. But if your window is really huge then yeah you're right you won't even - The portion of the - Yeah  This is the - of the backchannel won't - won't effect anything. But you - This is the - the idea  to consider only the - the small window Yeah. So. near - near - near the - the overlapping zone. You know  you shouldn't be more than like - You should definitely not be three times as big as your - as your backchannel. Yeah. Mm-hmm. Then you're gonna w- have a wash. And hopefully it's more like I'm not sure that's necessarily true. on the order of - Yeah? It is an empirical question  it seems like. Yea- Because - Yeah. because it - because Yeah. um again if you're just compensating for the gain  you know  the fact that this - this gain thing was crude  and the gain wh- if someone is speaking relatively at consistent level  just to - to give a - an extreme example  all you're doing is compensating for that. And then you still s- And then if you look at the frame with respect to that  it still should - should uh change Yeah  it depends how different your normalization is  as you slide your window across. I mean. That's something we don't know. Mm-hmm. It's possible to try it both ways  isn't it? Well  I mean we're also talking about in this small @@ a couple of different things. I mean  one is your analysis window and then the other is any sort of normalization that you're doing. Yeah I was talking about the n- normalization window. And the - And they could be quite different. Yeah. Yeah. Right. This was sort of where - Yeah. That's true. Yep. where we were last week. Yeah. But  anyway We - we'll have to look at some core things. Um. O_K. O_K. But that'd be great if - if you're marking those and - Great. O_K. um. Yeah. But it is definitely true that we need to have the time marks  Mm-hmm. and I was assuming that will be inherited because  Yep  I agree. if you have the words and they're roughly aligned in time Mm-hmm. via forced alignment or whatever we end up using  then you know  this student and I would be looking at the time marks and classifying all the frames inside those as whatever labels Coming off of the other - Yeah. Good. So  it wouldn't be Jane gave I wasn't planning to label the time marks. I can give you I was thinking that that would come from the engineering side  yeah. my transcription file  no? @@ I don't think you need to. Yeah. That should be linked to the words which are linked to time somehow  right? There you go. Well we're not any time soon going to get a forced alignment. So. Not now. Yeah. Um If it's not hand-marked then we're not going to get the times. Well  it's something that w- Well  we - we wouldn't be able to do any work without a forced alignment anyway  so somehow if - Yes once he gets going we're gonna hafta come up with one and Yes. Yeah. I mean w- I guess we could do a very bad one with Broadcast News. Good. So whatever you would label would be Good. attached to the words  I think. Great! Good  good. Mm-hmm. Yeah. Well again for the close mike stuff  That might be good enough. we could come up - take a s- take the Switchboard system or something  and - Yeah. Um It'd be worth a try. It would be interesting to see what we get. Just  you know  low-pass filter the speech and - Cuz there's - there's a lot of work you can't do without that  I mean  how - how would you - Yeah. You'd have to go in and measure every start and stop point next to a word is y- if you're interested in anything to do with words. So. Yep. It would be very inefficient. Yeah. Mm-hmm. Anyway So that'd be great. Good. O_K. Yeah. There's something we should talk about later but maybe not just now. But  uh  should talk about our options as far as the uh uh transcription Yep  if I_B_M doesn't - But. Well  w- O_K. Good. But Do we hafta turn - we'll do that later. Are we supposed to keep recording here? Yeah. Let's do that later. Yeah Right. Yeah. We'll talk about it later. Yeah. So uh Uh ""forms"". You had something on forms. Forms Next iteration of forms. Oops. Oh! Oh good  O_K. Um. Oh. How - So it's two pages per person? Nope. One's a digit form  one's a speaker form. Oh! So one is a one time only speaker form and the other is the digits. Oh  I see. Oh it's the same. Oh no no. Is - is new Is O_K. So don't fill these out. Alright. This is just the suggestion for uh what the new forms would look like. So  they incorporate the changes that we talked about. Date and time. Uh why did you switch the order of the Date and Time fields? This is rather a low-level  but On which one? On - on the new one  Time comes first and then Date  but I thought - Oh you mean on the digit form? This is - this is rather a low level question  but - Uh  because but it used - used to be Date came first. the user fills out the first three fields and I fill out the rest. Oh I see. Well  how would the - So it was intentional. It's an interesting observation  but it was intentional. How would the user know the time if they didn't know the date? Because the date is when you actually read the digits and the time and  excuse me  the time is when you actually read the digits  but I'm filling out the date beforehand. If you look at the form in front of you? that you're going to fill out when you read the digits? Yeah. you'll see I've already filled in the date but not the time. I always assumed - So the time is supposed to be pretty exact  because I've just been taking beginning time - Yeah  me too. time of the meeting. Yeah  Yeah  I've noticed that in the forms. I - yeah. The - the reason I put the time in  is so that the person @@ Me too. who's extracting the digits  meaning me  Oh! will know where to look in the meeting  Oh dear. We've been - But - to try to find the digits. we've been messing up your forms. I know. I am put - I am putting the beginning of the meeting. So you should call it  like  ""digits start time"". Or. And I haven't said anything. Yep. in - on there . Why - What - what were you putting in? Oh  well  I was saying if we started the meeting at Yeah. two thirty  I'd put two thirty  and I guess d- e- everyone was putting two thirty  and Yeah. Oh. No  it's about fifty fifty. I didn't realize there was ""uh oh I'm about to read this and I should"" - Actually it's about one third each. About one third of them are blank  about one third of them are when the digits are read  and about one third of them are when the meeting starts. Oh. So. This would be a radical suggestion but - I could put instructions? Nah. Ei- either that or maybe you could Yeah. maybe write down when people start reading digits on that particular session. But if I'm not at the meeting  I can't do that. I know  O_K. Yeah  he's been setting stuff up and going away. So. That's a good point. I see. Good point good point. For some reason he doesn't want to sit through every meeting that's - Yep  but that is the reason Name  Email and Time are where they are. Oh  O_K. Alright. Yeah. I rest my - And then the others are later on. Uh-huh. O_K. w- And the Seat is this number? Mm-hmm. Seat and Session. ""For official use only"" That's - ""use only"" Well  he's very professional. Actually you could - Well that does raise another question  which is why is the ""Professional use only"" line not higher? Why doesn't it come in at the point of Date and Seat? Oh. What? Because we're filling in other things. What? Well  because - If y- your - your professional use  you're gonna already have the date  and the s- What - which form are you talking about? Well I'm comparing the new one with the old one. This is the digit form. Oh. Oh you're talking about the digit form. The digit form doesn't - Yeah. Digit. Digit form. Oh! I wasn't supposed to - Yeah. Sorry. The digit - No  that's alright. The digit form doesn't have a ""for official use only"" line. Sorry. It just has a line  which is what you're supposed to read. That - uh O_K. @@ So on the digits form  Sorry about that. Yeah. everything above the line is a fill-in form and everything below the line is digits that the user reads. Yeah. O_K. Alright s- but I didn't mean to derail our discussion here  so you really wanted to start with this other form. No  either way is fine I just - You just started talking about something  and I didn't know which form you were referring to. Alright yeah  I was comparing - so th- this is - So I was looking at the change first. So it's like we started with this and now we've got a new version of it wi- with reference to this. So the digit form  we had one already. Now the f- the fields are slightly different. So the main thing that the person fills out um is the name and email and Yeah. time? Right. Ah! You do the rest? Yep. Just as uh - as I have Right. for all the others. What - And there's an addition of the native language  which is a bit redundant. This one has Native Language and this one does too. That's because the one  the digit form that has native language is the old form not the new form. Oh! Thank you. Thank you  thank you. There we go. Yeah. Oh  yeah. I'll catch up here. O_K  I see. ""South Midland  North Midland"" That's the old and that's the new. Yeah this was the problem with these categories  I - I picked those categories from TIMIT. I don't know what those are. Actually  the only way I know is from working with the database and having to figure it out. What - With TIMIT  yeah? uh-huh. What i- So is South Midland like Kansas? and North Midland like - like uh Illinois  or - ? So  I was gonna ask wh- w- Well yeah. Yeah. Nor- um - I mean. So - so what accent are we speaking? Western? By definition? And for simple for - for me? Is mean my native language Spanish - Probably Western  yeah. Well  Spanish? eh The original is the center of Spain and the beca- Yeah  I mean you could call it whatever you want. For the foreign language we couldn't classify every single one. So I just left it blank and you can put whatever you want. Because is different  the Span- uh the Spanish language from the - the north of Spain  of the south  of the west and the - Sure. But. So I'm not sure what to do about the Region field for English variety. Yeah. You know  when I wrote - I was writing those down  I was thinking  ""You know  these are great if you're a linguist "". Yeah. But I don't know how to - I don't know how to - I don't know how to categorize them. Actually even if you Yeah. t- If you're - if e- This wasn't developed by - th- these regions weren't - if y- if you're a T_I or M_I_T from nineteen eighty-five. Yeah Yeah. So I guess my only question was if - if you were a South Midland speaking region  person? Mm-hmm. Would you know it? Is that what you would call yourself? I don't know. Yeah. You know  I think if you're talking - if you're thinking in terms of places  as opposed to names different peop- names people have given to different ways of talking  I would think North Midwest  and South Midwest would be more common than saying Midland  right  I mean  I - Yeah. Now the usage - I went to s- Maybe we can give them a li- like a little map? with the regions and they just - No  I'm serious. No  that's not bad. Because i- at this - Yeah. it takes less time  and it's sort of cute there's no figure. in that side - in that side of the - the paper. Well. Well just a little - You know  it doesn't have all the detail  but you sort of - But what if you moved five times and - and uh Well  I was thinking you could have ma- multiple ones No  but you're categorized. That's the same - and then the amount of time - so  roughly. So. You could say  you know ""ten years on the east coast  Well  five years on the west coast"" or something or other. We - I think we don't want to get that level of detail at this form. I think that's alright if we want to follow up. But. I guess we don't really know. I mean I - As I said  I don't think there's a huge benefit to this region thing. It - it gets - The problem is that for some things it's really clear and usually listening to it you can tell right away if it's a New York or Boston accent  but New York and Boston are two - well  I guess they have the N_Y_C  but New England has a bunch of very different dialects and - Mm-hmm. and so does um Yeah  so I picked these regions cuz we had talked about TIMIT  and those are right from TIMIT. S- So do other places. Right. And so these would be satisfying like So. a speech research community if we released the database  but as to whether subjects know where they're from  I'm not sure because um I know that they had to fill this out for Switchboard. This is i- almost exactly the same as Switchboard regions or Oh. O_K. very close. Yeah. Um And I don't know how they filled that out. But th- if Midland - Yeah  Midland is the one that's difficult I guess. I think a lot of people - Yeah. Also Northwest you've got Oreg- Washington and Oregon now which uh y- people don't know if it's western or northern. Yeah  I certainly don't. I mean  I was saying I don't even know what I speak. It's like Northwest Oh  what is Northern? Am I speaking - Am I speaking Western? Well and what - and what's Northern? I think originally it was North - Northwest Northwest? Yeah. But - Yeah  so this is a real problem. I don't know what to do about it. Yeah. I wouldn't know how to characterize mine either. And - and so I would think - I c- I would say  I've - I've got a mix of California and Ohio. I think at the first level  for example  we speak the same. I don't know. our - our dialects Uh-huh. Or whatever you - region are the same. But I don't know what it is. So. Well  you have a like techno-speak accent I think. a techno-speak accent? A techno- Yeah  you know? A - a geek region? Well it's - Geek region. I mean I - you can sort of identify it f- It's - it's - Is different. Is different. not - not that that's - but - but maybe that - maybe we could leave this and see what people - See what people choose and then um let them just fill in if they don't - I mean I don't know what else we can do  cuz - I'm wondering about a question like  ""Where are you from mostly?"" Yeah. But I - I'm s- Yeah. I'm - now that you mentioned it though  I am - really am confused by ""Northern"". I agree. I really am. I mean  I agree. Yeah. I agree. if - if you're in New England  that's North. If you're - i- if you're Scandinavian  the Minnesota area's north. Uh yeah. That's - That's North Midland. But that's also North Midland  right? Yeah. Oh  @@ . - O_K. And - and - and Oregon and - Yeah. Of course  that's very different from  like  Michigan  and Oregon and Washington are - are Western  but Mmm. or - they're also Northern. Mm-hmm. uh  Idaho? Well there are hardly any subjects from Idaho. Montana? No problem. Just rule them out. There's only a few people in Idaho. There are hardly any subjects from ""beep"" Yeah. Sorry. No  that's - And - is - in those - Maybe - Maybe we - Maybe we should put a little map and say ""put an X_ on where you're from""  Yeah really. And if you put - We could ask where they're from. Yeah. But- It'd be pretty simple  yeah. Yeah. We went back to that. If you put eh the state? Well well we sort of - Where are you from mostly? We - we went - we went around this and then a lot of people Uh-huh. ended up saying that it - Mm-hmm. You know. Well  I like the idea of asking ""what variety of English do you speak"" as opposed to where you're from Yeah. Because th- if we start asking where we're from  again you have to start saying  ""well  is that the language you speak or is that just where you're from? "" Hmm? Right. Right. Yeah. I mean it gives us good information on where they're from  but Let's - Mm-hmm. And - that doesn't tell us anything - well  enough about their - We could always ask them if they're from - I mean. So - so I would say Germany like - You know am I speaking with German accent I don't think so. Oh. Right. Well  see  I'm thinking ""Where are you from mostly "" Oh  O_K yeah. because  you know  then you have some - some kind of subjective amount of time factored into it. Yeah. Yeah. Yep. Yeah. Yeah  I guess I could try to put - squeeze in a little map. I mean there's not a lot of r- of room I'd say  uh  ""Boston  New York City  the South and Regular"". Well - I think of those  Northern is the only one that I don't even know what they're meaning. And - And - Oh  I don't know. Yeah. Yeah. That's a joke. That's - So let's make it up. S- I mean  who cares. Right? We can make up our own - So we can say ""Northwest""  ""Rest of West"" or something. You know. ""West"" and Ye- hhh. I don't think the Northwest people speak any differently than I do. Um I mean. It doesn't even - Yeah  exactly. That's not really a region. ""Do you come from the Louisiana Purchase?"" I - So we could take out ""North"" - And usually here - people here know what is their ""Northern"". @@ kind of mmm lang- English language? That - that's exactly what we're arguing about. We don't know. eh here- That's - Yeah  w- It's - In - Is easy for people to know? It's - it's harder in America anywhere else  basically. because you have - I mean some of them are very obvious. If you - if you talk to someone speaking with Southern drawl  you know. N- m- Yeah. Yeah  or Boston. Or Boston  yeah. I can't do it  but - Or Boston? And those people  if you ask them to self-identify their accent they know. Yeah. Yeah. Yeah  they do. They know very well. Yeah I agree I agree. I agree. They know they don't speak the same as the But And they're proud of it. day o- Yeah. Yeah  exactly. is Boston New England? It's identity thing. And they're glad to tell you. @@ style. Well. Depends who you ask  I suppose. W- Oh. I guess that's the problem with these categories. But that's why they have New York City but - Well  we ca- Well  Boston's @@   too . Well  why can't we just say characterize - Or - something like char- characterize your accent ""Characterize your accent if you can."" and - and so I would say  ""I don't know"". Yeah. Right  which probably means you have a very - But someone from Boston with a really strong coloration would know. And so would an R_less Maine - And that's actually good. Yeah. or something  yeah. I was - I was thinking of something along that line because if you don't know  How- Good. then  you know  ruling out the fact that you're totally inept or something  Hmm. if somebody doesn't know  it probably means their accent isn't very strong compared to the sort of Well  I mean  midwest Hmm? it wasn't that long ago that we had somebody here who was from Texas who was absolutely sure that he didn't have any accent left. standard. And - and had - he had a pretty O_K  so. I propose  take out Northern noticeable drawl. add  don't know. Oh. Yeah. I - I would say more - more sweepingly  ""how would you characterize your Yeah. accent?"" So you want to change the instructions also not just say region? W- Well  I think this discussion has made me think that's s- something to consider. I don't know if I - if I read this form  I think they're going to ask it - they're going to answer the same way if you say  ""What's variety of English do you speak? Region."" as if you say ""what variety of region - region do you speak? Please characterize your accent?"" They're going to answer the same way. I guess - Well  I was not sure that - I - Mmm. So. I was suggesting not having the options  just having them - Oh  I see. Huh. Well what we talked about with that is is so that they would understand the granularity. Yes  but if  as Liz is suggesting  people who have strong accents know that they do - I mean that's what I had before  and you told me to list the regions to list them. and are - Each - each one has pros and cons I mean we - we - Right. Well  I know. Right. Right. So. That's true. Yeah last week - last week I was sort of r- arguing for having it wide open  but then everybody said ""Oh  no  but then it will be hard to interpret because some people will say Cincinnati and some will say Ohio"". And. I mean I had it wide open last week and - and you said TIMIT. What if we put in both? Yeah. Yeah. And - Would people - That's what the ""Other"" is for. No  I mean what if we put in both ways of asking them? So. One is Region and the another one is ""if you had to characterize yourself - your accent  what would you say?"" Won't they answer the same thing? Well they might only answer only one of the questions but if Yeah that's fine. You know. They might say ""Other"" for Region because they don't know what category to use Actually - Right. It just - but they might have something - because it is easier to have it open ended. And we - we might learn from what they say  as to which one's a better way to ask it. W- But - I - Cuz I really don't know. This is just a small thing but @@ um It says ""Variety"" and then it gives things that e- have American as one of the choices. But then it says ""Region""  but Region actually just applies to uh  U_S  right? Right. I mean that's why I put the ""Other"" in. Well  we thought about it. Ah  O_K. Yeah  O_K. We just - We sort of thought  ""yes  -"" S- y- y- I mean - At the last meeting  my recollection was that we felt people would have uh less - that - that there are so many types and varieties of these other languages and we are not going to have that many subjects from these different language groups and that it's a Yep. huge waste of - of space. O_K. So I mean  I - I mean the way I had it last time was Region was blank  it just said Region colon. That's what I thought. Yeah. Yeah. And - and I think that that's the best way to do it  because - because of the problems we're talking about but what we said last week  was no  put in a list  so I put in a list. So should we go back to - Maybe we can make the list a little smaller. Well  certainly dropping ""Northern "" I think is right  because none of us know what that is. Cuz  I mean - And keeping ""Other""  and then maybe this North Midland  we call it ""North Midwest"". South Midwest  or just - Yes I - South Midwest. Does that make sense? I - I think so. Yeah. South Midwest? That would help me - Yeah. Cuz - U- unless you're from Midland  Kansas. But. Yeah. Midland - I don't know where Midland is There's a - Or Midland - Midland - Is ""Midwest"" one word? Is it Midland - Midland - Midland  Texas or Midland  Kansas? I forget. Y- yeah  one w- But there's a town. Oh. in - in there. I forget what it is @@ . I don't think that's what they mean. But  yeah. So. Kansas would be South Midland. Right? Yeah. Y- yeah. And - and wouldn't - Yeah. Southern Midland. @@ So  th- And Colorado  right across the border  would be I'm from Kansas  actually. North Midland. Yeah. Colora- Oh  right. And then  the - And uh - the - dropping North  so it would be Western. It's just one big shebang  where  of course  you have huge variation in dialects  but - But you do in the others  too. So. But that's true of New England too. but so do you - Yeah. So. I mean only one - Yeah. Yeah. Yeah. Well  I shouldn't say that. I have no clue. I was going to say the only one that doesn't have a huge variety is New York City. But I have no idea whether it does or not. It does seem - I mean. I - I would U- think that these categories would be more - w- would be easier for an an- analyst to put in rather than the subject himself. I think that - that was what happened with TIMIT  was that it was an analyst. O_K. Wait a minute. Where does - Yeah  I don't know how it came from. Where does - d- w- O_K. Where - Where's - where does uh New - New York west of - west of uh New York City and Pennsylvania uh and uh So. That's New England I think. Yeah. New England N- No  it's not. Oh  no. I sort of thought they were part of the - one of the Midlands. Oh no. No  no. No. Pennsylvania is not - ""Other""  it goes under ""Other""  definitely under ""Other"". Well  you know  Pennsylvania has a pretty strong dialect and it's totally different than - Pennsylvania - Yeah. Pennsylvania is not New England. and uh New Jersey is not New England and Maryland is not New England and none of those are the South. O_K. So. Another suggestion. Yeah. Rather than have circle fill in forms  say ""Region  open paren  E_G_ Southern comma Western comma close paren colon."" O_K. O_K! That's good. Yeah. Fine by me  fine by me. Sure! I like that. Yeah. Let's just - And we'll see what we get. Yeah. We're all sufficiently tired of this Be easier on the subjects. that we're agreeing with you. I think that's fine. So. No. I think - I like that. I like that. You like it? O_K. Yeah  I do. Good. Actually  maybe we do one non-English one as well. Southern  Cockney? Yeah  and - Yeah. Is that a real accent? Sure  yeah! Yeah. How do you spell it? I think that's fine. Cockney? C_O - N_ E _Y? Yeah. You could say Liverpool. Liverpuddlian. Yeah. Actually  Liverpool doesn't l- Yeah. It's - Alright. Well. Well. I mean  pure - O_K  we'll do it that way. Actually  I like that a lot. O_K. Because that get's at both of the things we were trying to do  the granularity  and the person can just self-assess and we don't have to argue about what these regions are. That's right. Yeah. O_K. And it's easy on the subjects. Yep. Now I have one suggestion on the next section. Mm-hmm. Mm-hmm. So you have native language  you have region  and then you have time spent in English speaking country. Now  I wonder if it might be useful to have another open field saying ""which one parenthesis S_ paren- closed parenthesis"". Cuz if they spent time in - in Britain and America - Yes. It doesn't have to be ex- all - at all exact  just in the same open field format that you have. Yep  just which one. I think that's fine. Mm-hmm. Mm-hmm. with a - with an S_ ""which one sss  optional S_. O_K. Yeah. We uh - We done? Yep. Yeah  that's good. O_K. um s- e- Any - any other uh open mike topics or should we go right to the digits? Um  did you guys get my email on the multitrans? That - O_K. Isn't that wonderful! Yeah. Excellent! Thank you! I'm s- Yeah. So. So. I - I have a version also which actually displays all the channels. I ha- It's really great. But it's hideously slow. So you - this is n- Dan's patches  Dan Ellis's patches. The - what - the ones I applied  that you can actually do are Dan's  because it doesn't slow it down. M- Fantastic! Just uses a lot of memory. So when you say "" slow ""  does that mean to - No  the - the one that's installed is fine. It's not slow at all. I wrote another version. Which  instead of having the one pane with the one view  It has multiple panes with the views. Yeah. Mm-hmm. But the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls. Mm-hmm. It's really bad. It's - So  it - it's the redrawing of the w- That's a consideration. Mm-hmm. oh uh-huh  w- as you move. As you play  as you move  as you scroll. Just about anything  and it - it was so slow it was not usable. And this'll be a - So that's why I didn't install it and didn't pursue it. hav- having the multiwave will be a big help cuz - in terms of like disentangling overlaps and things  Oh yeah. that'll be a big help. So. Yeah. I think that the one Dan has is usable enough. It doesn't display the others. It displays just the mixed signal. Mm-hmm. But you can listen to any of them. That's excellent. He also has version control which is another nice Yeah. e- so you - No  he suggested that  but he didn't - e- the patches that you - It's not installed. Oh  I thought it was in one of those patches. No. No. Oh O_K. Well. So is there any hope for actually displaying Alright. the wave form? Um  not if we're going to use Tcl-T_K O_K. At least not if we're going to use Snack. I mean you would have to do something ourselves. Well  or use the one that crawls. O_K. Well  I'm - I probably would be trying to use the - whatever's there. And Why don't we - we see how Dan's works and if it - it's useful to have the - Yeah. If we really need the display - I mean. I wonder - I'm just wondering if we can display things other than the wave form. So. Suppose we have a feature - a feature stream. And it's just  you know  a - a Yeah. uni-dimensional feature  varying in time. And we want to plot that  instead of the whole wave form. I mean. Yeah. That might be faster. Right? So. Yeah. We - we could do that but that would mean changing the code. I mean this isn't a program we wrote. Yeah. This is a program that we got from someone else  O_K. and we've done patches on. O_K. Mm-hmm. Yeah. Well  I'll talk to you about it and we can see but Cou- So. Yeah. i- e- I mean  y- it's definitely great to have the other one. That's - If there was some - Is there some way to have someone write patches in something faster and - and - link it in  or something? Or is that - Not easily. I mean y- yes we could do that. You could - you can write widgets in C_. Yeah. And try to do it that way but I just don't think - it - Let's try it with Dan's and if that isn't enough  Right. we can do it otherwise. I think it is  cuz when I was playing with it  the mixed signal has it all in there. And so it's really - It's not too bad to find places in the - in the stream O_K. where things are happening. And it's also - Hmm? So I - I don't think it'll be bad. also the case that - that uh this multi-wave thing is proposed to the - So. Dan proposed it to the Transcriber central people  and it's likely that uh - So. And - and they responded favorably looks as though it will be incorporated in the future version. Oh. They said that the only reason they hadn't had the multi- the parallel uh stream one before was simply that they hadn't had time to do it. And uh Yeah. so it's likely that this - this may be entered into the ch- this central @@ . They may well have not had much demand for it. And if - if - Well that's - that's - that's true  too. Yeah. This is a - Yeah. So. You mean they could - they could do it and it would be fast enough if they do it? Or - ? a useful thing for us. Oh. No. Depends on how much work they did. I just mean - I just mean that it's - that - that his - So. Oh . This one that we now have Mm-hmm. does have the status of potentially being incorporated l- likely being incorporated into the central code. O_K. Now  tha- Now  if we develop further then  y- uh  I don't - I mean it's - I think it's a nice feature to have it - I think if - if - if one of us sat down and coded it  so that it could be displayed fast enough set that way. I'm sure they would be quite willing to incorporate it. Mm-hmm. But it's not a trivial task. O_K. Mm-hmm. Yeah. I just like the idea of it being something that's  you know  tied back into the original  so that other people can benefit from it. Yeah. Yeah. However. I also understand that you can have widgets that are very useful for their purpose and that you don't need to always go that w- route. Yeah. O_K. anyway  shall we do digits? Yeah. Yeah. Let's do digits  uh  and then we'll turn off the mikes  and then I have one other thing to discuss. O_K. I actually have to leave. So. O_K. Um. I mean I had to leave at three thirty  Uh-oh. so I can - Oh. O_K. Well  you want to go first? Or. Well  I can wait for the digits but I can't stay for the discussion I c- I have to make a call. So. O_K. Well  we'll talk to you about it - Well  should we - e- should we switch off the g- Um. Do you wanna go do digits or do you wanna just skip digits? No  I can do digits if - Then - if - But I don't wanna butt in  Alright. or something. You go ahead. But if there's something on the rest of the - I'm - I'll be around just have to make call before quarter of. So. Mm-hmm. Uh So I - Or we can talk about it. Ke- Why don't you read the digits? O_K. Alright. Yeah  why don't you read the digits and then you can go. Oh  this is the new one. Yeah. Yeah  don't - Alright. The - Don't read the old one. And the time is. O_K. This is transcript two seven five one  two seven seven zero nine two five four four O_ four O_ one six zero five nine zero seven one seven nine zero eight three eight two three four zero zero seven zero three zero six four three seven seven six eight nine eight four nine nine five one O_ zero zero eight one zero six three four four two five five nine six seven zero seven eight O_ five three three Transcript uh two seven one one dash two seven three zero. seven five seven six eight eight seven zero nine seven four four four O_ O_ one nine zero zero one six seven two two nine three four six one seven four five seven zero one five s- five six four two nine five O_ six seven eight zero seven five six O_ one five nine zero four four zero five one five two two two eight one O_ two four O_ three four five seven one eight two Transcript two six five one  two six seven O_. four five zero four seven nine seven two seven one three six five eight three O_ eight nine six zero five six O_ zero one two zero two four three eight two five two zero seven seven eight three six seven six seven nine seven one seven eight nine O_ O_ two two one three seven two five five three five seven one five three eight four eight one one zero Transcript number two six seven one dash two six nine zero five six seven O_ eight three O_ nine two two O_ three six O_ seven O_ four zero six one two seven one O_ one two four three four zero six seven two six four seven eight seven four eight three O_ nine O_ zero one zero eight nine nine three one nine four two seven seven five five seven five two Transcript two six nine one  two seven one O_. six nine seven eight nine zero zero two six eight two two four one four zero eight two three three three three four nine two four five zero six five six O_ six eight four one three four nine three four O_ eight six zero one two three five two seven one eight four eight six six six two O_ seven one O_K O_K. Turn it off. But wait till he - O_K. And ",A typical progress report meeting for the ICSI Meeting Recorder Group at Berkeley. Each of the group reported their most recent progress  and any results they have achieved. This then prompted discussion about the reasons behind such findings  which were for the most part not as expected. Topics the group touched upon included spectral subtraction  phase normalization  Voice activity detection  along with comparisons between systems. *NA* A couple of issues have arisen that need to be looked into further such as DC-offset and effects of PZM signals. Speaker Fn002 is worried about running VTS in the cepstral domain  because it requires a lot of work  and it is not clear that it will be much better than running it in the Mel domain. Similarly  since at the next stage of the project data will have marked boundaries  it is not clear that voice-activity detection is worth pursuing. Speaker me026 has been trying mean subtraction on the SRI system  with good improvement for the far mike  though worse on near mike. This contradicts previous findings for HTK  though he has some theories to explain the difference. Has also been working on different phase normalization techniques  with no luck. Speaker Mn007 has also been looking at differences  differences between the SRI system and the groups Aurora project  and again  there are a number of possible explanations. He has also been looking at a problem with the VAD and SNR. Mn052 has sorted bugs in implementation of wiener filtering  and has been investigating smoothing and also SNR. Fn002 is ready to run experiment investigating VTS in the cepstral domain. Speaker me006 is still working on his proposal. 
"I guess. O_K  we're on. So just make sure that th- your wireless mike is on  if you're wearing a wireless. Check one. Check one. And you should be able to see which one - which one you're on by  uh  watching the little bars change. So  which is my bar? Mah! Number one. Yep. Sibilance. Sibilance. So  actually  if you guys wanna go ahead and read digits now  as long as you've signed the consent form  that's alright. Are we supposed to read digits at the same time? No. Oh  O_K. No. Each individually. We're talking about doing all at the same time but I think cognitively that would be really difficult. To try to read them while everyone else is. Everyone would need extreme focus. So  when you're reading the digit strings  the first thing to do is just say which transcript you're on. Other way. We m- We may wind up with ver- We - we may need versions of all this garbage. For our stuff. Yeah. Yeah. Um. So the first thing you'd wanna do is just say which transcript you're on. So. Yeah. You can see the transcript? There's two large number strings on the digits? So you would just read that one. And then you read each line with a small pause between the lines. And the pause is just so the person transcribing it can tell where one line ends and the other begins. And I'll give - I'll read the digit strings first  so can see how that goes. Um. Again  I'm not sure how much I should talk about stuff before everyone's here. Mmm. Well  we have one more coming. O_K. Well  why don't I go ahead and read digit strings and then we can go on from there. So this is transcript three six five one three six seven O_. Three five one nine O_ three six four O_ two three O_ eight seven three nine eight seven five nine Uh  strike that. Eight seven nine five. nine O_ O_ six one zero zero one two two three five four five one O_ five two one Uh  five six four seven six seven eight O_ two one four O_ four six zero five five eight zero two eight. one six eight two eight two nine three. O_K. Well  we can start doing it. O_K. This is Transcript three six three one three six five O_. three one five four two nine seven six three nine five seven one six seven four four six seven eight nine zero four three zero two four nine two six nine one seven four one two three four zero four seven nine three seven four five six eight three O_ nine nine three four seven O_ seven zero nine O_- one seven one two. This is transcript three five seven one three five nine O_. Zero nine six zero. One. Two. Three zero zero zero. Five one two. Six four O_ one nine. Seven three. Eight eight eight. Nine. O_. Zero zero three one two nine eight. Two three five three three O_. Four nine Four nine one zero five zero seven. Six. Seven O_ five three one. Eight zero six two zero. O_ one five. Zero three eight three two. This is transcript three five nine one three six one zero. one four two six six three six five zero four five O_ five six seven two eight four nine nine nine O_ O_ O_ zero eight eight three one two four one five seven five O_ one five three two O_ six six eight six seven two six four nine one seven six zero zero eight eight nine eight seven eight five nine O_ O_ one two eight O_. This is transcript three five five one  three five seven O_. O_ nine O_ eight O_ two O_ zero one O_ O_ seven four three four zero one four two one eight five four seven eight eight six eight two seven eight O_ six six four five O_ nine zero zero one one five two six O_ three four seven six three one zero zero five six eight two seven nine two nine five nine O_ four two three. Thanks. So  uh  just also a note on wearing the microphones. All of you look like you're doing it reasonably correctly  but you want it about two thumb widths away from your mouth  and then  at the corner. And that's so that you minimize breath sounds  so that when you're breathing  you don't breathe into the mike. Um. Yeah  that's good. And uh - So  everyone needs to fill out  only once  the speaker form and the consent form. And the short form - I mean  you should read the consent form  but uh  the thing to notice is that we will give you an opportunity to edit a- all the transcripts. So  if you say things and you don't want them to be released to the general public  which  these will be available at some point to anyone who wants them  uh  you'll be given an opportunity by email  uh  to bleep out any portions you don't like. Um. On the speaker form just fill out as much of the information as you can. If you're not exactly sure about the region  we're not exactly sure either. So  don't worry too much about it. The - It's just self rating. Um. And I think that's about it. I mean   should I - Do you want me to talk at all about why we're doing this and what this project is? or - ? Um  yeah. No. There was - there was - Let's see. Does Nancy know that we're meeting in here? Oh - She got an emai- she was notified. I sent an email. Oh yeah  she got an e- Yeah  yeah. Whether she knows is another question. Um. So are the people going to be identified by name? Well  what we're gonna - we'll anonymize it in the transcript. Right. Um  but not in the audio. O_K. So  then in terms of people worrying about  So the- uh  excising things from the transcript  it's unlikely. Since it - it does- isn't attributed. Oh  I see  but the a- but the - but the - Right  so if I said  ""Oh  hi Jerry  how are you?""  we're not gonna go through and cancel out the ""Jerry""s. Yeah. Sure. Um  so we will go through and  in the speaker I_D tags there'll be  you know  M_one O_ seven  M_one O_ eight. Right. Right. Um  but uh  um  it w- uh  I don't know a good way of doing it on the audio  and still have people who are doing discourse research be able to use the data. O_K. Mm-hmm. No  I - I wasn't complaining  I just wanted to understand. Yep. Right. O_K. Well  we can make up aliases for each of us. Yeah  I mean  whatever you wanna do is fine  but we find that - We want the meeting to be as natural as possible. Right. O_K. O_K. So  we're trying to do real meetings. Right. And so we don't wanna have to do aliases and we don't want people to be editing what they say. Right. Right. So I think that it's better just as a pro- post-process to edit out every time you bash Microsoft. You know? Mm-hmm. Right. Um  O_K. So why don't you tell us briefly your - give - give your e- normal schpiel. O_K. So th- Um. So this is - The project is called Meeting Recorder and there are lots of different aspects of the project. Um. So my particular interest is in the P_D_A of the future. This is a mock-up of one. Yes  we do believe the P_D_A of the future will be made of wood. Um. The idea is that you'd be able to put a P_D_A at the table at an impromptu meeting  and record it  and then be able to do querying and retrieval later on  on the meeting. So that's my particular interest  is a portable device to do m- uh  information retrieval on meetings. Other people are interested in other aspects of meetings. Um. So the first step on that  in any of these  is to collect some data. And so what we wanted is a room that's instrumented with both the table top microphones  and these are very high quality pressure zone mikes  as well as the close talking mikes. What the close talk- ng- talking mikes gives us is some ground truth  gives us  um  high quality audio  um  especially for people who aren't interested in the acoustic parts of this corpus. So  for people who are more interested in language  we didn't want to penalize them by having only the far field mikes available. And then also  um  it's a very  very hard task in terms of speech recognition. Um. And so  uh  on the far field mikes we can expect very low recognition results. So we wanted the near field mikes to at least isolate the difference between the two. So that's why we're recording in parallel with the close talking and the far field at the same time. And then  all these channels are recorded simultaneously and framed synchronously so that you can also do things like  um  beam-forming on all the microphones and do research like that. Our intention is to release this data to the public  um  probably through f- through a body like the L_D_C. And  uh  just make it as a generally available corpus. Um. There's other work going on in meeting recording. So  we're - we're working with S_R_I  with U_W  Um. NIST has started an effort which will include video. We're not including video  obviously. And uh - and then also  um  a small amount of assistance from I_B_M. Is also involved. Um. Oh  and the digit strings  this is just a more constrained task. Um. So because the general environment is so challenging  we decided to - to do at least one set of digit strings to give ourselves something easier. And it's exactly the same digit strings as in T_I-digits  which is a common connected digits corpus. So we'll have some  um  comparison to be able to be made. O_K. Anything else? No. O_K  so when the l- last person comes in  just have them wear a wireless. It should be on already. Um. Either one of those. And uh  read the digit strings and - and fill out the forms. So  the most important form is the consent form  so just be s- be sure everyone signs that  if they consent. I'm sure it's pretty usual for meetings that people come late  so you will have to leave what you set . Yeah. Right. And uh  just give me a call  which  my number's up there when your meeting is over. Yep. And - I'm going to leave the mike here but it's n- Uh  but I'm not gonna be on so don't have them use this one. It'll just be sitting here. Thank you. Input? Yeah. There we go. By the way  Adam  we will be using the  uh  Yep. screen as well. So  you know. Wow! Organization. So you guys who got email about this oh f- uh  Friday or something about what we're up to. No. No. I got it. What was the nature of the email? Oh  this was about um  inferring intentions from features in context  and the words  like ""s- go to see""  or ""visit""  or some- Wel- we- I - uh - I - I - @@ You didn't get it? I don't think I did. I guess these g- have got better filters. Cuz I sent it to everybody. You just blew it off. O_K. Ah. It's really simple though. So this is the idea. Um. We could pursue  um  if we thought it's - it's worth it but  uh  I think we - we will agree on that  um  to come up with a - with a sort of very  very first crude prototype  and do some implementation work  and do some - some research  and some modeling. So the idea is if you want to go somewhere  um  and focus on that object down - Oh  I can actually walk with this. This is nice. down here. That's the Powder-Tower. Now  um  we found in our  uh  data and from experiments  that there's three things you can do. Um  you can walk this way  and come really  really close to it. And touch it. But you cannot enter or do anything else. Unless you're interested in rock climbing  it won't do you no good standing there. It's just a dark alley. But you can touch it. If you want to actually go up or into the tower  you have to go this way  and then through some buildings and up some stairs and so forth. If you actually want to see the tower  and that's what actually most people want to do  is just have a good look of it  take a picture for the family  you have to go this way  and go up here. And there you have a vre- really view - It exploded  the - during the Thirty -years-war. Really uh  interesting sight. Mmm. And um  these uh - these lines are  um  paths  or so- That's ab- er  i- the street network of our geographic information system. And you can tell that we deliberately cut out this part. Because otherwise we couldn't get our G_I_S system to take - to lead people this way. It would always use the closest point to the object  and then the tourists would be faced  you know  in front of a wall  but it would do them absolutely no good. So  what we found interesting is  first of all  intentions differ. Maybe you want to enter a building. Maybe you want to see it  take a picture of it. Or maybe you actually want to come as close as possible to the building. For whatever reason that may be. What's it - what's it made out of? Um  r- red limestone. So maybe you would wanna touch it. Yeah  maybe you would want to touch it. Um. Okay  I - This  um - These intentions  we - w- w- we could  if we want to  call it the - the Vista mode  where we just want to - eh - s- get the overview or look at it  the Enter mode  and the  well  Tango mode. I always come up with - with silly names. So this ""Tango"" means  literally translated  ""to touch"". So - But sometimes the - the Tango mode is really relevant in the - in the sense that  um  if you want to  uh - If you don't have the intention of entering your building  but you know that something is really close to it  and you just want to approach it  or get to that building. Consider  for example  the Post Office in Chicago  a building so large that it has its own zip code. So the entrance could be miles away from the closest point. So sometimes it m- m- m- makes sense maybe to d- to distinguish there. So  um  I've looked  uh  through twenty some - Uh  I didn't look through all the data. um  and there - there's uh  a lot more different ways in people - uh  the ways people phrase how to g- get - if they want to get to a certain place. And sometimes here it's b- it's a little bit more obvious - Um. Maybe I should go back a couple of steps and go through the - No  O_K come in  sit down. If you grab yourself a microphone. O_K. You need to sign some stuff and read some digits. Well  you can sign afterwards. O- or later. O_K. You have to al- also have to read some digits. Afterwards. O_K. Afterwards is fine. O_K  go ahead. They are uncomfortable. @@ Small? Mm-hmm. Really small? O_K. I see. O_K. Yep. Thank you. O_K  but that was our idea. Is - And it - it - it - it- it also has to be switched on  Nance. No  that one's already on  I thought he said. Yeah. I - I think - It's on? O_K  good. O_K. It's on. O_K. That was the idea. Um  people  when they w- when they want to go to a building  sometimes they just want to look at it. Sometimes they want to enter it. And sometimes they want to get really close to it. That's something we found. It's just a truism. And the places where you will lead them for these intentions are sometimes ex- in- incredibly different. I - I gave an example where the point where you end up if you want to look at it is completely different from where - if you want to enter it. So  this is sort of how people may  uh - may phrase those requests to a - a - a mock-up system at least that's the way they did it. And we get tons of - of these ""how do I get to""  ""I want to go to""  but also  ""give me directions to""  and ""I would like to see"". And um  what we can sort of do  if we look closer a- closer at the - the data - That was the wrong one. um  we can look at some factors that may make a difference. First of all  very important  and um  that - I've completely forgot that when we talked. This is of course a crucial factor  ""what type of object is it?"" So  some buildings you just don't want to take pictures of. Or very rarely. But you usually want to enter them. Some objects are more picturesque  and you - more f- more highly photographed. Then of course the - the actual phrases may give us some idea of what the person wants. Um. Sometimes I found in the - Uh  looking at the data  in a superficial way  I found some s- sort of modifiers that - that m- may also give us a hint  um  ""I'm trying to get to"" Nuh? ""I need to get to"". Sort of hints to the fact that you're not really sightseeing and - and just f- there for pleasure and so forth and so on. And this leads us straight to the context which also should be considered. That whatever it is you're doing at the moment may also inter- influence the interpretation of - of a phrase. So  this is  uh  really uh  uh  uh - My suggestion is really simple. We start with  um - Now  Let me  uh  say one more thing. What we do know  is that the parser we use in the SmartKom system will never differentiate between any of these. So  basically all of these things will result in the same X_M_L M_-three-L_ structure. Sort of action ""go""  and then an object. Yeah? and a source. So it's - it's - it's way too crude to d- Mm-hmm. capture those differences in intentions. So  I thought  ""Mmm! Maybe for a deep understanding task  that's a nice sort of playground or first little thing."" Where we can start it and n- sort of look - ""O_K  we need  we gonna get those M_-three-L_ structures. The crude  undifferentiated parse. Interpreted input. We may need additional part of speech  or maybe just some information on the verb  and modifiers  auxiliaries. We'll see. And I will try to - to sort of come up with a list of factors that we need to get out of there  and maybe we want to get a g- switch for the context. So this is not something which we can actually monitor  now  but just is something we can set. And then you can all imagine sort of a - a constrained satisfaction program  depending on - on what  um  comes out. We want to have an - a structure resulting if we feed it through a belief-net or - or something along those lines. We'd get an inferred intention  we - we produce a structure that differentiates between the Vista  the Enter  and the  um  Tango mode. Which I think we maybe want to ignore. But. That's my idea. It's up for discussion. We can change all of it  any bit of it. Throw it all away. Now @@ this email that you sent  actually. What? Now I remember the email. O_K. Huh. Still  I have no recollection whatsoever of the email. I'll have to go back and check. Not important. So  what is important is that we understand what the proposed task is. And  the - the i- uh  Robert and I talked about this some on Friday. And we think it's well-formed. So we think it's a well-formed  uh  starter task for this  uh  deeper understanding in the tourist domain. So  where exactly is the  uh  deeper understanding being done? Like I mean  s- is it before the Bayes-net? Is it  uh - Well  it's the - it's - it's always all of it. So  in general it's always going to be  the answer is  everywhere. Uh  so the notion is that  uh  this isn't real deep. But it's deep enough that you can distinguish between these th- three quite different kinds of  uh  going to see some tourist thing. And  so that's - that's the quote ""deep"" that we're trying to get at. And  Robert's point is that the current front-end doesn't give you any way to - Not only doesn't it do it  but it also doesn't give you enough information to do it. It isn't like  if you just took what the front-end gives you  and used some clever inference algorithm on it  you would be able to figure out which of these is going on. So  uh  and this is - Bu- I- in general it's gonna be true of any kind of deep understanding  there's gonna be contextual things  there're gonna be linguistic things  there're gonna be discourse things  and they gotta be combined. And  my idea on how to combine them is with a belief-net  although it may turn out that t- some totally different thing is gonna work better. Um  the idea would be that you  uh  take your - You're editing your slide? Yeah. As i- a- sort of  as I get ideas  uh w- uh. Oh. So  discourse - I - I - I thought about that. Of course that needs to sort of go in there. Oh. I'm sorry. O_K. So. This is minutes - taking minutes as we go  Yep. in his - in his own way. Um  but the p- the - Anyway. So the thing is  i- uh  d- naively speaking  you've - you've got a - for this little task  a belief-net  which is going to have as output  the conditional pr- probability of one of three things  that the person wants to - uh  to View it  to Enter it  or to Tango with it. Um. So that - the - the output of the belief-net is pretty well formed. And  then the inputs are going to be these kinds of things. And  then the question is - there are two questions - is  uh  one  where do you get this i- information from  and two  what's the structure of the belief-net? So what are the conditional probabilities of this  that  and the other  given these things? And you probably need intermediate nodes. I - we don't know what they are yet. So it may well be that  uh  for example  that  uh  knowing whether - Oh  another thing you want is some information abou- I think  about the time of day. Now  they may wanna call that part of context. But the time of day matters a lot. Mm-hmm. And  if things are obviously closed  then  you - People won't want to enter it. Pe- people don't wanna enter them. And  if it's not obvious  you may want to actually s- b- uh  point out to people that it's closed - you know  what they're g- going to is closed and they don't have the option of entering it. So another thing that can come up  and will come up as soon as you get serious about this is  that another option of course is to have a - more of a dialogue. So if someone says something you could ask them. Yeah. O_K. And - Now  one thing you could do is always ask them  but that's boring. And it also w- it also be a pain for the person using it. So one thing you could do is build a little system that  said  "" whenever you got a question like that I've got one of three answers. Ask them which one you want."" O_K. But that's  um  not what we're gonna do. But maybe that's a false state of the system  that it's too close to call. Oh yeah. You want the - you want the ability to a- You want the ability to ask  but what you don't wanna do is onl- build a system that always asks every time  and i- That's not getting at the scientific problem  and it's - Mm-hmm. In general you're - you know  it's gonna be much more complex than that. a- This is purposely a really simple case. Yeah. So  uh - Yeah. I have one more point to - to Bhaskara's question. Um  I think also the - the - the deep understanding part of it is - is going to be in there to the extent that we um  want it in terms of our modeling. We can start  you know  basic from human beings  model that  its motions  going  walking  seeing  we can mem- model all of that and then compose whatever inferences o- we make out of these really conceptual primitives. That will be extremely deep in the - in - in - in my understanding. Yeah. S- so - so the way that might come up  if you wanna - Suppose you wanted to do that  you might say  ""Um  as an intermediate step in your belief-net  is there a Source-Path-Goal schema involved?"" O_K? And if so  uh  is there a focus on the goal? Or is there a focus on the path? or something. And that could be  uh  one of the conditiona- you know  th- the - In some piece of the belief-net  that could be the - the appropriate thing to enter. So  where would we extract that information from? From the M_-three-L_? No. No. See  the M_-three-L_ is not gonna give th- What he was saying is  the M_-three-L_ does not have any of that. All it has is some really crude stuff saying  Right. ""A person wants to go to a place."" The M_-three-L_ is the old SmartKom output? O_K. Right. M_-three- well  M_-three-L_ itself refers to Multimedia Mark-up Language. It's just a language. Right  yeah. So we have th- w- we- we we have to have a better w- way of referring to - The parser output? Mm-hmm. Yeah. The - "" Analyzed speech"" I think it's what they call it  really  oder - Well  O_K. Yeah. o- th- No  actually  intention lattices is what we're gonna get. Is- i- but they c- they call it intention lattice  but tha- Anyway. In- in- a- intention lattice k- Hypothesis. They call it intention hypotheses. Right. So  th- they're gonna give us some cr- uh - or - We can assume that y- you get this crude information. About intention  and that's all they're going to provide. And they don't give you the kind of object  they don't give you any discourse history  if you want to keep that you have to keep it somewhere else. Well  they keep it. We have to request it. Right. Nuh? But it's not in there. Well  they - they kee- they keep it by their lights. It may - it may or may not Hmm. Yeah  or i- be what - what we want. Yeah. So  if someone says  ""I wanna touch the side of the Powder-Tower""  that would - basically  we need to pop up Tango mode and the - and the directions? If i- if - Yeah  if it got as simple as that  yeah. But it wouldn't. Yeah. O_K. But that doesn't necessarily - But we'd have to infer a Source-Path-Goal to some degree for touching the side  right? Well - Uh  th- the- there is a p- a point there if I understand you. Correct? Um  because um  sometimes people just say things - This you find very often. ""Where is the city hall?"" And this do- they don't wanna sh- see it on a map  or they don't wanna know it's five hundred yards away from you  or that it's to the - your north. They wanna go there. That's what they say  is  ""Where is it?"". Where is that damn thing? And the parser would output - Well  that's a - a question mark. sh- A lot of parsers  um  just  uh - That's way beyond their scope  is - of interpreting that. You know? But um  still outcome w- the outcome will be some form of structure  with the town hall and maybe saying it's a W_H focus on the town hall. But to interpret it  Mm-hmm. you know? somebody else has to do that job later. Yeah. I'm just trying to figure out what the SmartKom system would output  depending on these things. Um  it will probably tell you how far away it is  at least that's - That's even what Deep Map does. It tells you how far away it is  and - and shows it to you on a map. Because i- we can not differentiate  at the moment  between  you know  the intention of wanting to go there or the intention of just know- wanting to know where - where it is. People no- might not be able to infer that either  right? Like the fact - Like  I could imagine if someone came up to me and asked  ""Where's the city hall?""  I might say  g- ar- ""Are you trying to get there?"" Because how I describe um  t- its location - uh  p- probably depend on whether I think I should give them  you know  directions now  or Mm-hmm. @@ say  you know  whatever  ""It's half a mile away"" or something like that. It's a granularity factor  because where people ask you  ""Where is New York? ""  you will tell them it's on the East Coast. Yeah . Uh-huh. Yeah. Exactly. Right. Right. Y- y- eh - you won't tell them how to get there  ft- you know  take that bus to the airport and blah-blah-blah. Yeah. Right. But if it's the post office  you will tell them how to get there. Mm-hmm. So th- They have done some interesting experiments on that in Hamburg as well. So. Right. Right. But - i- Go - go back to the - the uh  th- Yeah  that slide. So I w- this is - ""onto"" is - is knowledge about buildings  their opening times  and then t- coupled with time of day  um  this should - You know . So that context was like  um  their presumed purpose context  i- like business or travel  as well as the utterance context  like  ""I'm now standing at this place at this time"". Yeah  well I think we ought to d- a- As we have all along  d- We - we've been distu- distinguishing between situational context  which is what you have as context  and discourse context  which you have as D_H  I don't know what the H_ means. Mm-hmm. Nuh. History. Discourse history. O_K. Yeah. Whatever. So we can work out terminology later. Yep. So  they're - they're quite distinct. I mean  you need them both  but they're quite distinct. And  so what we were talking about doing  a- a- as a first shot  is not doing any of the linguistics. Except to find out what seems to be useful. So  the - the - the reason the belief-net is in blue  is the notion would be - Uh  this may be a bad dis- bad idea  but the idea is to take as a first goal  see if we could actually build a belief-net that would make this three way distinction uh  in a plausible way  given these - We have all these transcripts and we're able to  by hand  extract the features to put in the belief-net. Saying  ""Aha! here're the things which  if you get them out of - out of the language and discourse  and put them into the belief-net  it would tell you which of these three uh  intentions is most likely. "" And if - to actually do that  build it  um - you know  run it - y- y- run it on the data where you hand-transcribe the parameters. And see how that goes. If that goes well  then we can start worrying about how we would extract them. So - where would you get this information? And  expand it to - to other things like this. But if we can't do that  then we're in trouble. I mean th- th- i- i- if you can't do this task  um - We need a different  uh  engine. Machine  I mean. Uh  uh   yeah  or something. Well it - i- I- if it - if it's the belief-nets  we- we'll switch to you know  logic or some terrible thing  but I don't think that's gonna be the case. I think that  uh  if we can get the information  a belief-net is a perfectly good way of doing the inferential combination of it. The real issue is  do- what are the factors involved in determining this? And I don't know. Hmm. But  only w- Hold on a s- Hold on a second. Muh . So  I know . Uh  uh  is it clear what's going on here? Yep. Um  I missed the beginning  but  um I guess - could you back to the slide  the previous one? So  is it that it's  um - These are all factors that uh  a- These are the ones that you said that we are going to ignore now? or that we want to take into account? You were saying n- Take them into account. Take the - the linguistic factors too. But - but you don't worry about - h- Oh  how to extract these features. O_K. how to extract them. So  f- let's find out which ones we need first  Got it. O_K. And - and it's clear from the data  um  like  sorta the correct answer in each case. and - But l- No. O_K. That's - that's the thing I'm curious ab- No. But - Let's go back to th- Let's go back to the - the - the slide of data. Like do we know from the data wh- which - Um - O_K. So - Not from that data. But  um  since we are designing Mm-hmm. a - a - a - an  compared to this  even bigger data collection effort  Mm-hmm. um  we will definitely take care to put it in there  Mm-hmm. in some Yeah. shape  way  form over the other  Right. to see whether we can  then  get sort of empirically validated data. Um  from this  we can sometimes  you know - an- and that's - that - but that - isn't that what we need for a belief-net anyhow? is sort of - s- sometimes when people want to just see it  they phrase it more like this? Mm-hmm. But it doesn't exclude anybody from phrasing it totally differently  even if they still - you know? Right. Right. But then other factors may come into play that change the outcome of their belief-net. Right. So  um  this is exactly what - Because y- you can never be sure. And I'm sure even i- the most  sort of  deliberate data collection experiment will never give you data that say  ""Well  if it's phrased like that  Sure. the intention is this."" You know  because then  uh  you - u- u- I mean  the only way you could get that is if you were to give th- the x- subjects a task. Right? Where you have - where your  uh  current goal is to - We- Yeah! That's what we're doing. But - but we will still get the phrasing all over the place. I'm sure that  you know - @@ So that's what you want? O_K. So you will know. Mm-hmm. Yeah. The - No  that's fine. I guess  it's just knowing the intention from Yeah. Mm-hmm. From that task  yeah. So  the experimental subject. @@ uh  I think you all know this  but we are going to actually use this little room and start recording subjects probably within a month or something. So  this is not any - lo- any of you guys' worry  except that we may want to push that effort to get information we need. So our job is to figure out how to solve these problems. If it turns out that we need data of a certain sort  then the sort of data collection branch can be  uh  asked to do that. And one of the reasons why we're recording the meeting for these guys is cuz we want their help when we d- we start doing uh  recording of subjects. So  yeah - y- you're absolutely right  though. No  you - you will not have  and there it is  and  uh - But you know  y- y- the  um - And I think the other concern that has come up before  too  is if it's - um - I don't know if this was collected - Mm-hmm. what situation this data was collected in. Was it - is it the one that you showed in your talk? Like people - No  no. No. But O_K. So was this  like  someone actually mobile  like - s- using a device? Uh  N- no  no- not - i- it was mobile but not - not with a w- a real wizard system. So there were never answers. Uh-huh. O_K. O_K. But  is it - I guess I don't know - The situation of - of collecting th- the data of  like - Here you could imagine them being - walking around the city. as like one situation. And then you have all sorts of other c- situational context factors that would influence w- how to interpret  like you said  the scope and things like that. Mm-hmm. If they're doing it in a - you know  ""I'm sitting here with a map and asking questions""  I - I would imagine that the data would be really different. Um  so it's just - Yeah. But - It was never th- th- the goal of that data collection to - to serve for sat- for such a purpose. So that's why for example the tasks were not Mm-hmm. differentiated by intentionality  there was n- there was no label  you know  intention A_  intention B_  intention C_. Or task A_  B_  C_. Mm-hmm. Right. Um I'm sure we can produce some if we need it  um  that - Mm-hmm. that will help us along those lines. But  you know  you gotta leave something for other people to model. So  to - Finding out what  you know  Mm-hmm. situational con- what the contextual factors of the situation really are  you know is an interesting s- interesting thing. Mm-hmm. u- u- Sort of I'm  at the moment  curious and I'm - I'm - s- w- want to approach it from the end where we can s- sort of start with this toy system that we can play around with  Mm-hmm. so that we get a clearer notion of what input we need Mm-hmm. for that  what suffices and what doesn't. And then we can start worrying about where to get this input  what - what do we need  you know - Ultimately once we are all experts in changing that parser  for example  maybe  there's just a couple three things we need to do and then we get more whatever  part of speech and more construction-type-like Mm-hmm. Hmm. stuff out of it. It's a m- pragmatic approach  uh  at the moment. How exactly does the data collection work? Do they have a map  and then you give them a scenario of some sort? O_K. Imagine you're the - the subject. You're gonna be in here  and somebody - And - and you see  uh  either th- the three-D_ model  or uh  a QuickTime animation of standing u- in a square in Heidelberg. So you actually see that. Um. The uh  um  first thing is you have to read a text about Heidelberg. So  just off a textbook  uh  tourist guide  to familiarize  uh  yourself with that sort of odd-sounding German street names  like Fischergasse and so forth. So that's part one. Part two is  you're told that this huge new  wonderful computer system exists  that can y- tell you everything you want to know  and it understands you completely. And so you're gonna pick up that phone  dial a number  and you get a certain amount of tasks that you have to solve. First you have to know - find out how to get to that place  maybe with the intention of buying stamps in there. Maybe - So  the next task is to get to a certain place and take a picture for your grandchild. The third one is to get information on the history of an object. The fourth one - And then the g- system breaks down. It crashes  a- At the third? Right then? And - After the third task. O_K. And then - Or after the fourth. Some find - @@ Forget that for now. And then  a human operator comes on  and - and exp- apologizes that the system has crashed  but  you know  urges you to continue  you know? now with a human operator. And so  you have basically the same tasks again  just with different objects  and you go through it again  and that was it. Oh  and one - one little bit - w- And uh  the computer you are - you are being told the computer system knows exactly where you are  via G_P_S. When the human operator comes on  um  that person does not know. So the G_P_S is crashed as well. So the person first has to ask you ""Where are you?"". And so you have to do some - s- tell the person sort of where you are  depending on what you see there. Um  this is a - a - a - a - a bit that I d- I don't think we - Did we discuss that bit? Uh  I just sort of squeezed that in now. But it's something  uh  that would provide some very interesting data for some people I know. So. So  in the display you can - Oh  you said that you cou- you might have a display that shows  like  the - Yeah. a- Additionally  y- you have a - a - a sort of a map type display. a w- your perspective? sort of? And so  as you - Uh  two-D_. n- Oh  two-D_. O_K. So as you move through it that's- they just track it on the - Two-D_. Yeah. b- y- for themselves You don't - @@ there. That's - I don't know. I but y- I don't think you really move  O_K. So sort of. Yeah? I mean that would be an - an - an enormous technical effort  unless we would - We can show it walks to   you know. We can have movies of walking  you walking through - through Heidelberg  and u- ultimately arriving there. Mm-hmm. Maybe we wanna do that. Yeah. Uh  I was just trying to figure out how - how ambitious the system is. The map was sort of intended to - You want to go to that place. You know  and it's sort of there. And you see the label of the name - Mm-hmm. So we get those names  pronunciation stuff  and so forth  and we can change that. Mm-hmm. Mm-hmm. So your tasks don't require you to - I mean  uh - yo- you're told - So when your task is  I don't know  ""Go buy stamps"" or something like that? So  do you have to respond? or does your - Uh  what are you ste- what are you supposed to be telling the system? Like  w- what you're doing now? or - Well  we'll see what people do. There's no - O_K  so it's just like  ""Let's figure out what they would say Yeah  and - and we will record both sides. I mean  we will record the Wi- the Wizard - under the circumstances"". Uh-huh. Uh-huh. I mean  in both cases it's gonna be a human  in the computer  and in the operator case. And we will re- there will be some dialogue  you know? So  you first have to do this  and that  and - and - Yep. Mm-hmm. see wh- what they say. We can ins- instruct the  uh  wizard in how expressive and talkative he should be. But um  maybe the - maybe what you're suggesting - Is what you're suggesting that it might be too poor  the data  if we sort of limit it to this ping pong one t- uh  task results in a question and then there's an answer and that's the end of the task? You wanna m- have it more - more steps  sort of? Yeah  I - I don't know how much direction is given to the subject about what their interaction - I mean  th- they're unfamiliar w- with interacting with the system. All they know is it's this great system that could do Mm-hmm. s- stuff. Right? So - Mm-hmm. Oh yeah  but - to some extent this is a different discussion. O_K? So. Uh  we - we have to have this discussion of th- the experiment  and the data collection  and all that sorta stuff Uh-huh. and we do have  um  a student who is a candidate for wizard. Uh  she's gonna get in touch with me. It's a student of Eve's. F_E_Y  Fey? Spelled F_E_Y. Do you - do you - Oh  Fey Parrill. Yeah. Uh-huh. You know her? O_K. Sh- Is sh- She started taking the class last year and then didn't - um  you know  didn't continue. I g- She's a g- Is she an undergradua- She is a graduate  O_K. She's graduated. Yeah. Yeah  I m- I know her very  very briefly. I know she was inter- you know  interested in O_K. aspect and stuff like that . So  anyway  she's looking for some more part time work w- while she's waiting actually for graduate school. And she'll be in touch. So we may have someone  uh  to do this  and she's got you know  some background in - in all this stuff. And is a linguist st- and  so So. That's - So  Nancy  we'll have an- At some point we'll have another discussion on Mm-hmm. exactly wha- t- t- you know  how that's gonna go. And um  Jane  but also  uh  Liz Mm-hmm. have offered to help us do this  Mmm. uh  data collection and design and stuff. So  when we get to that we'll have some people doing it that know what they're doing. O_K. I guess the reason I was asking about the sort of the de- the details of this kind of thing is that  um  it's one thing to collect data for  I don't know  speech recognition or various other tasks that have pretty c- clear correct answers  but with intention um  obviously  as you point out  there's a lot of di- other factors and - I'm not really sure  um  how - how - e- the question of how to make it a t- appropriate toy version of that - Um  it's ju- it's just hard. So  I mean  obviously it's a - Yeah  uh  actually I guess that was my question. Is the intention implicit in the scenario that's given? Like  do the - It is  if they have these tasks that they're supposed to - Yeah  I just wasn't sure to what level of detail the task was. to - to give - Yeah  uh - Mm-hmm. n- No one is  at the moment. Right. Right. O_K. So  we- that's part of what we'll have to figure out. Right. Mm-hmm. But  uh  the - The problem that I was tr- gonna try to focus on today was  let's suppose by magic you could collect dialogues in which  one way or the other  you were able to  uh  figure out both the intention  and set the context  and know what language was used. So let's suppose that we can get that kind of data. Um. The issue is  can we find a way to  basically  featurize it so that we get some discrete number of features so that  uh  when we know the values to all those features  or as many as possible  we can w- come up with the best estimate of which of the  in this case three little intentions  are most likely. w- What are the t- three intentions? Is it to go there  to see it  and - To come as close as possible to it. Th- the terminology we're using is to - Yeah  it's @@ . Go back. To v- O_K. to View it. O_K? To Enter it. Now those - It seems to me those are cl- you c- you have no trouble with those being distinct. ""Take a picture of it"" Mm-hmm. you - you might well want to be a really rather different place than Mm-hmm. entering it. And  for an object that's at all big  Mm-hmm. uh  sort of getting to the nearest part of it Mm-hmm. uh  could be quite different than either of those. Mm-hmm. Just sort of - O_K  so now I understand the referent of Tango mode. See  I would have thought it was more of a waltz. I didn't get that before. S- To ""Waltz"" it? Yeah  like  how close are you gonna be? Like  Tango's really close. Well. Yeah  cuz a tango - Yeah. Well  anyway. So - All these So  like  the question is how what features can - like  do you wanna try to extract from  say  the parse or whatever? Right. Like  the presence of a word or the presence of a certain uh  stem  or - Right. certain construction or whatever. Is there a construction  or the kind of object  or w- uh  anything else that's in the si- It's either in the - in the s- the discourse itself or in the context. So if it turns out that  whatever it is  you want to know whether the person's uh  a tourist or not  O_K? that becomes a feature. Now  how you determine that is another issue. But fo- for the current problem  it would just be  ""O_K  if you can be sure that it's a tourist  versus a businessman  versus a native  "" or something  uh  that would give you a lot of discriminatory power and then just have a little section in your belief-net that said  ""pppt!"" Though sin- f- in the short run  you'd set them  Mm-hmm. and see ho- how it worked  and then in the longer run  you would figure out how you could derive them. Right. From previous discourse or w- any- anything else you knew. So  how should - What's the uh  plan? Like  how should we go about figuring out these - O_K. So  first of all is  uh  do e- either of you guys  you got a favorite belief-net that you've  you know  played with? JavaBayes or something? Oh. No  not really. O_K. Well  anyway. f- Get one. O_K? So - y- so one of th- one of the things we wanna do is actually  uh  pick a package  doesn't matter which one  uh  presumably one that's got good interactive abilities  cuz a lot of what we're gonna be d- You know  we don't need the one that'll solve massive  uh  belief-nets quickly. d- w- These are not gonna get big in - in the foreseeable future. But we do want one in which it's easy to interact with and  uh  modify. Mm-hmm. Because i- that's - A lot of what it's gonna be  is  um  playing with this. And probably one in which it's easy to have  um  what amounts to transcript files. So that if - if we have all these cases - O_K? So we make up cases that have these features  O_K  and then you'd like to be able to say  ""O_K  here's a bunch of cases"" - There're even ones tha- that you can do learning O_K? So you have all their cases and - and their results and you have a - algorithms to go through and run around trying to set the - the probabilities for you. Um  probably that's not worth it. I mean  my guess is we aren't gonna have enough data that's good enough to make the - these data fitting ones worth it  but I don't know. So I would say you guy- the first task for you two guys is to um  pick a package. Mm-hmm. O_K  and you wanna it s- You know  the standard things you want it stable  you want it - yeah  @@ . And  as soon as we have one  we can start An- Nuh. trying to  uh  make a first cut at what's going on. But it - what I like about it is it's very concrete. O_K? We - we have a - we know what the outcomes are gonna be  and we have some - some data that's loose  we can use our own intuition  and see how hard it is  and  importantly  what intermediate nodes we think we need. So it - if it turns out that just  thinking about the problem  you come up with things you really need to - You know  this is the kind of thing that is  you know  an intermediate little piece in your belief-net. That'd be really interesting. Mm-hmm. And it - and it may serve as a platform for a person  maybe me  or whoever  who is interested in doing some linguistic analysis. I mean  w- we have the For- FrameNet group here  and we can see what they have found out about those concepts already  that are contained in the data  um  you know  to come up with a nice little set of features and um  maybe even means of s- uh  extracting them. And - and that altogether could also be - uh  become a nice paper that's going to be published somewhere  if we sit down and write it. And um - When you said JavaBayes belief-net you were talking about ones that run on coffee? or that are in the program language Java? No  th- It turns out that there is a  uh - The new end of Java libraries. O_K  and it turns out one called JavaBayes. Which is Mmm. O_K. one that fair - people around here use a fair amount. I have no idea whether that's - @@ The obvious advantage of that is that you can then  relatively easily  get all the other Java packages for GUIs or whatever else you might want to do. So that i- that's I think why Mm-hmm. a lot of people doing research use that. But it may not be - I have no idea whether that's the best choice an- and there're plenty of people around  students in the department who  you know  live and breathe Bayes-nets. So  uh  There's the m- tool kit that um  Kevin Murphy has developed  Right. which might be useful too. And it's available Matlab code. It's O_K. Right. So  yeah  Kevin would be a good person to start with. Nancy knows him well. I don't know I don't know whether you guys have met Kevin yet or not  but  uh - Mm-hmm. But i- Yeah  I know him. Yeah. But since we all probably are pretty sure that  um  the - For example  this th- th- the dialogue history is - is um  producing X_M_L documents. M_-three-L_ of course is X_M_L. And the ontology that um  uh the student is - is constructing for me back in - in E_M_L is in OIL and that's also in X_M_L. And so that's where a lot of knowledge about bakeries  about hotels  about castles and stuff is gonna come from. Mm-hmm. Yeah. Um  so  if it has that I_O capability and if it's a Java package  it will definitely be able - We can couple. Yeah. So  yeah  we're sort of committed to X_M_L as the kind of  uh  interchange. But that's  you know  not a big deal. Who isn't  nuh? So  in terms of - of - interchanging in and out of any module we build  It 'll be X_M_L. And if you're going off to queries to the ontology  for example  you'll have to deal with its interface. But that's - that's fine an- and um  all of these things have been built with much bigger projects than this in mind. So they - they have worked very hard. It's kind of blackboards and multi-wave blackboards and ways of interchanging and registering your a- And so forth. So  that I don't think is even worth us worrying about just yet. I mean if we can get the core of the thing to work  in a way that we're comfortable with  then we ca- we can get in and out of it with  uh  X_M_L  um  little descriptors. I believe. I don't - I don't see - Hmm. Yeah. Yeah  I like  for example  the - what you said about the getting input from - from just files about where you h- where you have the data  have specified the features and so forth. That's  of course  easy also to do with  you know  X_M_L. Uh  you could have an X_ - yeah  you could make and X_M_L format for that. Sure. So r- That - that - um  you know  feature value X_M_L format is probably as good a way as any. So it's als- Yeah  I guess it's also worth  um  while you're poking around  poke around for X_M_L packages that um  do things you'd like. Doesn't - does SmartKom system have such packages? Sure. Yeah. The - the lib- M_-three-L_ library does that. It's also - And the question is  d- you c- you - you'll have to l- We'll have to l- That should be - ay- We should be able to look at that - No  u- u- y- um- the - What I - What sort of came to my mind i- is - was the notion of an idea that Yeah. if - if there are l- nets that can actually lear- try to set their own  um  probability factors based on - on - on - on input - which is in file format  if we  um  get really w- wild on this  we may actually want to use some - some corpora that other people made and  for example  if - if they are in - in MATE  then we get X_M_ L documents with discourse annotations  t- you know  t- from the discourse act down to the phonetic level. Mm-hmm. Um  Michael has a project where - you know  recognizing discourse acts and he does it all in MATE  and so they're actually annotating data and data and data. So if we w- if we think it's worth it one of these days  not - not with this first prototype but maybe with a second  and we have the possibility of - of taking input that's generated elsewhere and learn from that  Right. that'd be nice. It'd be nice  but - but I - I - I do- I don't wanna count on it. I mean  you can't - you can't run your project based on the speculation that - No  no  uh  just for - that the data will come  and you don't have to actually design the nets. Nuh. Just a back door that - I - I think we should devote m- Could happen. Yeah. So in terms of - of the  um - the - what the SmartKom gives us for M_-three-L_ packages  it could be that they're fine  or it could be eeh. You don't - You know  you don't really like it. So we're not - we're not abs- we're not required to use their packages. We are required at the end to give them stuff in their format  but hey. Right. Um  it's  uh - It doesn't control what you do in- you know  internally. @@ What's the time frame for this? Two days? Huh? Two  three days? Yeah bu- w- I'd like that this - y- yeah  this week  to ha- to n- to have y- guys  uh  you know  pick the - y- you know  belief-net package and tell us what it is  and give us a pointer so we can play with it or something. No. Sure. And  then as soon as we have it  I think we should start trying to populate it for this problem. Make a first cut at  you know  what's going on  and probably the ea- easiest way to do that is some on-line way. I mean  you can f- figure out whether you wanna make it a web site or - You know  how- Uh - I - I - I - um  O_K  I - t- Yeah. I was actually more joking. With the two or three days. So this was - was a usual jo- O_K  I wasn't. Um  it will take as long as y- y- yo- you guys need for that. But um  Yeah. Right. maybe it might be interesting if - if the two of you can agree on who's gonna be the speaker next Monday  to tell us something about the net you picked  and what it does  and how it does that. Well  y- Well  or both of them speak. We don't care. Sure. Yeah  or you can split it up. So  y- Hmm. So that will be sort of the assignment for next week  is to - to - for slides and whatever net you picked and what it can do and - and how far you've gotten. Pppt! Well  I'd like to also  though  uh  ha- have a first cut at what the belief-net looks like. Even if it's really crude. O_K? So  you know  here a- here are - So we're supposed to @@ about features and whatnot  and - Right. Yeah. Mm-hmm. And  as I said  what I'd like to do is  I mean  what would be really great is you bring it in - If - if - if we could  uh  in the meeting  say  you know  ""Here's the package  here's the current one we have "" uh  you know  ""What other ideas do you have?"" and then we can think about this idea of making up the data file. Of  uh  you know  get a - t- a p- tentative format for it  let's say X_M_L  that says  l- you know  ""These are the various scenarios we've experienced."" We can just add to that and there'll be this - this file of them and when you think you've got a better belief-net  You just run it against this  um - this data file. So we'll be like  hand  uh  doing all the probabilities. O_K. Oh  yeah  unt- until we know more. And what's the relation to this with - Changing the table so that the system works in English? O_K. So this is - Whi- while you were doing this  I received two lovely emails. The - the full N_T and the full Linux version are there. I've downloaded them both  and I started to unpack the Linux one - Uh  the N_T one worked fine. and I started unta- pack the Linux one  it told me that I can't really unpack it because it contains a future date. So this is the time difference between Germany. I had to wait until one o'clock this afternoon before I was able to unpack it. Now  um - Then it will be my job to get this whole thing running both on Swede and on this machine. And so that we have it. And then um - Hopefully that - hoping that my urgent message will now come through to Ralph and Tilman that it will send some more documentation along  we - I control p- Maybe that's what I will do next Monday is show the state and show the system and show Yeah. that. Yeah. So the answer  Johno  is that these are  at the moment  separate. Uh  what one hopes is that when we understand how the analyzer works  we can both worry about converting it to English and worry about how it could ex- extract the parameters we need for the belief-net. I guess my question was more about time frame. So we're gonna do belief-nets this week  and then - Oh  yeah. I don't know. n- None of this is i- n- Neither of these projects has got a real tight time-line  in the sense that over the next month there's a - there's a deliverable. O_K. O_K. S- so uh  it's opportu- in that sense it's opportunistic. If - if - you know  if we don't get any information for these guys f- for several weeks then we aren't gonna sit around  you know  wasting time  trying to do the problem or guess what they - You know  just pppt! go on and do other things. O_K. Yeah  but uh - but the uh - This point is really - I think very  very valid that ultimately we hope that - that both will merge into a harmonious and  um  wonderful  um  state where we can not only do the bare necessities  I_E  changing the table so it does exactly in English what it does in German  but also that we can sort of have the system where we can say  ""O_K  this is what it usually does  and now we add this little thing to it""  you know? whatever  Johno's and Bhaskara's great belief-net  and we plug it in  and then for these certain tasks  and we know that navigational tasks are gonna be a core domain of the new system  it all - all of a sudden it does much better. Nuh? Because it can produce better answers  tell the person  as I s- showed you on this map  n- you know  produce either you know  a red line that goes to the Vista point or a red line that goes to the Tango point or red line that goes to the door  which would be great. So not only can you show that you know something sensible but ultimately  if you produce a system like this  it takes the person where it wants to go. Rather than taking him always to the geometric center of a building  which is what they do now. Mmm. And we even had to take out a bit. Nancy  you missed that part. We had to take out a bit of the road work. So that it doesn't take you to the wall every time. So. Um - Oh  really? So this was actually an actual problem that we encountered  which nobody have - has - because car navigation systems don't really care. You know  they get you to the beginning of the street  some now do the house number. Hmm. Mm-hmm. But even that is problematic. If you go d- If you wanna drive to the S_A_P in Waldorf  I'm sure the same is true of Microsoft  it takes you to the - the address  whatever  street number blah-blah-blah  you are miles away from the entrance. Yep. Because the s- postal address is maybe a mailbox somewhere. Mm-hmm. Nuh? but the entrance where you actually wanna go is somewhere completely different. So unless you're a mail person you really don't wanna go there. Right  yeah. Probably not then  cuz y- you probably can't drop the mail there anyway. Probably neither - e- not even that. Yeah. Clear? O_K. Sounds good. The Powder-Tower is made of red limestone. I was wondering. O_K. Do you wanna see a picture? Sure! Sure! Have to reboot for that though. Um. So  you two  who'll be working on this  li- are - are you gl- will you be doing - Well  I mean are you supposed to just do it by thinking about the situation? Can you use the sample data? Is it like - Yeah  I mean  ho- is there more than - Of course they use the sample data. Is there a lot s- of sample data that is beyond what you - what you have there? There - there's more than I showed  but um  um  I think this is sort of um  in part my job to look at that and - and to see whether there are features in there that can be extracted  and to come up with some Yeah. Right. features that are not you know  empirically based on - on a real experiment or on - on - on reality but sort of on your intuition of you know  ""Aha! Mm-hmm. Mm-hmm . Mm-hmm. This is maybe a sign for that  and this is maybe a sign for this."" Mm-hmm. Mm-hmm. So  yeah. Later this week we should sort of get together  and sort of Talk features. start thinking about that  hopefully. Yep. O_K. We can end the meeting and call Adam  and then we wanna s- look at some filthy pictures of Heidelberg. We can do that as well. Uh  is that O_K? Well they had - they used the ammunition - They stored the ammunition in that tower. Alright. And that's why  when it was hit by uh  a cannon ball  it exploded. It exploded. Oh. Ni- That's why they call it the Powder-Tower. Ahh. O_K. I first thought it had something to do with the material that it - w- that's why I asked. That's right  O_K. Mmm. ","The data collection running in parallel with the project can start shortly with recruiting subjects. Meanwhile  the german parser now works with english sentences. The parser's output modifies the XML used by the system to initiate actions and generate responses. The XML for Map requests also comprise a route  route elements and points of interest along the way. It is at this level that Enter/Vista/Approach tags will be added as action modes. As the project evolves  further enrichment of the ontology (actions  linguistic features) will be necessary. Similarly  object representations will include an EVA vector. This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type. These elements will constitute only a small part of the inputs of the Bayes-net that determines the action mode. The actual number of the inputs can create a combinatorial explosion when setting the probabilities. Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version. In any case  further to fulfilling the basic requirements (translating the parser and the generator into english)  the project is entirely open-ended in terms of focus of research. As the data collection is about to begin  there are some minor changes to be done in the design of the experiment  the script and the permission forms. Subjects can be recruited either from within the university or through other social circles. As to the system design  the next step is the translation of the generator into english. Moreover  it is important to test the system and its internal workings by adding new sentence types and modifying the parser. All further research will use the existing domain (""tourists in Heidelberg"")  as this provides enough diversity for the purposes of the project. The german partners for the project will realise all the necessary changes in the ontology. It is therefore preferable for the group to exercise foresight and agree on the set of new tags they will need in the long run  so that they limit the number of change requests. Finally  on a more technical note  Noisy-OR's were discussed and considered a sensible approach to deal with the potential problems with the setting the conditional probabilities of the Bayes-nets. Although the parser has been modified to work with english  the details of its internal workings (calling functions  setting discourse variables  generating actions) are not yet clear. Understanding the parsed data is helped by the database of objects  people and events accompanying the system  but the mapping of referring expressions to database objects can still be a hurdle. On a different level  the Bayes-net used to generate the different action modes can easily become unmanageable as the number of features to be taken into account increases. This can be tackled with the use of the Noisy-OR technique. The deterministic functions this requires cannot be introduced directly into JavaBayes  although some runaround ways can be implemented. A final  high-level issue  that has not been dealt with yet  is the definition of the constructions and the construction grammar framework analysis behind the whole enterprise. The preparation for the data collection is almost finished and expected to start experiments within a couple of weeks. There is some additional TV and cinema data currently being translated from german. The german parser has been translated and it can now be used for a range of sentence types in english. On the other hand  the translation of some parts of the relational database accompanying the system has also been commissioned. EML have provided the structure for Map requests  the basic representation of the navigational goals upon which further action modes are going to be built. The same people are also creating a general  top-level XML object ontology that will include all types of buildings. "
"It's not very significant. Channel three. Channel three. Uh  channel one. Yes. O_K. Mm-hmm. Ta- Channel three. Alright. O_K  did you solve speech recognition last week? Almost. Alright! Let's do image processing. Yes  again. Great. We did it again  Morgan. Alright! Doo-doop  doo-doo. What's wrong with - ? O_K. It's April fifth. Actually  Hynek should be getting back in town shortly if he isn't already. Is he gonna come here? Uh. Well  we'll drag him here. I know where he is. So when you said ""in town""  you mean Oregon. U- u- u- u- uh  I meant  you know  this end of the world  yeah  is really what I meant  uh  cuz he's been in Europe. Oh. Doo  doo-doo. Doo-doo. So. I have something just fairly brief to report on. Mmm. Great! Um  I did some experim- uh  uh  just a few more experiments before I had to  uh  go away for the w- well  that week. Was it last week or whenever? Um  so what I was started playing with was the - th- again  this is the H_T_K back-end. And  um  I was curious because the way that they train up the models  they go through about four sort of rounds of - of training. And in the first round they do - uh  I think it's three iterations  and for the last three rounds e- e- they do seven iterations of re-estimation in each of those three. And so  you know  that's part of what takes so long to train the - the - the back-end for this. I'm sorry  I didn't quite get that. There's - there's four and there's seven and - I - I'm sorry. Yeah. Uh  maybe I should write it on the board. So  there's four rounds of training. Um  I g- I g- I guess you could say iterations. The first one is three  then seven  seven  and seven. And what these numbers refer to is the number of times that the  uh  H_M_M re-estimation is run. It's this program called H_E_rest. But in H_T_K  what's the difference between  uh  a - an inner loop and an outer loop in these iterations? O_K. So what happens is  um  at each one of these points  Yeah. you increase the number of Gaussians in the model. Oh  right! This was the mix up stuff. That's right. I remember now. Yeah. The mix up. Right. And so  in the final one here  you end up with  uh - for all of the - the digit words  you end up with  uh  three mixtures per state  Yeah. eh  in the final thing. So I had done some experiments where I was - I - I want to play with the number of mixtures. But  um  Mm-hmm. Uh  one  two  uh  I wanted to first test to see if we actually need to do this many iterations early on. And so  Mm-hmm. um  I - I ran a couple of experiments where I reduced that to l- to be three  two  two  uh  five  I think  and I got almost the exact same results. And - but it runs much much faster. Mm-hmm. So  um  I - I think m- it only took something like  uh  three or four hours to do the full training  As opposed to - ? Good. as opposed to wh- what  sixteen hours or something like that? Yeah. It depends. I mean  it takes - you have to do an overnight basically  the way it is set up now. Mm-hmm. Mm-hmm. So  uh  even we don't do anything else  doing something like this could allow us to turn experiments around a lot faster. And then when you have your final thing  do a full one  so it's - And when you have your final thing  we go back to this. Yeah. So  um  and it's a real simple change to make. I mean  it's like one little text file you edit and change those numbers  and you don't do anything else. And then you just run. Oh  this is a - Mm-hmm. O_K. So it's a very simple change to make and it doesn't seem to hurt all that much. So I - So you - you run with three  two  two  five? That's a- Uh  I - I have to look to see what the exact numbers were. I - I thought was  like  Yeah. three  two  two  five  but I- I'll - I'll double check. It was over a week ago that I did it  so I can't remember exactly. But  uh - Mm-hmm. O_K. Mm-hmm. Oh. Mm-hmm. um  but it's so much faster. Hmm. I- it makes a big difference. So we could do a lot more experiments and throw a lot more stuff in there. Yeah. That's great. Um. Oh  the other thing that I did was  um  I compiled the H_T_K stuff for the Linux boxes. So we have this big thing that we got from I_B_M  which is a five-processor machine. Really fast  but it's running Linux. So  you can now run your experiments on that machine and you can run five at a time and it runs  Mm-hmm. uh  as fast as  you know  uh  five different machines. Mm-hmm. So  um  I've forgotten now what the name of that machine is but I can - I can send email around about it. Yeah. And so we've got it - now H_T_K's compiled for both the Linux and for  um  the Sparcs. Um  you have to make - you have to make sure that in your dot C_S_H_R_C  um  it detects whether you're running on the Linux or a - a Sparc and points to the right executables. Uh  and you may not have had that in your dot C_S_H_R_C before  if you were always just running the Sparc. So  um  uh  I can - I can tell you exactly what you need to do to get all of that to work. Mm-hmm. Hmm. Cool. But it'll - it really increases what we can run on. So  together with the fact that we've got these faster Linux boxes and that it takes less time to do these  um  we should be able to crank through a lot more experiments. So. Mm-hmm. Hmm. So after I did that  then what I wanted to do was try increasing the number of mixtures  just to see  um - see how - how that affects performance. Yeah. So. Yeah. In fact  you could do something like keep exactly the same procedure and then add a fifth thing onto it Mm-hmm. Exactly. that had more. Yeah. Right. Right. So at - at the middle o- where the arrows are showing  Uh-huh. that's - you're adding one more mixture per state  or - ? Uh  let's see  uh. It goes from this - uh  try to go it backwards - this - at this point it's two mixtures per state. So this just adds one. Except that  uh  actually for the silence model  it's six Mm-hmm. mixtures per state. O_K. Uh  so it goes to two. Um. And I think what happens here is - Might be between  uh  shared  uh - Yeah. I think that's what it is. shared variances or something  or - Uh  yeah. It's  uh - Shoot. I - I - I can't remember now what happens at that first one. Uh  I have to look it up and see. Oh  O_K. Um  there - because they start off with  uh  an initial model which is just this global model  and then they split it to the individuals. And so  it may be that that's what's happening here. I - I - I have to look it up and see. I - I don't exactly remember. O_K. O_K. Alright. So. That's it. So what else? Um. Yeah. There was a conference call this Tuesday. Um. I don't know yet the - what happened Tuesday  but the points that they were supposed to discuss is still  uh  things like the weights  uh - Oh  this is a conference call for  uh  uh  Aurora participant sort of thing. I see. For - Yeah. Yeah. Mmm. Do you know who was - who was - since we weren't in on it  uh  do you know who was in from O_G_I? Was - was - was Hynek involved or was it Sunil or - ? I have no idea. Mmm  I just - Yeah. Oh  you don't know. O_K. Alright. Um  yeah. So the points were the - the weights - how to weight the different error rates that are obtained from different language and - and conditions. Um  it's not clear that they will keep the same kind of weighting. Right now it's a weighting on - on improvement. Mm-hmm. Some people are arguing that it would be better to have weights on uh - well  to - to combine error rates before computing improvement. Uh  and the fact is that for - right now for the English  they have weights - they - they combine error rates  but for the other languages they combine improvement. So it's not very consistent. Um - Mm-hmm. Yeah. The  um - Yeah. And so - Well  this is a point. And right now actually there is a thing also  uh  that happens with the current weight is that a very non-significant improvement on the well-matched case result in huge differences in - in the final number. Mm-hmm. Hmm. And so  perhaps they will change the weights to - Yeah. How should that be done? I mean  it - it seems like there's a simple way - Mm-hmm. Uh  this seems like an obvious mistake or something. Th- they're - Well  I mean  the fact that it's inconsistent is an obvious mistake. But the - but  um  the other thing - I don't know I haven't thought it through  but one - one would think that In- each - It - it's like if you say what's the - what's the best way to do an average  an arithmetic average or a geometric average? Mm-hmm. It depends what you wanna show. Mm-hmm. Each - each one is gonna have a different characteristic. So - Yeah. Well  it seems like they should do  like  the percentage improvement or something  rather than the absolute improvement. Tha- that's what they do. Yeah. Well  they are doing that. No  that is relative. But the question is  do you average the relative improvements or do you average the error rates and take the relative improvement maybe of that? Yeah. Yeah. And the thing is it's not just a pure average because there are these weightings. Oh. It's a weighted average. Um. Yeah. And so when you average the - the relative improvement it tends to - to give a lot of - of  um  importance to the well-matched case because the baseline is already very good and  um  i- it's - Why don't they not look at improvements but just look at your av- your scores? You know  figure out how to combine the scores Mm-hmm. with a weight or whatever  and then give you a score - here's your score. And then they can do the same thing for the baseline system - and here's its score. And then you can look at - Well  that's what he's seeing as one of the things they could do. It's just when you - when you get all done  Mm-hmm. Yeah. I think that they pro- I m- I - I wasn't there but I think they started off this process with the notion that you should be significantly better than the previous standard. Mm-hmm. And  um  so they said ""how much is significantly better? what do you - ?"" And - and so they said ""well  you know  you should have half the errors "" or something  ""that you had before"". Mm-hmm. Hmm. Mm-hmm. Yeah. So it's  uh  Hmm. But it does seem like i- i- it does seem like it's more logical to combine them first and then do the - Combine error rates and then - Yeah. Yeah. Yeah. Well - But there is this - this - is this still this problem of weights. When - when you combine error rate it tends to give more importance to the difficult cases  Oh  yeah? and some people think that - well  they have different  um  opinions about this. Some people think that it's more important to look at - to have ten percent imp- relative improvement on well-matched case than to have fifty percent on the m- mismatched  and other people think that it's more important to improve a lot on the mismatch and - It sounds like they don't really have a good idea about what the final application is gonna be. So  bu- l- de- fff! Well  you know  the - the thing is Mmm. Yeah. Mmm. that if you look at the numbers on the - on the more difficult cases  um  if you really believe that was gonna be the predominant use  none of this would be good enough. Nothing anybody's - whereas you sort of Mm-hmm. Yeah. with some reasonable error recovery could imagine in the better cases that these - these systems working. So  um  I think the hope would be that it would - uh  it would work well for the good cases and  uh  it would have reasonable - reas- soft degradation as you got to worse and worse conditions. Um. Yeah. I - I guess what I'm - I mean  I - I was thinking about it in terms of  if I were building the final product and I was gonna test to see which front-end I'd - I wanted to use  I would try to weight things depending on the exact environment that I was gonna be using the system in. If I - But - but - No. Well  no - well  no. I mean  it isn't the operating theater. I mean  they don- they - they don't - they don't really know  I think. Yeah. So if - if they don't know  doesn't that suggest the way for them to go? I mean  I th- Uh  @@ you assume everything's equal. I mean  y- y- I mean  you - Well  I mean  I - I think one thing to do is to just not rely on a single number - to maybe have two or three numbers  you know  and - and - and say Yeah. Right. here's how much you  uh - you improve the  uh - the - the relatively clean case and here's - or - or well-matched case  and here's how - here's how much you  Mm-hmm. uh - So not - So not try to combine them. So. Yeah. Uh  actually it's true. Uh  I had forgotten this  uh  but  uh  well-matched is not actually clean. What it is is just that  Yeah. u- uh  the training and testing are similar. The training and testing. Mmm. So  I guess what you would do in practice is you'd try to get as many  uh  examples of similar sort of stuff as you could  and then  uh - So the argument for that being the - the - the more important thing  is that you're gonna try and do that  Yeah. but you wanna see how badly it deviates from that when - when - when the  uh - it's a little different. So - Um  so you should weight those other conditions v- very - you know  really small. But - No. That's a - that's a - that's an arg- I mean  that's more of an information kind of thing. that's an ar- Well  that's an argument for it  but let me give you the opposite argument. The opposite argument is you're never really gonna have a good sample of all these different things. Uh-huh. I mean  are you gonna have w- uh  uh  examples with the windows open  half open  full open? Going seventy  sixty  fifty  forty miles an hour? On what kind of roads? With what passing you? With - uh  I mean  Mm-hmm. Mm-hmm. I - I - I think that you could make the opposite argument that the well-matched case is a fantasy. Mm-hmm. Uh-huh. You know  so  I think the thing is is that if you look at the well-matched case versus the po- you know  the - the medium and the - and the fo- and then the mismatched case  um  we're seeing really  really big differences in performance. Right? And - and y- you wouldn't like that to be the case. You wouldn't like that as soon as you step outside - You know  a lot of the - the cases it's - is - Well  that'll teach them to roll their window up. I mean  in these cases  if you go from the - the  uh - I mean  I don't remember the numbers right off  but if you - if you go from the well-matched case to the medium  it's not an enormous difference in the - in the - the training-testing situation  and - and - and it's a really big Mm-hmm. performance drop. You know  so  um - Yeah  I mean the reference one  for instance - this is back old on  uh - on Italian - uh  was like six percent error for the well-matched and eighteen for the medium-matched and sixty for the - for highly-mismatched. Uh  and  you know  with these other systems we - we helped it out quite a bit  but still there's - there's something like a factor of two or something between well-matched and medium-matched. And so I think that if what you're - if the goal of this is to come up with robust features  it does mean - So you could argue  in fact  that the well-matched is something you shouldn't be looking at at all  that - that the goal is to come up with features that will still give you reasonable performance  you know  with again gentle degregra- degradation  um  even though the - the testing condition is not the same as the training. Hmm. So  you know  I - I could argue strongly that something like the medium mismatch  which is you know not compl- pathological but - I mean  what was the - the medium-mismatch condition again? Um  it's - Yeah. Medium mismatch is everything with the far microphone  but trained on  like  low noisy condition  like low speed and - or stopped car and tested on high-speed conditions  I think  like on a highway and - So - Right. So it's still the same - same microphone in both cases  Same microphone but - Yeah. but  uh  it's - there's a mismatch between the car conditions. And that's - uh  you could argue that's a pretty realistic Yeah. situation and  uh  I'd almost argue for weighting that highest. But the way they have it now  Mm-hmm. it's - I guess it's - it's - They - they compute the relative improvement first and then average that with a weighting? Yeah. And so then the - that - that makes the highly-matched the really big thing. Mm-hmm. Um  so  u- i- since they have these three categories  it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those. Mm-hmm. Just say ""O_K  in the - in the highly-matched case this is what happens  in the - m- the  uh - this other m- medium if this happens  in the highly-mismatched that happens"". Mm-hmm. And  uh  you should see  uh  a gentle degradation through that. Mmm. Um. But - I don't know. Yeah. I think that - that - I - I - I gather that in these meetings it's - it's really tricky to make anything ac- make any policy change because everybody has - has  uh  their own opinion and - Mm-hmm. I don't know . Yeah. Yeah. Uh  so - Yeah. Yeah  but there is probably a - a big change that will be made is that the - the baseline - th- they want to have a new baseline  perhaps  which is  um  M_F_C_C but with a voice activity detector. And apparently  uh  some people are pushing to still keep this fifty percent number. So they want to have at least fifty percent improvement on the baseline  Mm-hmm. but w- which would be a much better baseline. Mm-hmm. And if we look at the result that Sunil sent  just putting the V_A_D in the baseline improved  like  more than twenty percent  Mm-hmm. which would mean then - then - mean that fifty percent on this new baseline is like  well  more than sixty percent improvement on - So nobody would be there  probably. Right? on - o- e- e- uh - Right now  nobody would be there  but - Good. Yeah. Work to do. Uh-huh. So whose V_A_D is - Is - is this a - ? Uh  they didn't decide yet. I guess i- this was one point of the conference call also  but - mmm  so I don't know. Um  but - Yeah. Oh. Oh  I - I think th- that would be good. I mean  it's not that the design of the V_A_D isn't important  but it's just that it - it - it does seem to be i- uh  a lot of work to do a good job on - on that and as well as being a lot of work to do a good job on the feature design  so Yeah. Yeah. if we can cut down on that maybe we can make some progress. M- Yeah. Hmm. But I guess perhaps - I don't know w- Yeah. Uh  yeah. Per- e- s- s- someone told that perhaps it's not fair to do that because the  um - to make a good V_A_D you don't have enough to - with the - the features that are - the baseline features. So - mmm  you need more features. So you really need to put more - more in the - in - in the front-end. Yeah. So i- Um  S- sure. But i- bu- Wait a minute. I - I'm confused. Wha- what do you mean? Yeah. Yeah  if i- So y- so you m- s- Yeah  but - Well  let's say for ins- see  M_F_C_C for instance doesn't have anything in it  uh  related to the pitch. So just - just for example. So suppose you've - that what you really wanna do is put a good pitch detector on there and if it gets an unambiguous - Oh  oh. I see. Mm-hmm. if it gets an unambiguous result then you're definitely in a - in a - in a voice- in a  uh  s- region with speech. Uh. So there's this assumption that the v- the voice activity detector can only use the M_F_C_C? That's not clear  but this - e- Well  for the baseline. Yeah. So - so if you use other features then y- But it's just a question of what is your baseline. I g- Yeah. Right? What is it that you're supposed to do better than? And so I don't s- having the baseline be the M_F_C_C's means that people could choose to pour their ener- their effort into trying to do a really good V_A_D But they seem like two separate issues. Right? I mean - or tryi- They're sort of separate. Unfortunately there's coupling between them  which is part of what I think Stephane is getting to  is that you can choose your features in such a way as to improve the V_A_D. Yeah. And you also can choose your features in such a way as to prove - improve recognition. They may not be the same thing. But it seems like you should do both. Right? You should do both and - and I - I think that this still makes - I still think this makes sense as a baseline. It's just saying  as a baseline  we know - Mmm. you know  we had the M_F_C_C's before  lots of people have done voice activity detectors  Mm-hmm. you might as well pick some voice activity detector and make that the baseline  just like you picked some version of H_T_K and made that the baseline. Yeah. Right. And then let's try and make everything better. Um  and if one of the ways you make it better is by having your features be better features for the V_A_D then that's - so be it. But  Mm-hmm. uh  uh  uh  at least you have a starting point that's - um  cuz i- i- some of - the some of the people didn't have a V_A_D at all  I guess. Right? And - and Yeah. then they - they looked pretty bad and - and in fact what they were doing wasn't so bad at all. But  Mm-hmm. Mm-hmm. Yeah. It seems like you should um. try to make your baseline as good as possible. And if it turns out that you can't improve on that  well  I mean  then  you know  nobody wins and you just use M_F_C_C. Right? Yeah. I mean  it seems like  uh  it should include sort of the current state of the art that you want - are trying to improve  and M_F_C_C's  you know  or P_L_P or something - it seems like reasonable baseline for the features  and anybody doing this task  uh  is gonna have some sort of voice activity detection at some level  in some way. They might use the whole recognizer to do it but - rather than a separate thing  but - but they'll have it on some level. So  um. It seems like whatever they choose they shouldn't  you know  purposefully brain-damage a part of the system to make a worse baseline  or - You know? Well  I think people just had- it wasn't that they purposely brain-damaged it. I think people hadn't really thought through about the  uh - the V_A_D issue. Mmm. Mm-hmm. And - and then when the - the - the proposals actually came in and half of them had V_A_Ds and half of them didn't  and the half that did did well and the half that didn't did poorly. So it's - Mm-hmm. Mm-hmm. Um. Uh. Yeah. So we'll see what happen with this. And - Yeah. So what happened since  um  last week is - well  from O_G_I  these experiments on putting V_A_D on the baseline. And these experiments also are using  uh  some kind of noise compensation  so spectral subtraction  and putting on-line normalization  um  just after this. So I think spectral subtraction  L_D_A filtering  and on-line normalization  so which is similar to the pro- proposal-one  but with spectral subtraction in addition  and it seems that on-line normalization doesn't help further when you have spectral subtraction. Um. Is this related to the issue that you brought up a couple of meetings ago with the - the musical tones and - ? I - I have no idea  because the issue I brought up was with a very simple spectral subtraction approach  Mmm. and the one that they use at O_G_I is one from - from the proposed - the - the - the Aurora prop- uh  proposals  which might be much better. So  yeah. I asked Sunil for more information about that  but  uh  I don't know yet. Um. And what's happened here is that we - so we have this kind of new  um  reference system which use a nice - a - a clean downsampling-upsampling  which use a new filter that's much shorter and which also cuts Right. the frequency below sixty-four hertz  which was not done on our first proposal. When you say ""we have that""  does Sunil have it now  too  or - ? I- No. No. O_K. Because we're still testing. So we have the result for  O_K. uh  just the features and we are currently testing with putting the neural network in the K_L_T. Um  it seems to improve on the well-matched case  um  but it's a little bit worse on the mismatch and highly-mismatched - I mean when we put the neural network. And with the current weighting I think it's sh- it will be better because the well-matched case is better. Mmm. But how much worse - since the weighting might change - how - how much worse is it on the other conditions  when you say it's a little worse? It's like  uh  fff  fff um  ten percent relative. Yeah. O_K. Um. Mm-hmm. But it has the  uh - the latencies are much shorter. That's - Uh- y- w- when I say it's worse  it's not - it's when I - I - uh  compare proposal-two to proposal-one  so  r- uh  y- putting neural network compared to n- not having any neural network. Uh-huh. I mean  this new system is - is - is better  because it has um  this sixty-four hertz cut-off  uh  clean downsampling  and  um - what else? Uh  yeah  a good V_A_D. We put the good V_A_D. So. Yeah  I don't know. I - I - j- uh  uh - pr- But the latencies - but you've got the latency shorter now. Yeah. Latency is short - is - Yeah. Isn't it @@ And so- So it's better than the system that we had before. Yeah. Mainly because of the sixty-four hertz and the good V_A_D. O_K. And then I took this system and  mmm  w- uh  I p- we put the old filters also. So we have this good system  with good V_A_D  with the short filter and with the long filter  and  um  with the short filter it's not worse. So - well  is it - O_K. So that's - that's all fine. But what you're saying is that when you do these - So let me try to understand. When - when you do these same improvements to proposal-one  it's in - Yes. Uh - Mm-hmm. that  uh  on the - i- things are somewhat better  uh  in proposal-two for the well-matched case and somewhat worse for the other two cases. Yeah. So does  uh - when you say  uh - So - The th- now that these other things are in there  is it the case maybe that the additions of proposal-two over proposal-one are less im- important? Yeah. Probably  yeah. I get it. Um - So  yeah. Uh. Yeah  but it's a good thing anyway to have shorter delay. Then we tried  um  to do something like proposal-two but having  um  e- using also M_S_G features. So there is this K_L_T part  which use Mm-hmm. Right. just the standard features  and then two neura- two neural networks. Mm-hmm. Mmm  and it doesn't seem to help. Um  however  we just have one result  which is the Italian mismatch  so. Uh. We have to wait for that to fill the whole table  but - O_K. There was a start of some effort on something related to voicing or something. Is that - ? Yeah. Um  yeah. So basically we try to  uh  find good features that could be used for voicing detection  uh  but it's still  uh - on the  um - Oh  well  I have the picture. t- we - w- basically we are still playing with Matlab to - to look at - at what happened  and - What sorts of - Yeah. We have some - what sorts of features are you looking at? So we would be looking at  um  the variance of the spectrum uh  um  this  this  and this. of the excitation  something like this  which is - should be high for voiced sounds. Uh  we - Wait a minute. I - what does that mean? The variance of the spectrum of excitation. Yeah. So the - So basically the spectrum of the excitation for a purely periodic sig- signal shou- sh- O_K. Yeah  w- what yo- what you're calling the excitation  as I recall  is you're subtracting the - the  um - e- the mel - mel - mel filter  uh  spectrum from the F_F_T spectrum. Right. That's right. Yeah. So - Mm-hmm. Yeah. So we have the mel f- filter bank  we have the F_F_T  so we just - So it's - it's not really an excitation  but it's something that hopefully tells you something about the excitation. No. Yeah  that's right. Um - Yeah  yeah. Yeah. We have here some histogram  but they have a lot of overlap. E- yeah  but it's - it's still - Yeah. So  well  for unvoiced portion we have something tha- that has a mean around O_ point three  and for voiced portion the mean is O_ point fifty-nine. But the variance seem quite high. So - Mmm. How do you know - ? How did you get your voiced and unvoiced truth data? We used  uh  TIMIT and we used canonical mappings between the phones and Yeah. We  uh  use TIMIT on this  for - th- Yeah. But if we look at it in one sentence  it - apparently it's good  I think . Yeah  but - Yeah. Uh  so it's noisy TIMIT. That's right. Yeah. It's noisy TIMIT. Yeah. It seems quite robust to noise  so when we take - we draw its parameters across time for a clean sentence and then nois- the same noisy sentence  it's very close. Mm-hmm. Yeah. So there are - there is this. There could be also the  um - something like the maximum of the auto-correlation function or - which - Is this a - a s- a trained system? Or is it a system where you just pick some thresholds? Ho- how does it work? Right now we just are trying to find some features. Mm-hmm. And  uh - Yeah. Hopefully  I think what we want to have is to put these features in s- some kind of  um - well  to - to obtain a statistical model on these features and to - or just to use a neural network and hopefully these features w- would help - Because it seems like what you said about the mean of the - the voiced and the unvoiced - Mm-hmm. that seemed pretty encouraging. Right? Well  yeah  except the variance was big. Right? Yeah. Except the variance is quite high. Yeah. Well  y- Well  y- I - I don't know that I would trust that so much because you're doing these canonical mappings from TIMIT labelings. Right? So  Uh-huh. really that's sort of a cartoon picture about what's voiced and unvoiced. So that could be giving you a lot of variance. Yeah. I mean  i- it - it may be that - that you're finding something good and that the variance is sort of artificial because of how you're getting your truth. Yeah. But another way of looking at it might be that - I mean  what w- we- we are coming up with feature sets after all. Mm-hmm. So another way of looking at it is that um  the mel cepstru- mel spectrum  mel cepstrum  any of these variants  um  give you the smooth spectrum. It's the spectral envelope. By going back to the F_F_T  you're getting something that is more like the raw data. So the question is  what characterization - and you're playing around with this - another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you're missing that could help? So  I mean  looking at different statistical measures of that difference  coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise  where you're really just i- i- the way I'm looking at it is not so much you're trying to f- find the best - the world's best voiced-unvoiced  uh  uh  classifier  but it's more that  Mm-hmm. Mmm. you know  uh  uh  try some different statistical characterizations of that difference back to the raw data and - and Right. Right. m- maybe there's something there that the system can use. Yeah. Yeah  but ther- more obvious is that - Yeah. The - the more obvious is that - that - well  using the - th- the F_F_T  um  you just - it gives you just information about if it's voiced or not voiced  ma- mainly  I mean. But - So  Yeah. this is why we - we started to look by having Well  that's the rea- w- w- what I'm arguing is that's- sort of voiced Yeah. I mean  uh  what I'm arguing is that that - that's givi- you - gives you your intuition. phonemes and - But in - in reality  it's - you know  there's all of this - this overlap and so forth  Mm-hmm. Oh  sorry. and - But what I'm saying is that may be O_K  because what you're really getting is not actually voiced versus unvoiced  both for the fac- the reason of the overlap and - and then  uh  th- you know  structural reasons  uh  uh  like the one that Chuck said  that - that in fact  well  the data itself is - that you're working with is not perfect. Yeah. Mm-hmm. So  what I'm saying is maybe that's not a killer because you're just getting some characterization  one that's driven by your intuition about voiced-unvoiced certainly  Mm-hmm. but it's just some characterization of something back in the - in the - in the almost raw data  rather than the smooth version. Mm-hmm. And your intuition is driving you towards particular kinds of  uh  statistical characterizations of  um  what's missing from the spectral envelope. Mm-hmm. Um  obviously you have something about the excitation  um  and what is it about the excitation  and  you know - and you're not getting the excitation anyway  you know. So - so I - I would almost take a - uh  especially if - if these trainings and so forth are faster  I would almost just take a uh  a scattershot at a few different ways of look- of characterizing that difference and  uh  you could have one of them but - and - and see  you know  which of them helps. Mm-hmm. So i- is the idea that you're going to take whatever features you develop and - and just add them onto the future vector? O_K. Or  what's the use of the - the voiced-unvoiced detector? Uh  I guess we don't know exactly yet. But  um - Yeah. Th- It's not part of a V_A_D system that you're doing? No. Uh  no. No. No  the idea was  I guess  to - to use them as - as features. Oh  O_K. Features. I see. Uh - Yeah  it could be  uh - it could be a neural network that does voiced and unvoiced detection  Mm-hmm. but it could be in the - also the big neural network that does phoneme classification. Mm-hmm. Mmm. Yeah. But each one of the mixture components - I mean  you have  uh  uh  variance only  so it's kind of like you're just multiplying together these  um  probabilities from the individual features within each mixture. So it's - so  uh  it seems l- you know - I think it's a neat thing. Uh  it seems like a good idea. Yeah. Um. Yeah. I mean  I know that  um  people doing some robustness things a ways back were - were just doing - just being gross and just throwing in the F_F_T and actually it wasn't - wasn't - wasn't so bad. Uh  so it would s- and - and you know that i- it's gotta hurt you a little bit to not have a - a spectral  uh - a s- a smooth spectral envelope  so there must be something else that you get in return for that - that  uh - Mm-hmm. uh - So. So how does - uh  maybe I'm going in too much detail  but how exactly do you make the difference between the F_F_T and the smoothed spectral envelope? Wha- wh- i- i- uh  how is that  uh - ? Um  we just - How did we do it up again? Uh  we distend the - we have the twenty-three coefficient af- after the mel f- Mm-hmm. filter  and we extend these coefficient between the - all the frequency range. Mm-hmm. And i- the interpolation i- between the point is - give for the triang- triangular filter  the value of the triangular filter and of this way we obtained this mode- So you essentially take the values that - th- that you get from the triangular filter and extend them this model speech. S- to sor- sort of like a rectangle  that's at that Yeah. Mm-hmm. m- value. Yeah. I think we have linear interpolation. So we have - we have one point for - mmm Yeah  it's linear. Mmm. one energy for each filter bank  which is the energy that's centered on - on - on the triangle - Oh. Yeah. At the n- @@ at the center of the filter - So you - you end up with a vector that's the same length as the F_F_T vector? And then you just  uh  compute differences and  Yeah. That's right. Yeah. Yeah. I have here one example if you - if you want see something like that. Then we compute the difference. Yeah. Uh-huh. uh  sum the differences? O_K. So. And I think the variance is computed only from  like  two hundred hertz to one - to fifteen hundred. Oh! O_K. Mm-hmm. Two thou- two - fifteen hundred? No. Mm-hmm. Because - Right. Two hundred and fifty thousand. Fifteen hundred. Because - Yeah. Yeah. Two thousand and fifteen hundred. Above  um - it seems that - Well  some voiced sound can have also  like  a noisy part on high frequencies  and - Yeah. No  it's - makes sense to look at low frequencies. But - Well  it's just - So this is - uh  basically this is comparing an original version of the signal to a smoothed version of the same signal? Yeah. Right. So i- so i- i- this is - I mean  i- you could argue about whether it should be linear interpolation or - or - or - or zeroeth order  but - but Uh-huh. at any rate something like this is what you're feeding your recognizer  typically. Like which of the - ? No. Uh  so the mel cepstrum is the - is the - is the cepstrum of this - So this is - Yeah. Yeah. this  uh  spectrum or log spectrum  whatever it - You- you're subtracting in - in - in power domain or log domain? Right  right. In log domain. Yeah. Log domain. O_K. So it's sort of like division  when you do the - yeah  the spectra. Yeah. Uh  yeah. Um. It's the ratio. Yeah. But  anyway  um - and that's - So what's th- uh  what's the intuition behind this kind of a thing? I - I don't know really know the signal-processing well enough to understand what - So. what is that doing. Yeah. What happen if - what we have - have - what we would like to have is some spectrum of the excitation signal  Yeah. I guess that makes sense. Yeah. which is for voiced sound ideally a - a pulse train Uh-huh. and for unvoiced it's something that's more flat. Uh-huh. Right. And the way to do this is that - well  we have the - we have the F_F_T because it's computed in - in the - in the system  and we have Mm-hmm. the mel filter banks  Mm-hmm. and so if we - if we  like  remove the mel filter bank from the F_F_T  we have something that's close to the excitation signal. Oh. O_K. It's something that's like Oh! O_K. Yeah. a - a- a train of p- a pulse train for voiced sound and that's - that should be flat for - Yeah. Yeah. I see. So do you have a picture that sh- ? Is this for a voiced segment  this picture? So- It's - Y- yeah. Yeah. What does it look like for unvoiced? You have several - some unvoiced? The dif- No. Unvoiced  I don't have for unvoiced. I'm sorry. Oh. Yeah. So  you know  all - Yeah. But - Yeah. Yeah. This is the - between - This is another voiced example. Yeah. No. But it's this  Oh  yeah. This is - but between the frequency that we are considered for the excitation - for the difference and this is the difference. Right. Mm-hmm. This is the difference. O_K. Yeah. Yeah. So  of course  it's around zero  but - Well  no. It is - Sure looks - Hmm. Hmm. Yeah. Because we begin  uh  in fifteen So  point - the fifteen point. does - does the periodicity of this signal say something about the - the - Fifteen p- So it's - Pitch. Yeah. It's the pitch. Yeah. Mm-hmm. the pitch? O_K. Yeah. That's like fundamental frequency. Mm-hmm. So  I mean  i- t- t- I mean  to first order what you'd - what you're doing - O_K. I see. I mean  ignore all the details and all the ways which is - that these are complete lies. Mm-hmm. Uh  the - the - you know  what you're doing in feature extraction for speech recognition is you have  uh  in your head a - a - a - a simplified production model for speech  in which you have Yeah. Mm-hmm. This is the - the auto-correlation - the R_zero energy. a periodic or aperiodic source that's driving some filters. Do you have the mean - do you have the mean for the Uh  first order for speech recognition  you say ""I don't care about the source"". Right? For - auto-correlation - ? Yeah. I have the mean. Well  I mean for the - the energy. Right. Right. And so you just want to find out what the filters are. The filters roughly act like a  um - a  uh - Yeah. Here. They should be more close. Ah  no. This is this? More close. Is this? a- an overall resonant - you know  f- some resonances and so forth that th- that's processing excitation. And this. Mm-hmm. Mm-hmm. Yeah. So they are - this is - there is less difference. Mm-hmm. So if you look at the spectral envelope  just the very smooth properties of it  you get something closer to that. This is less - it's less robust. Less robust. Yeah. Oh  yeah. And the notion is if you have the full spectrum  with all the little nitty-gritty details  Yeah. that that has the effect of both  and it would be a multiplication in - in frequency domain so that would be like an addition in log - Mm-hmm. Mm-hmm. Mm-hmm. power spectrum domain. And so this is saying  well  if you really do have that sort of vocal tract envelope  and you subtract that off  what you get is the excitation. And I call that lies because you don't really have that  you just have some kind of signal-processing trickery to get something that's kind of smooth. It's not really what's happening in the vocal tract so you're not really getting the vocal excitation. Yeah. Right. That's why I was going to the - why I was referring to it in a more - a more  uh  uh  conservative way  when I was saying ""well  it's - yeah  it's the excitation"". But it's not really the excitation. It's whatever it is that's different between - Oh. This moved in the - Yeah. So - so  stand- standing back from that  you sort of say there's this very detailed representation. Mm-hmm. You go to a smooth representation. You go to a smooth representation cuz this typically generalizes better. Mm-hmm. Um  but whenever you smooth you lose something  so the question is have you lost something you can you use? Right. Um  probably you wouldn't want to go to the extreme of just ta- saying ""O_K  our feature set will be the F_F_T""  cuz we really think we do gain something in robustness from going to something smoother  Mm-hmm. but maybe there's something that we missed. Yeah. So what is it? And then you go back to the intuition that  well  you don't really get the excitation  but you get something related to it. Mm-hmm. Mm-hmm. And it - and as you can see from those pictures  you do get something that shows some periodicity  uh  in frequency  you know  and - and - and also in time. So - so  Hmm. That's - that's really neat. So you don't have one for unvoiced picture? Uh  not here. No  I have s- But not here. Oh. Mm-hmm. Yeah. But presumably you'll see something that won't have this kind of  uh  uh  uh  regularity in frequency  uh  in the - But - Yeah. Well. Not here. I would li- I would like to see those pictures. Yeah. Well  so. Yeah. I can't see you Yeah. now. Yeah. I don't have. Mm-hmm. And so you said this is pretty - doing this kind of thing is pretty robust to noise? It seems  yeah. Um  Pfft. Huh. Oops. The mean is different with it  because the - the histogram for the - the classifica- Oh! No  no  no. But th- the kind of robustness to noise - So if - if you take this frame  Hmm. uh  from the noisy utterance and the same frame from the clean utterance - You end up with a similar difference Y- y- y- yeah. We end up with - over here? Yeah. O_K. Cool! I have here the same frame for the clean speech - Oh  that's clean. Oh  O_K- the same cle- But they are a difference. Because here the F_F_T is only with Yeah  that's - two hundred fifty-six point and this is with five hundred twelve. Oh. O_K. Yeah. This is kind of inter- interesting also because if we use the standard  uh  frame length of - of  like  twenty-five milliseconds  um  what happens is that for low-pitched voiced  because of the frame length  y- you don't really have - you don't clearly see this periodic structure  Mm-hmm. because of the first lobe of - of each - each of the harmonics. So this one inclu- is a longer - Ah. So  this is like - yeah  fifty milliseconds or something like that. Fifty millis- Yeah. Yeah  but it's the same frame and - Oh  it's that time-frequency trade-off thing. Right? Yeah. I see. Yeah. Mm-hmm. Oh. Oh  so this i- is this the difference here  So  yeah. No. This is the signal. This is the signal. for that? I see that. Oh  yeah. The frame. Oh  that's the f- the original. This is the fra- the original frame. Yeah. So with a short frame basically you have only two periods and it's not - not enough to - to have this kind of neat things. But - Yeah. Mm-hmm. Yeah. Mm-hmm. And here - No  well. Yeah. So probably we'll have to use  like  long f- long frames. Mm-hmm. Mm-hmm. Hmm. Oh. That's interesting. Mmm. Yeah  maybe. Well  I mean it looks better  but  I mean  the thing is if - if  uh - if you're actually asking - you know  if you actually j- uh  need to do - place along an F_F_T  it may be - it may be pushing things. Yeah. And - and  uh - Would you - would you wanna do this kind of  uh  difference thing after you do spectral subtraction? Uh  maybe. No. Maybe we can do that. Mmm. Hmm. The spectral subtraction is being done at what level? Is it being done at the level of F_F_T bins or at the level of  uh  mel spectrum or something? Um  I guess it depends. I mean  how are they doing it? How they're doing it? Yeah. Um  I guess Ericsson is on the  um  filter bank  no? F_F_T. Filter bank  yeah. It's on the filter bank  so. So  yeah  probably - So in that case  it might not make much difference at all. I- i- it - Yeah. Seems like you'd wanna do it on the F_F_T bins. Maybe. I mean  certainly it'd be better. I- I mean  if you were gonna - uh  for - for this purpose  that is. Mm-hmm. Yeah. Yeah. Mm-hmm. O_K. Mmm. What else? Uh. Yeah  that's all. @@ So we'll perhaps try to convince O_G_I people to use the new - the new filters and - Yeah. O_K. Uh  has - has anything happened yet on this business of having some sort of standard  uh  Uh  source  or - ? not yet but I wi- I will call them and - O_K. now they are - I think they have more time because they have this - well  Eurospeech deadline is over and - When is the next  um  Aurora deadline? It's  um  in June. June. Yeah. Early June  late June  middle June? I don't know w- Hmm. Hmm. O_K. Um  and he's been doing all the talking but - but these - he's - he's  uh - Yeah. This is - this by the way a bad thing. We're trying to get  um  m- more female voices in this record as well. So. Make sur- make sure Carmen talks as well. Uh  but has he pretty much been talking about what you're doing also  and - ? Oh  I - I am doing this. Yeah  yeah. I don't know. I'm sorry  but Yes. I think that for the recognizer for the meeting recorder that it's better that I don't speak. Yeah  well. You know  uh  we'll get - we'll get to  uh  Spanish voices sometime  and we do - we want to recognize  uh  you too. Because - After the - after  uh  the result for the T_I-digits on the meeting record there will be foreigns people. Y- Yeah  but - Oh  no. We like - we - we're - we're - w- we are - we're in the  uh  Bourlard-Hermansky-Morgan  uh  frame of mind. Yeah  we like high error rates. It's - That way there's lots of work to do. So it's - Yeah. Uh  anything to N- um  not- not- not much is new. So when I talked about what I'm planning to do last time  talk about? I said I was  um  going to use Avendano's method of  um  using a transformation  um  to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation. He has a trick for doing that involving viewing the D_F_T as a matrix. Um  but  uh  um  I decided not to do that after all because I - I realized to use it I'd need to have these short analysis frames get plugged directly into the feature computation somehow and right now I think our feature computation is set to up to  um  Mm-hmm. take  um  audio as input  in general. So I decided that I - I'll do the reverberation removal on the long analysis windows and then just re-synthesize audio and then send that. This is in order to use the S_R_I system or something. Right? Um  or - or even if I'm using our system  I was thinking it might be easier to just re-synthesize the audio  Yeah? because then I could just feacalc as is and I wouldn't have to change the code. Oh  O_K. Yeah. I mean  it's - um  certainly in a short - short-term this just sounds easier. Uh-huh. Yeah. I mean  longer-term if it's - if it turns out to be useful  one - one might want to Right. That's true. do something else  but - Uh  uh  I mean  in - in other words  you - you may be putting But - e- u- other kinds of errors in from the re-synthesis process. From the re-synthesis? Um  O_- O_K. I don't know anything about re-synthesis. Uh  how likely do you think that is? Yeah. Uh  it depends what you - what you do. I mean  it's - it's - it's  uh  um - Don't know. But anyway it sounds like a reasonable way to go for a - for an initial thing  and we can look at - at exactly what you end up doing and - and then figure out if there's some - something that could be - be hurt by the end part of the process. O_K. O_K. So that's - That - Yeah  e- That's it  that's it. Uh-huh. That was it  huh? O_K. O_K. Um  anything to add? Um. Well  I've been continuing reading. I went off on a little tangent this past week  um  looking at  uh  uh  modulation s- spectrum stuff  um  and - and learning a bit about what - what  um - what it is  and  uh  the importance of it in speech recognition. And I found some - some  uh  neat papers  um  historical papers from  um  Kanedera  Hermansky  and Arai. And they - they did a lot of experiments where th- where  um  they take speech Yeah. and  um  e- they modify the  uh - they - they - they measure the relative importance of having different  um  portions of the modulation spectrum intact. And they find that the - the spectrum between one and sixteen hertz in the modulation is  uh - is im- important for speech recognition. Yeah. Um. Sure. I mean  this sort of goes back to earlier stuff by Drullman. Yeah. And - and  uh  the - the M_S_G features were sort of built up Right. with this notion - But  I guess  I thought you had brought this up in the context of  um  targets somehow. Right. Um - But i- m- i- it's not - I mean  they're sort of not in the same kind of category as  say  a phonetic target or a syllabic target or a - Mmm. Mm-hmm. Um  I was thinking more like using them as - as the inputs to - to the detectors. or a feature or something. Oh  I see. Yeah. Well  that's sort of what M_S_G does. Yeah. Right? So it's - Mm-hmm. But - but  uh - S- Yeah. Yeah. Anyway  we'll talk more about it later. Yeah. O_K. We can talk more about it later. Yeah. Yeah. Yeah. So maybe  le- let's do digits. Should we do digits? Let you - you start. Oh  O_K. Reading transcript L_ dash five six. One seven six eight  six six nine one  seven nine two one. Two O_ three  five O_  O_ one two five. Four zero five six  four  three three four. Nine two nine zero  three one one four  eight six two nine. Four one three  six two five  six six nine zero. Four three  six seven  six one  five two  nine eight. Seven six  three three  three seven  seven eight  two three. Eight four two  six one  four six two seven. Transcript L_ fifty-five  or transcript L_ five five. Six eight seven  seven one five  zero seven five. Eight nine six zero  three  eight six five. Five six six  two zero  zero two nine six. Eight four two eight  nine  one six four. One six eight  six two  four zero one three. Three one  two six  six one  nine nine  six zero. Eight three seven zero  eight  zero eight zero. Six two three six  four zero zero six  nine seven four three. Transcript L_ dash four nine. Eight eight four  two five nine  seven four five zero. Seven eight seven  zero one zero  six one five eight. Seven four  two two  five zero  three nine  seven zero. Eight five eight  zero three  four seven one four. Zero six zero  four four  two  zero zero one. Two two nine three  three  one two eight. Eight  five five eight  five five  eight six nine  one. Three five eight  two nine  four O_ one seven. Transcript L_ fifty. Um  nine O_ six seven  three  nine three three. O_  eight three O_  O_ eight  three four eight  one. Two one three  six five  three one five nine. Four O_  eight four  three O_  five two  one one. Nine two four  five eight four  five five zero four. Two two  two six  one six  eight one  five five. Seven O_ seven  O_ eight seven  eight four O_ two eight O_ three  one six O_  five O_  seven four. Transcript L_ dash fifty three. Five nine  five four  eight eight  three nine  one four. Eight six zero  three one zero  nine seven five three. Five five  five two  nine nine  three three  six five. Three three seven  zero seven  four seven one zero. Six four one eight  three  one six six. Five seven six  eight nine five  nine one six. Two two  eight three  three zero  five five  nine five. Zero five nine  six one five  zero two five. Transcript L_ dash f- fifty-four. One four three one seven seven one O_ three two. Nine eight two four eight eight eight one two. One three one  zero five seven  six eight one two. Six two eight eight  seven five  nine one  two zero. Five two seven two  eight  six one seven. Four nine eight  O_ O_ O_  seven zero nine. Eight six two  four five  eight eight  nine two. Two two one  one nine  six seven eight three. Right. @@ ",The main topics discussed were arrangements and objectives of an upcoming field trip to visit research partners OGI; a number of members reported their progress to date; if there are any tasks that one member can help others with; an overall description of the Cube project  a multi-lingual speech recognition system for use by the cellular phone industry  along with consideration of some of the issues therein  specifically disk and resource issues. Essentially the cube consists of three dimension: input features; training corpus; and test corpus. Most important concerns are which combinations of features to use  and what combinations of languages and broad/specific corpora to use for the training The group will meet at the building at 6am to go to the airport for their field trip together. Speaker me018 needs to discuss files that can be moved with speaker mn007. For the OGI meeting they need to take a clear description of the cube project  and an estimate of how long the entire process should take. At the meeting they should discuss what they will ultimately put through the system. People are to consider what me034 could do on the project to speed things up  though creating the phoneme superset is a possibility. Speaker me018 is to look into the machines that mn007 has been running data on to find out what they are. Rather than consider level of normalization as a further dimension to the project  whatever OGI finds the best will be used systematically. Need to use multiple machines and SPERT boards to run processes on because they take so long. They will consider looking at articulatory features rather than straight phonemes  though it wouldn't be perfect. It is not clear what combinations of dimensions  which features  should be run in the cube project. It is important to know because the processes are going to be large and processor and memory hungry. To bear in mind is the fact that the cellular industry has an image of speech recognition in that's what they are after. Must be careful if using a broad training source that is carefully hand marked  because it would be unclear which is the reason for improvement. Memory is of concern  because final product needs to run potentially one cheaper cell phones  which have limited memory capacity. OGI doesn't have a phoneme superset ready prepared  for they are working with clusters  which may be good enough for digits  but not for discriminating words. Speaker mn007 has been preparing the French digit database. Training and testing with varying noise. speaker me006 has installed updated software for everyone. Working on label files from TIMIT for training neural nets. Trying to figure out what the input to the cube should be. speaker fn002 has been testing the Italian database on a net trained on Spanish. She has had problems with incompatible labels though. Within the next year  the network is to be upgraded  and in a couple of weeks  the group should have access to 4 new 36 gigabyte file servers. Me018 has been copying some corpus stuff to a non-backed up system  but not yet deleted originals. Current plan is to use a superset of phones for the cube project derived from the various training languages. HTK training currently takes 6 hours to a day  and the neural net takes 1-2 days. 
"Uh  is it the twenty-fourth? Yeah. now we're on. Uh Chuck  is the mike type wireless - Yes. wireless headset? O_K. Yes. Yeah. For you it is. Yeah. We uh - we abandoned the lapel because they sort of were not too - not too hot  not too cold  they were - you know  they were uh  far enough away that you got more background noise  uh  and uh - and so forth but they weren't so close that they got quite the - you know  the really good - No  th- Uh-huh. O_K. they - I mean they didn't - Wait a minute. I'm saying that wrong. They were not so far away that they were really good representative distant mikes  but on the other hand they were not so close that they got rid of all the interference. So it was no - didn't seem to be a good point to them. Uh-huh. On the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice  precisely because it's in the middle. Yeah  yeah. There's uh  some kinds of junk that you get with these things that you don't get with the lapel uh  little mouth clicks and breaths and so forth are worse with these than with the lapel  but given the choice we - there seemed to be very strong opinions for uh  getting rid of lapels. So  The mike number is - Uh  your mike number's written on the back of that unit there. Oh yeah. One. And then the channel number's usually one less than that. Oh  O_K. It- it's one less than what's written on the back of your - yeah. O_K. O_K. O_K. So you should be zero  actually. Hello? Yeah. For your uh  channel number. Yep  yep. And you should do a lot of talking so we get a lot more of your pronunciations. no  they don't - don't have a - have any Indian pronunciations. So what we usually do is um  we typically will have our meetings and then at the end of the meetings we'll read the digits. Everybody goes around and reads the digits on the - the bottom of their forms. Yeah. Session R_- R_nineteen? R_nineteen. O_K. Yeah. We're - This is session R_nineteen. If you say so. O_ K. Do we have anything like an agenda? What's going on? Um. I guess um. So. One thing - Sunil's here for the summer? Sunil's here for the summer  right. Um  so  one thing is to talk about a kick off meeting maybe uh  and then just uh  I guess uh  progress reports individually  and then uh  plans for where we go between now and then  pretty much. Um. I could say a few words about um  some of the uh  compute stuff that's happening around here  so that people in the group know. Mm-hmm. O_K. Why don't you start with that? That's sort of - Yeah? O_K. We um - So we just put in an order for about twelve new machines  uh  to use as sort of a compute farm. And um  uh  we ordered uh  SUN-Blade-one-hundreds  and um  I'm not sure exactly how long it'll take for those to come in  but  uh  in addition  we're running - So the plan for using these is  uh  we're running P_make and Customs here and Andreas has sort of gotten that all uh  fixed up and up to speed. And he's got a number of little utilities that make it very easy to um  run things using P_make and Customs. You don't actually have to write P_make scripts and things like that. The simplest thing - And I can send an email around or  maybe I should do an F_A_Q on the web site about it or something. Um  there's a c- How about an email that points to the F_A_Q  you know what I'm saying? so that you can - Yeah. Yeah  yeah. Uh  there's a command  uh  that you can use called "" run command"". ""Run dash command""  ""run hyphen command"". And  if you say that and then some job that you want to execute  uh  it will find the fastest currently available machine  and export your job to that machine  and uh - and run it there and it'll duplicate your environment. So you can try this as a simple test with uh  the L_ S command. So you can say ""run dash command L_ S ""  and  um  it'll actually export that L_S command to some machine in the institute  and um  do an L_S on your current directory. So  substitute L_S for whatever command you want to run  and um - And that's a simple way to get started using - using this. And  so  soon  when we get all the new machines up  um  e- then we'll have lots more compute to use. Now th- one of the nice things is that uh  each machine that's part of the P_make and Customs network has attributes associated with it. Uh  attributes like how much memory the machine has  what its speed is  what its operating system  and when you use something like "" run command""  you can specify those attributes for your program. For example if you only want your thing to run under Linux  you can give it the Linux attribute  and then it will find the fastest available Linux machine and run it on that. So. You can control where your jobs go  to a certain extent  all the way down to an individual machine. Each machine has an attribute which is the name of itself. So you can give that as an attribute and it'll only run on that. If there's already a job running  on some machine that you're trying to select  your job will get queued up  and then when that resource  that machine becomes available  your job will get exported there. So  there's a lot of nice features to it and it kinda helps to balance the load of the machines and uh  right now Andreas and I have been the main ones using it and we're - Uh. The S_R_I recognizer has all this P_make customs stuff built into it. So. So as I understand  you know   he's using all the machines and you're using all the machines  Yeah. Exactly. is the rough division of - Yeah  you know  I - I sort of got started using the recognizer just recently and uh  uh I fired off a training job  and then I fired off a recognition job and I get this email about midnight from Andreas saying  ""uh  are you running two trainings simultaneously s- my m- my jobs are not getting run."" So I had to back off a little bit. But  soon as we get some more machines then uh - then we'll have more compute available. So  um  that's just a quick update about what we've got. So. Um  I have - I have a question about the uh  parallelization? Mm-hmm. So  um  let's say I have like  a thousand little - little jobs to do? Mm-hmm. Um  how do I do it with ""run command""? I mean do - You could write a script uh  which called run command on each sub-job right? But you probably Uh-huh. A thousand times? O_K. wanna be careful with that because um  you don't wanna saturate the network. Uh  so  um  you know  you should - you should probably not run more than  say ten jobs yourself at any one time  uh  just because then it would Oh  too much file transfer and stuff. keep other people - Well it's not that so much as that  you know  e- with - if everybody ran fifty jobs at once then it would just bring everything to a halt and  you know  people's jobs would get delayed  so it's sort of a sharing thing. O_K. Um  so you should try to limit it to somet- sometim- some number around ten jobs at a time. Um. So if you had a script for example that had a thousand things it needed to run  um  you'd somehow need to put some logic in there if you were gonna use ""run command""  uh  to only have ten of those going at a time. And uh  then  when one of those finished you'd fire off another one. Um  I remember I - I forget whether it was when the Rutgers or - or Hopkins workshop  I remember one of the workshops I was at there were - everybody was real excited cuz they got twenty-five machines and there was some kind of P_make like thing that sit- sent things out. Mm-hmm. Mm-hmm. Mm-hmm. So all twenty-five people were sending things to all twenty-five machines and and things were a lot less efficient than if you'd just use your own machine. as I recall  but. Yeah. Yeah. Yeah. Yep. Yeah  exactly. Yeah  you have to be a little bit careful. Hmm. Um  but uh  you can also - If you have that level of parallelization um  and you don't wanna have to worry about writing the logic in - in a Perl script to take care of that  you can use um  P_make Just do P_make. s- and - and you basically write a Make file that uh  you know your final job depends on these one thousand things  and when you run Mm-hmm. P_make  uh  on your Make file  you can give it the dash capital J_ Mm-hmm. and - and then a number  and that number represents how many uh  machines to use at once. Right. And then it'll make sure that it never goes above that. Right. O_K. So  I can get some documentation. So it - it's - it's not systematically queued. I mean all the jobs are running. If you launch twenty jobs  they are all running. It depends. If you - ""Run command""  that I mentioned before  is - doesn't know about other things that you might be running. Alright. Uh-huh. So  it would be possible to run a hundred run jobs at once  Right. and they wouldn't know about each other. But if you use P_make   then  it knows about all the jobs that it has to run Mm-hmm. and it can control  uh  how many it runs simultaneously. So ""run command"" doesn't use P_make  or - ? It uses ""export"" underlyingly. But  if you - i- It's meant to be run one job at a time? So you could fire off a thousand of those  and it doesn't know - any one of those doesn't know about the other ones that are running. So why would one use that rather than P_make ? Well  if you have  um - Like  for example  uh if you didn't wanna write a P_make script and you just had a  uh - an H_T_K training job that you know is gonna take uh  six hours to run  and somebody's using  uh  the machine you typically use  you can say ""run command"" and your H_T_K thing and it'll find another machine  the fastest currently available machine and - and run your job there. Now  does it have the same sort of behavior as P_make  which is that  you know  if you run something on somebody's machine and they come in and hit a key then it - Yes. Yeah  there are um - Right. So some of the machines at the institute  um  have this attribute called "" no evict"". And if you specify that  in - in one of your attribute lines  then it'll go to a machine which your job won't be evicted from. Mm-hmm. But  the machines that don't have that attribute  if a job gets fired up on that  which could be somebody's desktop machine  and - and they were at lunch  they come back from lunch and they start typing on the console  Mm-hmm. then your machine will get evicted - your job will get evicted from their machine and be restarted on another machine. Automatically. So - which can cause you to lose time  right? If you had a two hour job  and it got halfway through and then somebody came back to their machine and it got evicted. So. If you don't want your job to run on a machine where it could be evicted  then you give it the minus - the attribute  you know  ""no evict""  and it'll pick a machine that it can't be evicted from. So. Um  what - what about - I remember always used to be an issue  maybe it's not anymore  that if you - if something required - if your machine required somebody hitting a key in order to evict things that are on it so you could work  Mm-hmm. but if you were logged into it from home? and you weren't hitting any keys? cuz you were  home? Yeah  I - I'm not sure how that works. Uh  it seems like Andreas did something for that. Um. Yeah. Hmm. O_K. We can ask him sometime. But - Yeah. I don't know whether it monitors the keyboard or actually looks at the console T_T_Y  so maybe if you echoed something to the you know  dev - dev console or something. Hmm? You probably wouldn't ordinarily  though. Yeah. Right? You probably wouldn't ordinarily. I mean you sort of - you're at home and you're trying to log in  and it takes forever to even log you in  and you probably go  ""screw this""  and - You know. Yeah. Yeah  yeah. Yeah. Yeah  so  um  yeah. I - I can - I'm not sure about that one. But uh. yeah. O_K. Uh  I need a little orientation about this environment and uh scr- s- how to run some jobs here because I never d- did anything so far with this X_ emissions So  O_K. I think maybe I'll ask you after the meeting. Um. Yeah. Yeah  and - and also uh  Stephane's a - a really good resource for that if you can't Yeah  yeah  yeah. Yep. O_K  sure @@ find me. Mmm. Especially with regard to the Aurora stuff. He - he knows that stuff better than I do. O_K. O_K. Well  why don't we uh  uh  Sunil since you're haven't - haven't been at one of these yet  why don't yo- you tell us what's - what's up with you? Wh- what you've been up to  hopefully. Um. Yeah. So  uh  shall I start from - Well I don't know how may I - how - O_K. Uh  I think I'll start from the post uh Aurora submission maybe. Yeah. Uh  yeah  after the submission the - what I've been working on mainly was to take - take other s- submissions and then over their system  what they submitted  because we didn't have any speech enhancement system in - in ours. So - So I tried uh  And u- First I tried just L_D_A. And then I found that uh  I mean  if - if I combine it with L_D_A  it gives @@ improvement over theirs. Uh - Are y- are you saying L_D_A? Yeah. L_D_A. O_K. Yeah. So  just - just the L_D_A filters. I just plug in - I just take the cepstral coefficients coming from their system and then plug in L_D_A on top of that. Mm-hmm. But the L_D_A filter that I used was different from what we submitted in the proposal. What I did was I took the L_D_A filter's design using clean speech  uh  mainly because the speech is already cleaned up after the enhancement so  instead of using this  uh  narrow - narrow band L_D_A filter that we submitted uh  I got new filters. So that seems to be giving - uh  improving over their uh  system. Slightly. But  not very significantly. And uh  that was uh  showing any improvement over - final - by plugging in an L_D_A. And uh  so then after - after that I - I added uh  on-line normalization also on top of that. And that - there - there also I n- I found that I have to make some changes to their time constant that I used because th- it has a - a mean and variance update time constant and - which is not suitable for the enhanced speech  and whatever we try it on with proposal-one. But um  I didn't - I didn't play with that time constant a lot  I just t- g- I just found that I have to reduce the value - I mean  I have to increase the time constant  or reduce the value of the update value. That's all I found So I have to . Uh  Yeah. And uh  uh  the other - other thing what I tried was  I just um  uh  took the baseline and then ran it with the endpoint inf- uh th- information  just the Aurora baseline  to see that how much the baseline itself improves by just supplying the information of the - I mean the w- speech and nonspeech. And uh  I found that the baseline itself improves by twenty-two percent by just giving the wuh- . Uh  can you back up a second  I - I - I missed something  uh  I guess my mind wandered. Ad- ad- When you added the on-line normalization and so forth  uh  uh things got better again? or is it? Did it not? Yeah. No. No. No  things didn't get better with the same time constant that we used. No  no. With a different time constant. With the different time constant I found that - I mean  I didn't get an improvement over not using on-line normalization  Oh. No you didn't  O_K. because I - I found that I would have change the value of the update factor. But I didn't play it with Yeah. play - play quite a bit to make it better than. O_K. So  it's still not - I mean  the on-line normalization didn't give me any improvement. O_K. And uh  O_K. so  oh yeah So I just stopped there with the uh  speech enhancement. The - the other thing what I tried was the - adding the uh  endpoint information to the baseline and that itself gives like twenty-two percent because the - the second - the new phase is going to be with the endpointed speech. And just to get a feel of how much the baseline itself is going to change by adding this endpoint information  I just  Hmm. uh  use - So people won't even have to worry about  uh  doing speech-nonspeech then. Yeah that's  that's what the feeling is like. They're going to give the endpoint information. Mmm. I see. G- I guess the issue is that people do that anyway  everybody does that  and they wanted to see  Yeah. given that you're doing that  what - what are the best features that you should use. Yeah  I see. So  I mean clearly they're interact. So I don't know that I entirely agree with it. But - but it might be uh - In some ways it might be better t- to - Yeah. rather than giving the endpoints  to have a standard Mm-hmm. that everybody uses and then interacts with. But  you know. It's - it's still someth- reasonable. So  are people supposed to assume that there is uh - Are - are people not supposed to use any speech outside of those endpoints? Uh - Or can you then No. No. That i- I - use speech outside of it for estimating background noise and things? Yeah. Yeah  yeah  exactly. I guess that is - that is where the consensus is. Like y- you will - you will - You'll be given the information about the beginning and the end of speech but the whole speech is available to you. O_K. So it should make the spectral subtraction style things work even better  So. because you don't have the mistakes in it. Yeah. Yeah? O_K. Yeah. So - So that - that - The baseline itself - I mean  it improves by twenty-two percent. I found that in s- one of the SpeechDat-Car cases  that like  the Spanish one improves by just fifty percent by just putting the endpoint. Wow. w- I mean you don't need any further speech enhancement with fifty. So  uh  So the baseline itself improves by fifty percent. Yeah  by fifty percent. Yeah. So it's g- it's gonna be harder to beat that actually. But - but - Wow. Yeah. Yeah  so - so that is when uh  the - the qualification criteria was reduced from fifty percent to something like twenty-five percent for well-matched. And I think they have - they have actually changed their qualification c- criteria now. And uh  Yeah  I guess after that  I just went home f- I just had a vacation fo- for four weeks. O_K. No  that's - that's - that's a good - good update. Uh. Ye- Yeah  and I - I came back and I started working on uh  some other speech enhancement algorithm. I mean  so - I - from the submission what I found that people have tried spectral subtraction and Wiener filtering. These are the main uh  approaches where people have tried  so just to - Yeah. just to fill the space with some f- few more speech enhancement algorithms to see whether it improves a lot   I - I've been working on this uh  signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s- and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace. Mm-hmm. And - So  I've been actually running some s- So far I've been trying it only on Matlab. I have to - Yeah. to - to test whether it works first or not and then I'll p- port it to C_ and I'll update it with the repository once I find it- it giving any some positive result. So  yeah. S- So you s- you So you said one thing I want to jump on for a second. So - so now you're - you're getting tuned into the repository thing that he has here and - Yeah. so we- we'll have a single place where the stuff is. Yep. Yeah. Cool. Um  so maybe uh  just briefly  you could remind us about the related experiments. Cuz you did some stuff that you talked about last week  I guess? Mm-hmm. Um  where you were also combining something - both of you I guess were both combining something from the uh  Right. French Telecom system with the u- uh - I - I don't know whether it was system one or system two  or - ? Mm-hmm. It was system one. So we - O_K. The main thing that we did is just to take the spectral subtraction from the France Telecom  which provide us some speech samples that are uh  with noise removed. So I let me - let me just stop you there. So then  one distinction is that uh  you were taking the actual France Telecom features and then applying something to - Uh  no there is a slight different. Uh I mean  which are extracted at the handset Yeah. because they had another back-end blind equalization - Yeah. Yeah. Yeah. But that's what I mean. But u- u- Sorry  yeah  I'm not being - I'm not being clear. Yeah. Yeah. What I meant was you had something like cepstra or something  right? Yeah  yeah  yeah  yeah. And so one difference is that  I guess you were taking spectra. The speech. Yeah. Yeah. But I guess it's the s- exactly the same thing because on the heads- uh  handset they just applied this Wiener filter and then compute cepstral features  right? or - ? Yeah  the cepstral f- The difference is like - There may be a slight difference in the way - because they use exactly the baseline system for converting the cepstrum once you have the speech. Right. I mean  if we are using our own code for th- I mean that - that could be the only difference. I mean  there is no other difference. Yeah. Mm-hmm. But you got some sort of different result. So I'm trying to understand it. But uh  Yeah  well I think we should uh  have a table with all the result because I don't know I uh  I don't exactly know what are your results? But  I th- O_K. O_K. Mmm. Yeah  but so we did this  and another difference I guess is that we just applied uh  proposal-one system after this without - well  with our modification to reduce the delay of the - the L_D_A filters  and Uh-huh. Well there are slight modifications  but it was the full proposal-one. In your case  if you tried And the filter - Only L_D_A. just putting L_D_A  then maybe on-line normalization - ? Yeah. Af- I - after that I added on-line normalization  yeah. Mm-hmm. So we just tried directly to - to just  keep the system as it was and  um  when we plug the spectral subtraction it improves uh  signif- significantly. Um  but  what seems clear also is that we have to retune the time constants of the on-line normalization. Because if we keep the value that was submitted Yeah  yeah. Yeah. uh  it doesn't help at all. You can remove on-line normalization  or put it  it doesn't change anything. Uh  uh  as long as you have the spectral subtraction. But  you can still find some kind of optimum somewhere  and we don't know where exactly but  Yeah. uh. Yeah  I assume. So it sounds like you should look at some tables of results or something and see where i- Right. Yeah. Yeah. where the - Mm-hmm. where they were different and what we can learn from it. Mm-hmm. without any change. Yeah. But it's - O_K. Well  It's the new. with - with - The new. with changes  because we change it the system to have - with Oh yeah  I mean the - the new L_D_A filters. I mean - O_K. The new. Yeah. L_D_A filters. There are other things that we finally were shown to improve also like  the sixty-four hertz cut-off. Mm-hmm. Mm-hmm. w- Uh  it doesn't seem to hurt on T_I-digits  finally. O_K. Maybe because of other changes. O_K. Um  well there are some minor changes  yeah. Mm-hmm. And  right now if we look at the results  it's  um  always better than - it seems always better than France Telecom for mismatch and high-mismatch. And it's still slightly worse for well-matched. Um  But but this is not significant. But  the problem is that it's not significant  but if you put this in the  mmm  uh  spreadsheet  it's still worse. Even with very minor - uh  even if it's only slightly worse for well-matched. Mm-hmm. And significantly better for H_M. Uh  but  well. I don't think it's importa- important because when they will change their metric  uh  uh  mainly because of uh  when you p- you plug the um  frame dropping in the baseline system  it will improve a lot H_M  and M_M  so  Yeah. um  I guess what will happen - I don't know what will happen. But  the different contribution  I think  for the different test set will be more even. Because the - your improvement on H_M and M_M will also go down significantly in the spreadsheet so. But the the well-matched may still - I mean the well-matched may be the one which is least affected by adding the Mm-hmm. endpoint information. Right. Yeah. So the - the M_M - Mm-hmm. M_M and H_M are going to be v- hugely affected by it. Yeah. Yeah  so um  yeah. Yeah. But they d- the - everything I mean is like  but there that's how they reduce - why they reduce the qualification to twenty-five percent or some - something on. Mm-hmm. But are they changing the weighting? Uh  no  I guess they are going ahead with the same weighting. Yeah. Yeah. So there's nothing on - I don't understand that. I guess I - I haven't been part of the Yeah. discussion  so  um  it seems to me that the well-matched condition is gonna be unusual  in this case. Unusual. Usual. Uh-huh. Because  um  you don't actually have good matches ordinarily for what any @@ - particular person's car is like  or uh  Mmm. Mmm. It seems like something like the middle one is - is more Hmm. natural. So I don't know why the well-matched is Right . uh - Mm-hmm. Yeah  but actually the well - well the well-matched um  uh  I mean the - the well-matched condition is not like  uh  the one in T_I-digits where uh  you have all the training  uh  conditions exactly like replicated in the testing condition also. It's like  this is not calibrated by S_N_R or something. The well-matched has also some - some mismatch in that which is other than the - The well wa- matched has mismatch? has - has also some slight mismatches  unlike the T_I-digits where it's like perfectly matched because it's artificially added noise. Perfect to match. Yeah. Yeah. But this is natural recording. So remind me of what well-matched meant? You've told me many times. The - the well-matched is like - the - the well-matched is defined like it's seventy percent of the whole database is used for training and thirty percent for testing. Yeah. Well  so it means that if the database is large enough  it's matched. Because It's - it's - O_K  it's - it Yeah. in each set you have a range of conditions - Well - Right. So  I mean  yeah  unless they deliberately chose it to be different  which they didn't because they want it to be well-matched  it is pretty much - You know  so it's - so it's sort of saying if you - It's - it's not guaranteed though. Yeah. Uh  it's not guaranteed. Right. Right. Yeah. Mm-hmm. Yeah because the m- the main - major reason for the m- the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually. Again  if you have enough - if you have enough - No- yeah  yeah. Yeah. So it's sort of i- i- it's sort of saying O_K  so you - much as you train your dictation machine for talking into your computer  um  you - you have a car  and so you drive it around a bunch and - and record noise conditions  or something  and then - I don't think that's very realistic  I mean I th- I - I you know  so I - Mm-hmm. I - I - you know  I guess they're saying that if you were a company that was selling the stuff commercially  that you would have a bunch of people driving around in a bunch of cars  and - and you would have something that was roughly similar and maybe that's the argument  but I'm not sure I buy it  so. Yeah  yeah  yeah. Uh  So What else is going on? Mmm. You- Yeah. We are playing - we are also playing  trying to put other spectral subtraction mmm  in the code. Um  it would be a very simple spectral subtraction  on the um  mel energies which I already tested but without the um frame dropping actually  and I think it's important to have frame dropping Is it - is spectral subtraction typically done on the - after the mel  uh  scaling or is it done on the F_F_T bins? if you use spectral subtraction. Um  Does it matter  or - ? I d- I don't know. Well  it's both - both uh  cases can i- Oh. Yeah. So- some of the proposal  uh  we're doing this on the bin - on the F_F_T bins  others on the um  mel energies. You can do both  but I cannot tell you what's - Hmm. which one might be better or - Hmm. I - I guess if you want to reconstruct the speech  it may be a good idea to do it on F_F_T bins. I don't know. Mmm. Yeah  but But for speech recognition  it may not. I mean it may not be very different if you do it on mel warped or whether you do it on F_F_T. I see. So you're going to do a linear weighting anyway after that. Well - Yeah? Hmm. So  it may not be really a big different. Well  it gives something different  but I don't know what are the  pros and cons of It- I- Uh-huh. both. Hmm. So O_K. The other thing is like when you're putting in a speech enhancement technique  uh  is it like one stage speech enhancement? Because everybody seems to have a mod- two stages of speech enhancement in all the proposals  which is really giving them some improvement. Yeah. Mm-hmm. Mm-hmm. I mean they just do the same thing again once more. Mm-hmm. And - So  there's something that is good about doing it - I mean  to cleaning it up once more. Yeah  it might be. Yeah. Yeah  so we can - So maybe in my implementation I should also Yeah. try to inspire me from That's what this kind of thing and - Yeah. Well  the other thing would be to combine what you're doing. I mean maybe one or - one or the other of the things that you're doing would benefit from the other happening first. That's wh- Yeah. So  Right  so he's doing a signal subspace thing  maybe it would work better if you'd already done some simple spectral subtraction  or maybe vi- maybe the other way around  you know? Yeah  mm-hmm. Yeah. So I 've been thinking about combining the Wiener filtering with signal subspace  Mm-hmm. I mean just to see all - some - some such permutation combination to see whether it really helps or not. Mm-hmm. Mm-hmm. Mm-hmm. Yeah. Yeah. How is it - I - I guess I'm ignorant about this  how does - I mean  since Wiener filter also assumes that you're - that you're adding together the two signals  how is - how is that differ from signal subspace? The signal subspace? Yeah. The - The signal subspace approach has actually an in-built Wiener filtering in it. Oh  O_K. Yeah. It is like a K_L transform followed by a Wiener filter. Is the signal is - is a signal substrate . Oh  oh  O_K so the difference is the K_L. So  the - the different - the c- the - the advantage of combining two things is mainly coming from the signal subspace approach doesn't work very well if the S_N_R is very bad. It's - I see. it works very poorly with the poor S_N_R conditions  and in colored noise. So essentially you could do simple spectral subtraction  followed by a K_L transform  followed by a Wiener filtering. Wiener filter. It's a - it's a cascade of two s- Yeah  in general  you don't - that's right you don't wanna othorg- orthogonalize if the things are noisy. Actually. Um  that was something that uh  Herve and I were talking about with um  the multi-band stuff  that if you're converting things to from uh  bands  groups of bands into cepstral coef- you know  local sort of local cepstral coefficients that it's not that great to do it if it's noisy. Mm-hmm. O_K. Yeah. Uh  So. so. So that - that's one reason maybe we could combine s- some - something to improve S_N_R a little bit  Yeah. first stage  and then do a something in the second stage which could take it further. What was your point about - about colored noise there? Oh  the colored noise uh - Yeah. the colored noise - the - the v- the signal subspace approach has - I mean  it - it actually depends on inverting the matrices. So it - it - ac- the covariance matrix of the noise. Mm-hmm. So if - if it is not positive definite  I mean it has a - it's - It doesn't behave very well if it is not positive definite ak- It works very well with white noise because we know for sure that it has a positive definite. So you should do spectral subtraction and then add noise. So the way they get around is like they do an inverse filtering  first of the colo- colored noise and then make the noise white  and then finally when you reconstruct the speech back  you do this filtering again. Yeah. Yeah. Yeah  right. I was only half kidding. I mean if you - sort of you do the s- spectral subtraction  Yeah. Yeah. Yeah. that also gets rid - and then you - then - then add a little bit l- noise - noise addition - I mean  that sort of what J_ - J_RASTA does  in a way. If you look at what J_RASTA doing essentially i- i- it's equivalent to sort of adding a little - adding a little noise  Yeah. Huh? Uh-huh. Uh-huh. in order to get rid of the effects of noise. So. Yeah. O_K. Uh  yeah. So there is this. And maybe we - well we find some people so that uh  agree to maybe work with us  and they have implementation of V_T_S techniques so it's um  Vector Taylor Series that are used to mmm  uh f- to model the transformation between clean cepstra and noisy cepstra. So. Well  if you take the standard model of channel plus noise  Mm-hmm. uh  it's - it's a nonlinear eh- uh  transformation in the cepstral domain. Yes. And uh  there is a way to approximate this using uh  first-order or second-order Taylor Series and it can be used for uh  getting rid of the noise and the channel effect. Who is doing this? Uh w- working in the cepstral domain? So there is one guy in Grenada  Yeah  in Grenada one of my friend. and another in uh  Lucent that I met at I_CASSP. uh  Who's the guy in Grenada? Uh  Jose Carlos Segura. I don't know him . This V_T_S has been proposed by C_M_U? Is it - is it the C_M_U? Yeah  yeah  O_K. From C_. Mm-hmm. Yeah  yeah  yeah. Originally the idea was from C_M_U. Mm-hmm. Yeah. Uh-huh. Well  it's again a different thing that could be tried. Um  Uh-huh. Mmm  yeah. Yeah  so at any rate  you're looking general  uh  standing back from it  looking at ways to combine one form or another of uh  noise removal  uh  with - with these other things we have  Mm-hmm. uh  looks like a worthy thing to - to do here. Uh  yeah. But  yeah. But for sure there's required to - that requires to re-check everything else  and re-optimize Oh yeah. the other things and  for sure the on-line normalization may be the L_D_A filter. Um  Well one of the - seems like one of the things to go through next week when Hari's here  cuz Hari'll have his own ideas I - too - or I guess not next week  week and a half  Uh-huh. uh  will be sort of go through these alternatives  what we've seen so far  and come up with some game plans. Um. You know. So  I mean one way would - he- Here are some alternate visions. I mean one would be  you look at a few things very quickly  you pick on something that looks like it's promising and then everybody works really hard on the same - different aspects of the same thing. Another thing would be to have t- to - to pick two pol- two plausible things  and - and you know  have t- sort of two working things for a while until we figure out what's better  and then  you know  uh  Mm-hmm. but  w- um  uh  he'll have some ideas on that too. The other thing is to  uh - Most of the speech enhancement techniques have reported results on small vocabulary tasks. But we - we going to address this Wall Street Journal in our next stage  which is also going to be a noisy task so s- very few people have reported something on using some continuous speech at all. So  there are some - I mean  I was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction doesn't seems to be the thing to do for large vocabulary tasks. And it's - Always people have shown improvement with Wiener filtering and maybe subspace approach over spectral subtraction everywhere. But if we - if we have to use simple spectral subtraction  we may have to do some optimization to make it So they're making - there - Somebody's generating Wall Street Journal with additive - artificially added noise or something? work @@ . Yeah  yeah. Sort of a - sort of like what they did with T_I-digits  and? Yeah  O_K. Yeah. Yeah. I m- I guess Guenter Hirsch is in charge of that. O_K. Guenter Hirsch and T_I. Maybe Roger - r- Roger  maybe in charge of. And then they're - they're uh  uh  generating H_T_K scripts to - Yeah. Yeah  I don't know. There are - they have - there is no - I don't know if they are converging on H_T_K or are using some Mississippi State  yeah. I'm not sure about that. Mis- Mississippi State maybe  yeah. Yeah  so that'll be a little - little task in itself. Um  well we've - Yeah. Yeah  it's true for the additive noise  y- artificially added noise we've always used small vocabulary too. But for n- there's been noisy speech this larv- large vocabulary that we've worked with in Broadcast News. So we- we did the Broadcast News evaluation and Mm-hmm. some of the focus conditions were noisy and - and - But we - but we didn't do spectral subtraction. We were doing our funny stuff  right? We were doing multi- multi- uh  multi-stream and - and so forth. It had additive n- Yeah. But it  you know  we di- stuff we did helped. I mean it  did something. So. O_K. Um  now we have this um  meeting data. You know  like the stuff we're recording right now  and - Yeah. Yeah. and uh  that we have uh  for the - uh  the quote-unquote noisy data there is just - noisy and reverberant actually. It's the far field mike. And uh  we have uh  the digits that we do at the end of these things. And that's what most o- again  most of our work has been done with that  with - with uh  connected digits. Uh-huh. Um  but uh  we have recognition now with some of the continuous speech  large vocabulary continuous speech  using Switchboard - uh  Switchboard recognizer  Yeah. O_K. uh  no training  from this  just - just plain using the Switchboard. Oh. You just take the Switchboard trained - ? Yeah  yeah. That's - that's what we're doing  yeah. Now there are some adaptation though  that - that uh  Andreas has been playing with  but we're hop- uh  actually uh  Dave and I were just talking earlier today about maybe at some point not that distant future  trying some of the techniques O_K. Yeah. That's cool. O_K. that we've talked about on  uh  some of the large vocabulary data. Um  I mean  I guess no one had done - yet done test one on the distant mike using uh  the S_R_I recognizer and  uh  I don't - not that I know of. Yeah  cuz everybody's scared. Yeah. You'll see a little smoke coming up from the - the C_P_U or something trying to - trying to do it  but That's right uh  yeah. But  you're right that - that - that's a real good point  that uh  we - we don't know yeah  uh  I mean  what if any of these ta- I guess that's why they're pushing that in the uh - in the evaluation. Yeah. Uh  But um  Good. O_K. Anything else going on? at you guys' end  or - ? I don't have good result  with the - inc- including the new parameters  I don't have good result. Are similar or a little bit worse. With what - what other new p- new parameter? You're talking about your voicing? Yeah. So maybe - You probably need to back up a bit seeing as how Sunil  yeah . Yeah. Mm-hmm. Yeah. I tried to include another new parameter to the traditional parameter  the coe- the cepstrum coefficient  that  like  the Uh-huh. auto-correlation  the R_zero Mm-hmm. and R_one over R_zero Mm-hmm. and another estimation of the var- the variance of the difference for - of the spec- si- uh  spectrum of the signal and - and the spectrum of time after filt- mel filter bank. I'm so sorry. I didn't get it. Nuh. Well. Anyway. The - First you have the sp- the spectrum of the signal  and you have the - Mm-hmm. on the other side you have the output of the mel filter bank. Mm-hmm. You can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal. Mmm. O_K. I do the difference - I found a difference at the variance of this different because  suppose O_K. Uh-huh. we - we think that if the variance is high  maybe you have n- uh  noise. Yeah. And if the variance is small  maybe you have uh  speech. Uh-huh. To - to To - The idea is to found another feature for discriminate between voice sound and unvoice sound. O_K. And we try to use this new feature - feature. And I did experiment - I need to change - to obtain this new feature I need to change the size - the window size - size. of the a- of the - analysis window size  to have more information. Yeah. Make it longer. Uh  sixty-two point five milliseconds I think. O_K. And I do - I did two type of experiment to include this feature directly with the - with the other feature and to train a neural network to select it voice-unvoice-silence - silence and to - to concat this new feature. But the result are Unvoiced. Well. n- with the neural network I have more or less the same result. As using just the cepstrum  or - ? Result. Yeah. Yeah. O_K. It's neve- e- e- sometime it's worse  sometime it's a little bit better  but not significantly. And - Uh  is it with T_I-digits  or with - ? No  I work with eh  Italian and Spanish basically. O_K. O_K. And if I don't y- use the neural network  and use directly the feature Uh-huh. the results are worse. But Doesn't help. I - I - I really wonder though. I mean we've had these discussions before  and - and one of the things that struck me was that - uh  about this line of thought that was Mm-hmm. particularly interesting to me was that we um - whenever you condense things  uh  in an irreversible way  um  you throw away some information. And  that's mostly viewed on as a good thing  in the way we use it  because we wanna suppress things that will cause variability for uh particular  uh  phonetic units. Um  but  you'll do throw something away. And so the question is  uh  can we figure out if there's something we've thrown away that we shouldn't have. And um. So  when they were looking at the difference between the filter bank and the F_F_T that was going into the filter bank  I was thinking ""oh  O_K  so they're picking on something they're looking on it to figure out noise  or voice - voiced property whatever."" So that - that's interesting. Maybe that helps to drive the - the thought process of coming up with the features. But for me sort of the interesting thing was  ""well  but is there just something in that difference which is useful? "" So another way of doing it  maybe  would be just to take the F_F_T uh  power spectrum  and feed it into a neural network  and then use it  you know  in combination  or alone  or - or whatever To know - Wi- with what targets? Voiced  unvoiced is like - Uh  no. Oh. Or anything. No the - just the same - same way we're using - I mean  the same way that we're using the filter bank. Phones. Oh  O_K. Mm-hmm. Exact way - the same way we're using the filter bank. I mean  the filter bank is good for all the reasons that we say it's good. But it's different. And  you know  maybe if it's used in combination  it will get at something that we're missing. Mm-hmm. And maybe  you know  using  orth- you know  K_L_T  or uh  um  adding probabilities  I mean  all th- all the different ways that we've been playing with  that we would let the - essentially let the neural network determine what is it that's useful  that we're missing here. Mm-hmm. Yeah  but there is so much variability in the power spectrum. Mm-hmm. Well  that's probably why y- i- it would be unlikely to work as well by itself  but it might help in combination. Mm-hmm. Mmm. But I - I - I have to tell you  I can't remember the conference  but  uh  I think it's about ten years ago  I remember going to one of the speech conferences and - and uh  I saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front-end or something  and a couple posters away it was somebody who compared one to uh  just putting in the F_F_T and the F_F_T did slightly better. Mm-hmm. So I mean the - i- i- It's true there's lots of variability  but again we have these wonderful statistical mechanisms for quantifying that a- that variability  and you know  doing something reasonable with it. So  um  Mm-hmm. uh  It- it's same  you know  argument that's gone both ways about uh  you know  we have these data driven filters  in L_D_A  and on the other hand  if it's data driven it means it's driven by things that have lots of variability  and that are necessarily - not necessarily gonna be the same in training and test  so  in some ways it's good to have data driven things  and in some ways it's bad to have data driven things. So  part of what we're discovering  is ways to combine things that are data driven than are not. Yeah  d- Yeah. Uh  so anyway  it's just a thought  that - that if we - if we had that - maybe it's just a baseline uh  which would show us ""well  what are we really getting out of the filters""  or maybe i- i- probably not by itself  but in combination  Mm-hmm. uh  you know  maybe there's something to be gained from it  and let the - But  you know  y- you've only worked with us for a short time  maybe in a year or two you w- you will actually come up with the right set of things to extract from this information. But  maybe the neural net and the H_M_Ms could figure it out quicker than you. So. It's just a thought. Maybe. Yeah  I can - I will try to do that. Yeah. What - one - one um p- one thing is like what - before we started using this V_A_D in this Aurora  the - th- what we did was like  I - I guess most of you know about this  adding this additional speech-silence bit to the cepstrum and training the H_M_M on that. Mm-hmm. That is just a binary feature and that seems to be improving a lot on the SpeechDat-Car where there is a lot of noise but not much on the T_I-digits. So  a- adding an additional feature to distin- to discriminate between speech and nonspeech was helping. Wait - I - I'm sorry? That's it. Yeah  we actually added an additional binary feature to the cepstrum  just the baseline. Yeah? You did some experiment. Yeah  yeah. Well  in - in the case of T_I-digits it didn't actually give us anything  because there wasn't any f- anything to discriminate between speech  and it was very short. Yeah. Hmm. But Italian was like Well - very - it was a huge improvement on Italian. Mm-hmm. But anyway the question is even more  is within speech  can we get some features? Are we drop- dropping information that can might be useful within speech  I mean. To - maybe to distinguish between voice sound and unvoiced sounds? O_K. Mm-hmm. Yeah  yeah. Yeah. And it's particularly more relevant now since we're gonna be given the endpoints. Yeah. Mm-hmm. So. Yeah  yeah. Uh. Mmm. So. Um. Mmm. There was a paper in I_CASSP - this I_CASSP - over the uh extracting some higher-order uh  information from the cepstral coefficients and I forgot the name. Some is- some harmonics I don't know  I can - I can pull that paper out from I_CASSP. It - Huh? Yeah. Talking cumulants or something? Cumulants or something. But - No. Uh  I don't know. I don't remember. It wa- it was taking the  um - It was about finding the higher-order moments of - Yeah. And I'm not sure about whether it is the higher-order moments  or - Yeah  cumulants  yeah. maybe higher-order cumulants and - Oh. Yeah. Or m- e- It was - it was - Yeah. I mean  he was showing up uh some - something on noisy speech  some improvement on the noisy speech. Yeah. Mm-hmm. Some small vocabulary tasks. Uh. So it was on P_L_P derived cepstral coefficients. Yeah  but again - You could argue that th- that's exactly what the neural network does. Mmm. So n- neural network uh  is in some sense equivalent to computing  you know  higher-order moments of what you - yeah. trying to f- to Moments  yeah. Yeah. So. I mean  it doesn't do it very specifically  and Mm-hmm. pretty - you know. But. Yep. Uh  anything on your end you want to talk about? Uh. Um  nothing I wanna really talk about. I can - I can just uh  um  share a little bit - Sunil hasn't - hasn't heard about uh  what I've been doing. Um  so  Yeah. um  I told you I was - I was - I was getting prepared to take this qualifier exam. So basically that's just  um  trying to propose um  uh  your next your - your following years of - of your P_H_D work  trying - trying to find a project to - to define and - and to work on. So  I've been  uh  looking into  um  doing something about r- uh  speech recognition using acoustic events. So  um  the idea is you have all these - these different events  for example voicing  nasality  R_coloring  you know burst or noise  uh  frication  that kinda stuff  um  building robust um  primary detectors for these acoustic events  and using the outputs of these robust detectors to do speech recognition. Um  and  um  these - these primary detectors  um  will be  uh  inspired by  you know  multi-band techniques  um  doing things  um  similar to Larry Saul's work on  uh  graphical models to - to detect these - these  uh  acoustic events. And  um  so I - I been - I been thinking about that and some of the issues that I've been running into are  um  exactly what - what kind of acoustic events I need  what - um  what acoustic events will provide a - a good enough coverage to - in order to do the later recognition steps. And  also  um  once I decide a set of acoustic events  um  h- how do I - how do I get labels? Training data for - for these acoustic events. And  then later on down the line  I can start playing with the - the models themselves  the - the primary detectors. Um  so  um  I kinda see - like  after - after building the primary detectors I see um  myself taking the outputs and feeding them in  sorta tandem style into - into a um  Gaussian mixtures H_M_M back-end  um  and doing recognition. Um. So  that's - that's just generally what I've been looking at. Um  Yeah. By - by the way  uh  the voiced-unvoiced version of that for instance could tie right in to what Carmen was looking at. So  Yeah. Mm-hmm. you know  um  if you - if a multi-band approach was helpful as - as I think it is  it seems to be helpful for determining voiced-unvoiced  that one might be another Mm-hmm. Yeah. thing. Mm-hmm. Yeah. Um  were - were you gonna say something? Oh. It looked - O_K  never mind. Um  yeah. And so  this - this past week um  I've been uh  looking a little bit into uh  TRAPS Mmm. um  and doing - doing TRAPS on - on these e- events too  just  um  seeing - seeing if that's possible. Uh  and um  other than that  uh  I was kicked out of I_house for living there for four years. Oh no. So you live in a cardboard box in the street now or  no? Yeah. Uh  well  s- s- som- something like that. In Albany  yeah. Yeah. Yeah. And uh. Yep. That's it. Suni- i- d'you v- did uh - did you find a place? Is that out of the way? Uh  no not yet. Uh  yesterday I called up a lady who ha- who will have a vacant room from May thirtieth and she said she's interviewing two more people. So. And she would get back to me on Monday. So that's - that's only thing I have and Diane has a few more houses. She's going to take some pictures and send me after I go back. O_K. So it's - that's - Oh. So you're not down here permanently yet? No. I'm going back to O_G_I today. Ah! Oh  O_K. Oh. O_K. And then  you're coming back uh - Uh  i- I mean  I - I p- I plan to be here on thirty-first. Thirty-first  O_K. Thirty-first. Yeah  well if there's a house available or place to - Yeah  I hope. Well  I mean i- i- if - if - They're available  and they'll be able to get you something  so worst comes to worst we'll put you up in a hotel for - for - for a while until you - Yeah. So  in that case  I'm going to be here on thirty-first definitely . O_K. You know  if you're in a desperate situation and you need a place to stay  you could stay with me for a while. I've got a spare bedroom right now. Oh. O_K. Thanks. That sure is nice of you. So  it may be he needs more than me. Oh r- oh. Oh no  no. My - my cardboard box is actually a nice spacious two bedroom apartment. So a two bedroom cardboard box. Th- that's great. Thanks Dave. yeah Yeah. Yeah. Yeah. Yeah. Um  Yeah. Do y- wanna say anything about - You - you actually been - Uh  last week you were doing this stuff with Pierre  you were - you were mentioning. Is that - that something worth talking about  or - ? Um  it's - Well  um  it - I don't think it directly relates. Um  well  so  I was helping a speech researcher named Pierre Divenyi and he's int- He wanted to um  look at um  how people respond to formant changes  I think. Um. So he - he created a lot of synthetic audio files of vowel-to-vowel transitions  and then he wanted a psycho-acoustic um  spectrum. And he wanted to look at um  how the energy is moving over time in that spectrum and compare that to the - to the listener tests. And  um. So  I gave him a P_L_P spectrum. And - to um - he - he t- wanted to track the peaks so he could look at how they're moving. So I took the um  P_L_P L_P_C coefficients and um  I found the roots. This was something that Stephane suggested. I found the roots of the um  L_P_C polynomial to  um  track the peaks in the  um  P_L_P L_P_C spectra. well there is aligned spectral pairs  is like the - the - Is that the aligned s- It's a r- root L_P_C  uh  of some sort. Oh  no. So you just - Mm-hmm. Yeah. instead of the log you took the root square  I mean cubic root or something. What di- w- I didn't get that. No  no. It's - it's - it's taking the - finding the roots of the L_P_C polynomial. Polynomial. Yeah. Is that the line spectral - So it's like line spectral pairs. Except I think what they call line spectral pairs they push it towards the unit circle  don't they  to sort of? Oh  it's like line sp- Yeah  yeah  yeah  yeah. But it - But uh  you know. But what we'd used to do w- when I did synthesis at National Semiconductor twenty years ago  the technique we were playing with initially was - was taking the L_P_C polynomial and - and uh  finding the roots. It wasn't P_L_P cuz Hynek hadn't invented it yet  but it was just L_P_C  and uh  we found the roots of the polynomial  And th- When you do that  sometimes they're f- they're what most people call formants  sometimes they're not. Mmm. So it's - it's - it's a little  uh - Formant tracking with it can be a little tricky cuz you get these funny values in - in real speech  but. Hmm. So you just - You typically just get a few roots? You know  two or three  something like that? Well you get these complex pairs. And it depends on the order that you're doing  but. Mm-hmm. Right. So  um  if - @@ Every root that's - Since it's a real signal  the L_P_C polynomial's gonna have real coefficients. So I think that means that every root that is not a real root Mm-hmm. is gonna be a c- complex pair  um  of a complex value and its conjugate. Um. So for each - And if you look at that on the unit circle  um  one of these - one of the members of the pair will be a positive frequency  one will be a negative frequency  I think. So I just - So  um  f- for the - I'm using an eighth-order polynomial and I'll get three or four of these pairs Yeah. which give me s- which gives me three or four peak positions. Hmm. This is from synthetic speech  or - ? It's - Right. Yeah. Yeah. So if it's from synthetic speech then maybe it'll be cleaner. I mean for real speech in real - then what you end up having is  like I say  funny little things that are - don't exactly fit your notion of formants How did - all that well. But - but mostly they are. Mostly they do. And - and what - I mean in - in what we were doing  But- Yeah. Mmm  I - which was not so much looking at things  it was O_K because it was just a question of quantization. Uh  we were just you know  storing - It was - We were doing  uh  stored speech  uh  quantization. But - but uh  in your case Mm-hmm. um  you know - Actually you have peaks that are not at the formant's positions  but But - there's some of that  yes. they are lower in energy and - Well they are much lower. If this is synthetic speech can't you just get the formants directly? I mean h- how is the speech created? It was created from a synthesizer  and um - Wasn't a formant synthesizer was it? I bet it - it might have - may have been but maybe he didn't have control over it or something? I - d- d- this - In - in fact w- we - we could get  um  formant frequencies out of the synthesizer  as well. And  um  w- one thing that the  um  L_P_C approach will hopefully give me in addition  um  is that I - I might be able to find the b- the bandwidths of these humps as well. Um  Stephane suggested looking at each complex pair as a - like a se- second-order I_I_R filter. Um  but I don't think Yeah. there's a g- a really good reason not to um  get the formant frequencies from the synthesizer instead. Except that you don't have the psycho-acoustic modeling in that. Yeah  so the actual - So you're not getting the actual formants per se. You're getting the - Again  you're getting sort of the  uh - Mm-hmm. You're getting something that is - is uh  af- strongly affected by the P_L_P model. And so it's more psycho-acoustic. So it's a little - It's - It's - It's sort of - sort of a different thing. Oh  I see. That's sort of the point. But - Yeah. i- Ordinarily  in a formant synthesizer  the bandwidths as well as the ban- uh  formant centers are - I mean  that's - Somewhere in the synthesizer that was put in  as - Yeah. Mm-hmm. as what you - But - but yeah  you view each complex pair as essentially a second-order section  which has  uh  band center and band width  and um  um - But. Yeah. O_ K. So  uh  yeah  you're going back today and then back in a week I guess  and. Yeah. Yeah. Great! Well  welcome. Thanks. I guess we should do digits quickly. Mmm. Oh yeah  digits. I almost forgot that. I almost forgot our daily digits. Digits. You wanna go ahead? Sure. Transcript L_ dash one four two one nine seven five three three six zero three zero zero eight one four one eight seven eight four five eight seven two five five four two three two one one eight seven th- three two one one zero eight four one six five zero five six five two five one nine two seven seven four seven zero eight four eight four eight four one seven three two nine six four one seven two Transcript L_ dash one four three eight nine seven four nine one six eight six two one nine four eight nine nine four eight eight six one one six one nine two five nine two six eight three nine eight four eight zero zero six zero seven six five one five two six two one seven eight seven five four two nine two five four nine eight seven four two seven eight three two nine seven two three two one six six seven five two six two Transcript L_ dash one forty four nine seven two one seven five six three two two six eight four three two zero two eight two zero nine one eight six four one zero four two five seven seven seven one eight five nine two seven six nine five eight five four nine seven zero six nine nine four five three eight seven two nine three four five seven two two nine O_ three four two two one zero eight two nine seven one seven Reading transcript L_ dash one four five five eight nine nine five one four nine zero zero seven one one four three two nine five seven three six eight seven seven one six zero three zero zero four six five seven seven nine seven three one two seven three two five nine one one seven one five zero three five one zero five zero two one seven five one six six five six two two eight four six eight nine Transcript L_ dash one four six nine one three three O_ O_ seven O_ six four four six three seven seven three one two four four six three six nine three zero two seven two eight two seven six eight seven five two two four nine seven six nine three eight nine six one nine one three four eight one two three four four two six one nine three three O_ three four five seven nine four two seven eight five six five two Transcript L_ dash one four O_. three five three one eight four zero one two four five six three three four O_ six three four five two five nine two two seven seven five seven one eight two seven five two eight four zero four seven eight six zero zero four nine nine eight zero seven five five one six zero zero seven one O_ one six zero five nine six O_ five two five eight four five seven seven one nine seven Transcript L_ dash one four one six two two seven six O_ O_ four two nine five three seven eight nine three six five four two five eight nine eight five one five one six one seven three zero eight eight nine four nine two four seven seven nine nine two three nine two nine zero zero five six zero nine zero one seven nine eight five O_ five O_ five nine two five four four four three nine five eight nine eight four three zero four two three two nine seven O_K. ","Minor technical issues such as format conversions for XML and JavaBayes and the full translation of the SmartKom generation module in English  are currently being resolved. The voice synthesiser will also be replaced by better technology. An important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net. Mental space interdependencies are based on relatively clean rules  since people seem to manage them easily. A step towards this goal is the construction formalism being put together. This module will eventually have to include ways to simulate questions  do emphasis and focus. The constructions could be built assuming either conventional or conversational implicature. At this stage both routes need to be examined. The formalism will also serve as a starting point for the definition of construal mechanisms. Similarly  issues like time plans and discourse stacks are dependent on how the ontology and discourse history are going to be structured and linked. One suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net. Finally  using type constraints in the construction analysis should work  as long as they are complex enough not to generate too many parses. It is necessary to ask the JavaBayes programmer whether he already has XML conversion programs. For the SmartKom generation module  all the syntax-to-prosody rules are going to be re-written for English. Additionally  OGI can offer a range of synthesiser voices to choose from. The focus of the next meeting  whose time was rescheduled  will be the discussion of the revised construction formalism. The presentation will unify the existing ideas and help identify the areas in need of further work  such as how it can deal with time and tense use and how they affect inferences in belief-nets. The ambiguity in a ""where is X?"" construction can be coded in the formalism as a semantic feature or pushed forward to the belief-net where pragmatic features will disambiguate it: in terms of system design  both options need to be investigated at this stage. As the translation of the german SmartKom into English moves on  the generation rules may prove difficult to tackle for someone without experience in functional programming  as they are written in LISP. As far as the construction analysis is concerned  the two problems that will need to be solved are to identify the couplings between constructions in different mental spaces and to define how inferences will work in the belief-net from a technical point of view. Additionally  in the example ""Where is X?"" construction  the ambiguity (Location or Path) could be coded either in the semantics of the construction or as if determined by context. The former could mean creating a different construction for every slight pragmatic variation. On the other hand  some of the belief-net probabilities could be instantiated in the lexicon. Specifying which approach to take when linking the ontology and the discourse history has also proven not to be straightforward. Finally  it is still undecided where construal comes in  which would help delimit the constructions as well. Several technical matters are being resolved: a conversion program is being written for data to be translated between XML and the Java Embedded-Bayes notation; the language generation templates are now available for the english version of the SmartKom system; SmartKom now works on three different machines at ICSI. On the other hand  future collaboration on belief-nets has already been agreed with another research group. The construction analysis and formalism are also progressing. Several issues that have been dealt with were mentioned during the meeting: indefinite pronouns and wh-questions  noun-phrase structure  etc. This analysis is being done with the help of a linguist  who often provides different perspectives to methods and terminology. "
"O_K. So  uh You can fill those out  uh after  actually  so So  I got  uh these results from  uh  Stephane. Also  um  I think that  uh um we might hear later today  about other results. I think s- that  uh  there were some other very good results that we're gonna wanna compare to. But  r- our results from other - other places  yeah. I- I'm sorry? I didn't- Um  I got this from you and then I sent a note to Sunil about the - cuz he has been running some other systems other than the - the ICSI O_G_I one. Yeah. Mm-hmm. Oh yeah. So um  I wan- wanna - wanna see what that is. But  uh  you know  so we'll see what it is comparatively later. But it looks like  um M- yeah. You know most of the time  even - I mean even though it's true that the overall number for Danish - we didn't improve it If you look at it individually  what it really says is that there's  um  uh Looks like out of the six cases  between the different kinds of  uh  matching conditions out of the six cases  there's basically  um  a couple where it stays about the same  uh  three where it gets better  and one where it gets worse. Yeah. Uh  go ahead. Y- Actually  uh  um  for the Danish  there's still some kind of mystery because  um  um  when we use the straight features  we are not able to get these nice number with the ICSI O_G_I one  I mean. We don't have this ninety-three seventy-eight  we have eight- yeah. Eighty-nine forty-four. Uh  so  uh  that's probably something wrong with the features that we get from O_G_I. Uh  and Sunil is working on - on trying to - to check everything. Oh  and - and we have a little time on that - and - actually so Hmm? We have a little bit of time on that  actually. Yeah. We have a day or so  so When - when - when do you folks leave? Uh  Sunday. Sunday? So So  uh Yeah  until Saturday midnight  or something  we have W- we - we have time  yeah. Well  that would be good. That'd be good. Yeah. Yeah. Uh  and  you know  i- u- when- whenever anybody figures it out they should also  for sure  email Hynek because Hynek will be over there telling people what we did  so he should know. Mmm. Good  O_K. Yeah. So  um So  we'll - we'll hold off on that a little bit. I mean  even with these results as they are  it's - it's - it's really not that bad. But - but  uh  um And it looks like the overall result as they are now  even without  you know  any - any bugs being fixed is that  uh  on the - the other tasks  we had this average of  uh  forty- uh - nine percent  or so  improvement. And here we have somewhat better than that than the Danish  and somewhat worse than that on the German  but I mean  it sounds like  uh  one way or another  the methods that we're doing can reduce the error rate from - from mel cepstrum down by  you know a fourth of them to  uh  a half of them. Somewhere in there  depending on the exact case. So So that's good. I mean  I think that  uh  one of the things that Hynek was talking about was understanding what was in the other really good proposals and - and trying to see if what should ultimately be proposed is some  uh  combination of things. Um  if  uh - Cuz there's things that they are doing there that we certainly are not doing. And there's things that we're doing that they're not doing. And - and they all seem like good things. Yeah. Mmm  yeah. So So How much - how much better was the best system than ours? Well  we don't know yet. Mmm. Uh  I mean  first place  there's still this thing to - to work out  and second place - second thing is that the only results that we have so far from before were really development set results. Oh  O_K. So  I think in this community that's of interest. It's not like everything is being pinned on the evaluation set. But  um  for the development set  our best result was a little bit short of fifty percent. And the best result of any system was about fifty-four  where these numbers are the  uh  relative  uh  reduction in  uh  word error rate. Oh  O_K. And  um  the other systems were  uh  somewhat lower than that. There was actually - there was much less of a huge range than there was in Aurora one. In Aurora one there were - there were systems that ba- basically didn't improve things. Hmm. And here the - the worst system still reduced the error rate by thirty-three percent  or something  in development set. Oh  wow. So - so  you know  sort of everybody is doing things between  well  roughly a third of the errors  and half the errors being eliminated  uh  and varying on different test sets and so forth. Mm-hmm. So I think Um It's probably a good time to look at what's really going on and seeing if there's a - there's a way to combine the best ideas while at the same time not blowing up the amount of  uh  resources used  cuz that's - that's critical for this - this test. Do we know anything about - who - who's was it that had the lowest on the dev set? Um  uh  the  uh  the- there were two systems that were put forth by a combination of - of  uh  French Telecom and Alcatel. And  um they - they differed in some respects  but they e- em- one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System  uh  which is the biggest difference  I think. But - but there're - there're - there're some other differences  too. Uh  and - and  uh  they both did very well  you know? Uh-huh. So  um  my impression is they also did very well on - on the - the  uh  evaluation set  but  um  I - I- we haven't seen - you've- you haven't seen any final results for that yeah. And they used - the main thing that - that they used was spectral subtraction? Or There is a couple pieces to it. There's a spectral subtraction style piece - it was basically  you know  Wiener filtering. And then - then there was some p- some modification of the cepstral parameters  where they - Yeah  actually  something that's close to cepstral mean subtraction. But  uh  the way the mean is adapted - um  it's signal dependent. I'm - I'm  uh So  basically  the mean is adapted during speech and not during silence. Yeah. But it's very close to - to cepstral mean subtraction. But some people have done exactly that sort of thing  of - of - and the - I mean it's not - To - to look in speech only  to try to m- to measure these things during speech  that's p- that's not that uncommon. Yeah  yeah. But i- it- it - so it looks like they did some - some  uh  reasonable things  uh  and they're not things that we did  precisely. We did unreasonable things  which - because we like to try strange things  and - and  uh  and our things worked too. Hmm. And so  um  uh  it's possible that some combination of these different things that were done would be the best thing to do. But the only caveat to that is that everybody's being real conscious of how much memory and how much C_P_U they're using because these  Mm-hmm. uh  standards are supposed to go on cell phones with m- moderate resources in both respects. Did anybody  uh  do anything with the models as a - an experiment? Or Uh  they didn't report it  if they did. N- nobody reported it? Yeah. I think everybody was focused elsewhere. Um  now  one of the things that's nice about what we did is  we do have a - a  uh - a filtering  which leads to a - a  uh - a reduction in the bandwidth in the modulation spectrum  which allows us to downsample. So  uh  as a result of that we have a reduced  um  transmission rate for the bits. Mm-hmm. That was misreported the first time out. It - it said the same amount because for convenience sake in the particular way that this is being tested  uh  they were repeating the packets. So it was - they were s- they - they had twenty-four hundred bits per second  but they were literally creating forty-eight hundred bits per second  um  even though y- it was just repeated. Oh. Mm-hmm. Right. So  uh  in practice So you could've had a repeat count in there or something. Well  n- I mean  this was just a ph- phoney thing just to - to fit into the - the software that was testing the errors - channel errors and so on. Oh. So - so in reality  if you put this - this system in- into  uh  the field  it would be twenty-four hundred bits per second  not forty-eight hundred. Oh. So  um  so that's a nice feature of what - what we did. Um  but  um  well  we still have to see how it all comes out. Hmm. Um  and then there's the whole standards process  which is another thing altogether. When is the development set - I mean  the  uh  uh  test set results due? Like the day before you leave or something? Uh  probably the day after they leave  but we'll have to - we'll have to stop it the day before we leave. Yeah  yeah. So Huh. I think tha- I think the - the meeting is on the thirteenth or something. Yeah  this Tuesday  yeah. And  uh  they  uh Right. And the - the  uh  results are due like the day before the meeting or something. So Yeah  probably  well I th- I think - I- I think they are  yeah. Yeah  well So um  since we have a bit farther to travel than some of the others  uh  we'll have to get done a little quicker. But  um  I mean  it's just tracing down these bugs. I mean  just exactly this sort of thing of  you know  why - why these features seem to be behaving differently  uh  in California than in Oregon. Hmm. Might have something to do with electricity shortage. Uh  we didn't - we didn't have enough electrons here and Uh  but  um Uh  I think  you know  the main reason for having - I mean  it only takes w- to run the - the two test sets in - just in computer time is just a day or so  right? So yeah. Yeah  it's very short interval. So  I think the who- the whole reason for having as long as we have  which was like a week and a half  is - is because of bugs like that. Hmm. So Huh So  we're gonna end up with these same kind of sheets that have the the percentages and so on just for the - Yeah  so there are two more columns in the sheets  two. Oh  I guess it's the same sheets  yeah  yeah - just with the missing columns filled in. Yeah  it's the same sheets  yeah. Yeah. Yeah. Well  that'll be good. So  I'll dis- I'll disregard these numbers. That's - that's - that's good. So  Hynek will try to push for trying to combine  uh  different things? Or Uh  well that's um yeah Hmm? I mean  I think the question is ""Is there - is there some advantage?"" I mean  you could just take the best system and say that's the standard. But the thing is that if different systems are getting at good things  um  a- again within the constraint of the resources  if there's something simple that you can do Now for instance  uh  it's  I think  very reasonable to have a standard for the terminal's side and then for the server's side say  ""Here's a number of things that could be done."" So  um  everything that we did could probably just be added on to what Alcatel did  and i- it'd probably work pretty well with them  too. So  um  uh  that's one - one aspect of it. And then on the terminal's side  I don't know how much  um  memory and - and C_P_U it takes  but it seems like the filtering Uh  I mean  the V_A_D stuff they both had  right? And  um  so - and they both had some kind of on-line normalization  right? Uh  yeah. Of sorts  yeah? So - so  it seems like the main different there is the - is the  uh  filtering. And the filtering - I think if you can - shouldn't take a lot of memory to do that Uh  and I also wouldn't think the C_P_U  uh  would be much either for that part. So  if you can - if you can add those in um then  uh  you can cut the data rate in half. Yeah. So it seems like the right thing to do is to - on the - on the terminal's side  take what they did  if it - if it does seem to generalize well to German and Danish  uh  take what they did add in a filter  and add in some stuff on the server's side and - and - and that's probably a reasonable standard. Um They are working on this already? Because - yeah  Su- Sunil told me that he was trying already to put some kind of  uh  filtering in the France Telecom. Uh Yeah  so that's - that's - that's what That would be ideal - would be is that they could  you know  they could actually show that  in fact  a combination of some sort  uh  would work even better than what - what any of the systems had. And  um  then it would - it would  uh be something to - to discuss in the meeting. But  uh  not clear what will go on. Um  I mean  on the one hand  um  sometimes people are just anxious to get a standard out there. I mean  you can always have another standard after that  but this process has gone on for a while on - already and - and people might just wanna pick something and say  ""O_K  this is it."" And then  that's a standard. Uh  standards are always optional. It's just that  uh  if you disobey them  then you risk not being able to sell your product  or Uh um And people often work on new standards while an old standard is in place and so on. So it's not final even if they declared a standard. The other hand  they might just say they just don't know enough yet to - to declare a standard. So you - you - you will be - you will become experts on this and know more - far more than me about the tha- this particular standards process once you - you go to this meeting. So  be interested in hearing. So  uh  I'd be  uh  interested in hearing  uh  your thoughts now I mean you're almost done. I mean  you're done in the sense that  um  you may be able to get some new features from Sunil  and we'll re-run it. Uh  but other than that  you're - you're basically done  right? So  uh  I'm interested in hearing - hearing your thoughts about where you think we should go from this. Yeah. I mean  we tried a lot of things in a hurry  and  uh  if we can back off from this now and sort of take our time with something  and not have doing things quickly be quite so much the constraint  what - what you think would be the best thing to do. Uh  well Hmm Well  first  uh  to really have a look at - at the speech from these databases because  well  we tried several thing  but we did not really look at what- what's happening  and where is the noise  and O_K. Eh It's a novel idea. Look at the data. O_K. Yeah. Or more generally  I guess  what - what is causing the degradation. Yeah  yeah. Actually  there is one thing that - well Um  generally we - we think that most of the errors are within phoneme classes  and so I think it could be interesting to - to see if it - I don't think it's still true when we add noise  and so we have - I - I guess the confusion ma- the confusion matrices are very different when - when we have noise  and when it's clean speech. And probably  there is much more between classes errors for noisy speech. Mm-hmm. And so  um Yeah  so perhaps we could have a - a large gain  eh  just by looking at improving the  uh  recognition  not of phonemes  but of phoneme classes  simply. Mm-hmm. And which is a s- a s- a simpler problem  perhaps  but - which is perhaps important for noisy speech. The other thing that strikes me  just looking at these numbers is  just taking the best cases  I mean  some of these  of course  even with all of our - our wonderful processing  still are horrible kinds of numbers. But just take the best case  the well-matched uh  German case after - er well-matched Danish after we - the kind of numbers we're getting are about eight or nine uh p- percent error per digit. Mm-hmm. Mm-hmm. Yeah. This is obviously not usable  right? No. I mean  if you have ten digits for a phone number I mean  every now and then you'll get it right. Sure. I mean  it's - it's  uh  um So  I mean  the other thing is that  uh - And - and - a- and - and also  um part of what's nice about this is that this is  uh  um a realistic - almost realistic database. I mean  it's still not people who are really trying to accomplish something  but - but  uh  within the artificial setup  it isn't noise artificially added  you know  simulated  uh  additive noise. Mm-hmm. It's real noise condition. And  um  the - the training - the training  I guess  is always done on the close talking No  actually - actually the well-matched condition is still quite di- still quite difficult. No? I mean  it's - they have all these data from the close mike and from the distant mike  from different driving condition  open window  closed window  and they take all of this and they take seventy percent  I think  for training and thirty percent for testing. Yeah. Mm-hmm. So  training is done on different conditions and different microphones  and testing also is done on different microphone and conditions. So  probably if we only take the close microphones  I guess the results should be much much better than this. I see. Mmm. Oh  O_K  that explains it partially. Uh Wha- what about i- in - so the - the - go ahead. Yeah  so - there is this  the mismatched is  um the same kind of thing  but the driving conditions  I mean the speed and the kind of road  is different for training and testing  is that right? Yeah. And the last condition is close microphone for training and distant for testing. Yeah. Uh  O_K  so So - s- so - I see. So  yeah  so the high - so the - right - so the highly mismatched case is in some sense a good model for what we've been  you know  typically talking about when we talk about additive noise in - And so - and i- i- k- it does correspond to a realistic situation in the sense that  um  people might really be trying to  uh  call out telephone numbers or some- or something like that  in - in their cars and they're trying to connect to something. Yeah. Mmm. Um Actually  yeah  it's very close to clean speech training because  well  because the close microphone and noisy speech testing  yeah. Yeah. Yeah. Yeah. Mmm. And the well-matched condition is what you might imagine that you might be able to approach  if you know that this is the application. You're gonna record a bunch on people in cars and so forth  and do these training. And then  uh  when y- you sell it to somebody  they will be a different person with a different car  and so on. So it's - this is a- an optim- somewhat optimistic view on it  uh  so  you know  the real thing is somewhere in between the two. Uh  uh  but Yeah. But the - I mean  the th- th- it doesn't work. Even the optimistic one is Yeah  right. It - Right  it doesn't work. So  in a way  that's  you know  that's sort of the dominant thing is that even  say on the development set stuff that we saw  the  uh  the numbers that  uh  that Alcatel was getting when choosing out the best single numbers  it was just - you know  it wasn't good enough for - for a - a - for a real system. Mmm. Mm-hmm. You - you - you  um So  uh  we still have stuff to do. Yeah. Uh  and  uh I don't know So  looking at the data  where  you know - what's the - what's - what's th- what's characteristic i- e- yeah  I think that's - that's a good thing. Does a- any- you have any thoughts about what else y- you're thinking that you didn't get to that you would like to do if you had more time? Uh Oh  f- a lot of thing. Because we trying a lot of s- thing  and we doesn't work  we remove these. Maybe we trying again with the articulatory feature. I don't know exactly because we tried - we - some - one experiment that doesn't work. Um  forgot it  something Mm-hmm. I don't know exactly because  tsk maybe do better some step the general  eh  diagram. Mm-hmm. I don't know exactly s- to think what we can improve. Yeah  cuz a lot of time- it's true  there were a lot of times when we've tried something and it didn't work right away  even though we had an intuition that there should be something there. And so then we would just stop it. Um And  uh  one of the things - I don't remember the details on  but I remember at some point  when you were working with a second stream  and you tried a low-pass filtering to cepstrum  in some case you got - M_S_G Well  but it was an M_S_G-like thing  but it wasn't M_S_G  right? Yeah. Uh  you - y- I think in some case you got some little improvement  but it was  you know  sort of a small improvement  and it was a - a big added complication  so you dropped it. But  um  that was just sort of one try  right? You just took one filter  threw it there  right? Yeah  yeah. And it seems to me that  um  if that is an important idea  which  you know  might be  that one could work at it for a while  as you're saying. Hmm. And  uh Uh  and you had  you know  you had the multi-band things also  and  you know  there was issue of that. Yeah  mmm. Mm-hmm. Um  Barry's going to be  uh  continuing working on multi-band things as well. We were just talking about  um  some  uh  some work that we're interested in. Kind of inspired by the stuff by Larry Saul with the  uh uh  learning articulatory feature in - I think  in the case of his paper - with sonorance based on  uh  multi-band information where you have a - a combination of gradient learning an- and  uh  E_M. Mm-hmm. Um  and Um  so  I think that  you know  this is a  uh - this is a neat data set. Um  and then  uh  as we mentioned before  we also have the - the new  uh  digit set coming up from recordings in this room. So  there's a lot of things to work with. Um and  uh what I like about it  in a way  is that  uh  the results are still so terrible. Uh Uh I mean  they're much better than they were  you know. We're talking about thirty to sixty percent  uh  error rate reduction. That's - that's really great stuff to - to do that in relatively short time. But even after that it's still  you know  so poor that - that  uh  no one could really use it. So  um I think that's great that - because - and y- also because again  it's not something - sometimes we've gotten terrible results by taking some data  and artificially  you know  convolving it with some room response  or something - we take a very - Uh  at one point  uh  Brian and I went downstairs into the - the basement where it was - it was in a hallway where it was very reverberant and we - we made some recordings there. And then we - we  uh - uh  made a simulation of the - of the room acoustics there and - and applied it to other things  and uh Mm-hmm. But it was all pretty artificial  and - and  you know  how often would you really try to have your most crucial conversations in this very reverberant hallway? Um So  uh This is what's nice about the Aurora data and the data here  is that - is that it's sort of a realistic room situation uh  acoustics - acoustic situation  both terms in noise and reflections  and so on and n- n- And  uh  uh  with something that's still relatively realistic  it's still very very hard to do very well. So Yeah. Yeah  so d- well Actually  this is - tha- that's why we - well  it's a different kind of data. We're not - we're not used to work with this kind of data. Yeah. That's why we should have a loo- more closer look at what's going on. Mm-hmm. Um Yeah. So this would be the first thing  and then  of course  try to - well  kind of debug what was wrong  eh  when we do Aurora test on the M_S_G particularly  and on the multi-band. Yeah. Yeah. Yeah. Uh Yeah. Yeah. No  I - I think there's lots of - lots of good things to do with this. So Um So let's - I guess You were gonna say something else? Oh  O_K. What do you think? About Anything About other experiments? Uh  now  I'm interested in  um  uh looking at the experiments where you use  um uh  data from multiple languages to train the neural net. And I don't know how far  or if you guys even had a chance to try that  but that would be some- it'd be interesting to me. Yeah  but S- b- Again  it's the kind of - of thing that  uh  we were thin- thinking - thinking that it would work  but it didn't work. And  eh  so there is kind of - of not a bug  but something wrong in what we are doing  perhaps. Yeah. Right. Right. Right. Uh  something wrong  perhaps in the - just in the - the fact that the labels are - well Mm-hmm. What worked best is the hand-labeled data. Mm-hmm. Um Uh  so  yeah. I don't know if we can get some hand-labeled data from other languages. Yeah. It's not so easy to find. Right. But that would be something interesting t- to - to see. Yeah  yeah. Yeah. Also  uh  I mean  there was just the whole notion of having multiple nets that were trained on different data. So one form of different data was - is from different languages  but the other Well  i- in fact  uh  m- in those experiments it wasn't so much combining multiple nets  it was a single net that had different Yeah. So  first thing is would it be better if they were multiple nets  for some reason? Second thing is  never mind the different languages  just having acoustic conditions rather than training them all up in one  would it be helpful to have different ones? So  um That was a question that was kind of raised by Mike Shire's thesis  and on - in that case in terms of reverberation. Right? That - that sometimes it might be better to do that. But  um  I don't think we know for sure. So  um Right. So  next week  we  uh  won't meet because you'll be in Europe. Whe- when are you two getting back? Um  I'm You on Friday or S- on Saturday or ? Sunday because it's - it's less expensive  the price - the price the ticket. S- oh yeah  Sunday  yeah. Yeah  that's right. Ah. You've gotta S- have a Saturday overnight  right? I'll be back on Tuesday. Tuesday. Where - where's the meeting? Um Uh  Amsterdam  I think  yeah? Yeah. Yeah  Amsterdam. Uh-huh. Yeah  yeah. Yep. Um So  we'll skip next week  and we'll meet two weeks from now. And  uh  I guess the main topic will be  uh  you telling us what happened. Yeah. Yeah. Uh  so Yeah  well  if we don't have an- anything else to discuss  we should  uh  turn off the machine and then say the real nasty things. Should we do digits first? Oh yeah  digits! Oh  yeah  digits. Yeah. Yeah. Good point. Yeah  good thinking. Why don't you go ahead. O_K. Transcript three seven nine one three eight one zero nine zero four zero two zero zero seven one one seven O_ four two four O_ nine two two one three six one three five O_ nine four nine five six zero six zero seven eight five six eight zero nine seven O_ five O_ five zero seven zero one zero zero nine one two three O_ seven nine eight eight O_ five seven six three nine seven seven one eight eight nine Transcript three seven five one dash three seven seven zero. eight five five seven three zero six nine six six O_ O_ zero one two O_ four two five five six six six seven eight two eight nine O_ O_ one one two three four three eight six four four eight three five six seven zero four three zero zero seven Transcript three six seven one dash three six nine zero. four five zero zero four two seven two O_ three eight five three O_ five one O_ nine seven one eight four seven six O_ zero nine four five one O_ three two four one one five five four nine nine two six six three seven seven nine eight eight zero zero two eight five nine O_ seven O_ O_ O_ eight one two two eight six eight three five three seven one zero nine four five Transcript six nine- Uh  yeah  I'm sorry. Transcript three six nine one three seven one O_. five six seven O_ six nine four five O_ one five zero three two one seven two zero two six two four three O_ four four O_ five five four six one seven O_ O_ seven five eight six two eight three eight eight four nine eight O_ O_ zero zero one nine eight one zero zero three two eight zero nine four two five four five Transcript number three seven seven one dash three seven nine O_. nine one O_ eight O_ four six nine O_ zero seven one six O_ one two three four zero zero zero six four seven six five nine nine zero eight five seven six seven two eight five six eight three six seven four one three nine eight nine O_ zero O_ @@ I'm sorry. one O_ three one four O_ four seven five seven three six nine six five seven eight O_K. ",ICSI's Meeting Recorder Group at Berkeley met mainly to discuss work on their main project  the Aurora task  but also talked about the work of one of their student members. Some members of the group met recently with research partners to settle on the current state of their software  and decide on the future work they would investigate  and these decisions were relayed to the rest of the group. Of the three areas for the future  they touched mostly upon the use of a second  parallel  data stream. The group also discussed a new part to the evaluation  the use of a chunk of the Wall Street Journal. Speaker me006 is working on data clustering  and discussion of related issues led to more general acoustic matters. After the meeting  mn052 volunteered to get the second data stream up and running in the current software. Since he has been asked to assist in a particular aspect of the work  me018 has to contact the relevant persons in order to be added to the according mailing list. There is a new system coming from OGI for dealing with the Wall Street Journal data  and me013 wanted everyone to pay attention to areas where the groups might get hurt because of their features. The group's code has been updated  and in it's frozen state  runs at the second best level in the project. The CVS allowing access to the code is up and running  but now one at OGI is actually working on it yet. Speaker me006 has been reading literature on data clustering  with particular attention to a previous work  and is contemplating how to generalise it. 
"O_K  we're recording. It's recording. Oh. Wait a minute. Wait a minute. Gotta turn this on. Yeah. Oh boy  I got the harness. @@ Uh-oh. Um. Hmm. One. O_K. Boy  this - these things sure are weird. O_K. Yeah. Channel. What channel am I on? Oh  channel two. Make sure to turn your microphone on. There's a battery. Channel. There we go. O_K. Your channel number's already on this blank sheet. So you just - If you can - Yeah. Channel five? Channel five. I'm on channel five. Channel whatever. Camera one  camera two. What am I? Little low? Channel four? Channel five. This number four? O_K. Channel five. O_K. The gai- the gain's up at it - what it usually is  but if you think it's - Is it? Yeah. It's sort of a default. But I can set it higher if you like. Oh. Maybe it should be a little higher. Yeah? It's not showing much. Test  test  test  test  test  test  test  test  test  test. O_K  that - that seems better? Yeah? O_K  good. Ah  that's good  that's good. Yeah. Can't get it on ? That's good  that's good. O_K. Ahh. Mmm. So I - I had a question for Adam. Have we started already? Well  we started recording  but - Yeah. Yeah. Is Jane around or - ? I saw her earlier. Uh. She can just walk in  I guess  or - I think - Yeah. She'll probably come up. Right. Since we're starting late I figured we'd better just start. Yeah. Great idea. I was gonna ask Adam to  uh  say if he thought anymore about the demo stuff because it occurred to me that this is late May and the DARPA meeting is in mid July. Uh  but I don't remember w- what we - I know that we were gonna do something with the transcriber interface is one thing  but I thought there was a second thing. Anybody remember? Well  we were gonna do a mock-up  like  question answering or something  I thought  that was totally separate from the interface. Do you remember? Remember  like  Mm-hmm. asking questions and retrieving  but in a pre-stored fashion. Right. That was the thing we talked about  I think  before the transcriber - Come on in. Yeah. Alright. So anyway  you have to sort out that out and get somebody going on it cuz we're - got a - got a month left basically. So. You like these. Right? O_K  good. O_K. Um O_K. So  what are we g- else we got? You got - you just wrote a bunch of stuff. No. That was all  um  previously here. Oh. I was writing the digits and then I realized I could xerox them  Oh  oh. because I didn't want people to turn their heads from these microphones. So. Oh. We all  by the way  have the same digit form  for the record. So. That's cool. Yeah. So  the choice is  uh  which - which do we want more  the - the - the comparison  uh  of everybody saying them at the same time or the comparison of people saying the same digits at different times that - ? It's just cuz I didn't have any more digit sheets. I know that. So. But  you know  which opportunity should we exploit? Yeah. Unison. I mean  it - Actually it might be good to Unison. have them separately and have the same exact strings. I mean  we could use them for normalizing or something  but it of course goes more quickly doing them in unison. I don't know. I guess we'll see i- I guess it's dependent on See how long we go. how long we go and how good the snack is out there. Yeah. Hmm. Get some advance intelligence. But anyway  they won't be identical as somebody is saying zero in some - sometimes  you know  saying O_  and so  it's not i- not identical. Yeah. Right. Right. Yeah. We'd have to train. We'd be like a chorus. O_K. Yeah. We'd have to get s- get some experience. Greek chorus. Yeah. Yes. Yeah. Really boring chorus. Um. Do we have an agenda? Adam usually tries to put those together  but he's ill. So. I've got a couple of things to talk about. Yeah. Uh ju- what - what might those be? Uh  I_B_M stuff and  um  just getting uh  meeting information organized. Meeting info organized. O_K. Um. Are you implying that it's currently disorganized? In my mind. Is there stuff that's happened about  um  uh  the S_R_I recognizer et cetera  tho- those things that were happening before with - ? Y- y- you guys were doing a bunch of experiments with different front-ends and then with - Well. Is - is that still sort of where it was  uh  the other day? We're improving. We're improving. Yeah. Now the - the - You saw the note that the P_L_P now is getting basically the same as the M_F_C_C. Right? Right. Right. Yeah. Actually it looks like it's getting better. Oh. So. But - but it's not - Just with - with age  kind of. With age. Yeah. Yeah. Yeah. But  uh  that's not d- directly related to me. Doesn't mean we can't talk about it. Um  it seems - It looks l- I haven't - The - It's - The experiment is still not complete  but  um  it looks like the vocal tract length normalization is working beautifully  actually  w- using the warp factors that we computed for the S_R_I system and just applying them to the ICSI front-end. Mm-hmm. That's pretty funny. O_K. Yeah. So you just need to copy over to this one. Just had to take the reciprocal of the number because O_K. @@ they have different meanings in the two systems. Ah! Yeah. Well  that's always good to do. O_K. Yeah. O_K. Uh - But one issue actually that just came up in discussion with Liz and - and Don Yeah. was  um  as far as meeting recognition is concerned  um  we would really like to  uh  move  uh  to  uh  doing the recognition on automatic segmentations. Because in all our previous experiments  we had the - uh  you know  we were essentially cheating by having the  um  you know  the h- the hand-segmentations as the basis of the recognition. Mm-hmm. And so now with Thilo's segmenter working so well  I think we should consider Mmm. So. Come on. doing a - Yeah. We - But - Y- think - you think we should increase the error rate. Good. uh  doing - Anyway. Yeah. Yeah. Yeah. Yeah. Yeah. That- that's what I wanted to do anyway  so we should just Yeah. Yeah. Yeah. And even - get together and - The good thing is that since you  um  have high recall  even if you have low precision cuz you're over-generating  that's good because we could train Yeah. Right. noise models in the recognizer for these kinds of  Yeah. uh  transients and things that come from the microphones  but I know that if we run recognition unconstrained on a whole waveform  we do very poorly because we're - we're getting insertions in places what - that you may well be cutting out. So we do need some kind of pre-segmentation. Well - Yeah. Mm-hmm. We should - we should consider doing some extra things  like  um  you know  retraining or adapting the - Mmm. the models for background noise to the - to this environment  for instance. Yeah. Yeah. And  yeah  using Thilo's  So. you know  posteriors or some kind of - or - right now they're - they're discrete  yes or no for a speaker  Yeah. to consider those particular speaker background models. So. There's lots of ins- interesting things that could be done. Right. Yeah. Yeah. We should do that. So. Good. So  uh  why don't we  uh  do the I_B_M stuff? You had some thing about that? Yeah. So  um  talked with Brian and gave him the alternatives to the single beep at the end of each utterance that we had Right. generated before. And so - The  uh  Chuck chunks. Yeah. The Chuck chunks. Right. Hmm. And so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu- a number  a digit  and then a beep  Yeah. Yeah. uh  at the beginning of each one and that would help keep them from getting lost. And  um  so Adam wrote a little script to generate those style  uh  beeps and so we're - Where'd you get the digits from? I came up here and just recorded the numbers one through ten. They sound really good. So. That's a great idea. Does it sound O_K? Yeah. So  um - Yeah. We just used those. And do you splice them into the waveform? Or - ? Yeah. He - then he d- I recorded - Actually  I recorded one through ten three times at three different speeds and then he picked. Right. Mm-hmm. He liked the fastest one  so he just cut those out and spliced them in between  uh  two beeps. It will be funny uh - It sounds like a radio announcer's voice. Really. Does it? Yeah  yeah. It will be funny when you're really reading digits  and then there are the chunks with - with your digits in? Yeah. With my - Oh  right. Oh that's right. Yeah. Now actually  That'll throw them  huh? we're - Are we handling - ? Uh  maybe we should have you record A_  B_  C_ for those or something. Yeah. Yeah. Huh! Maybe. And she said it wasn't gonna - the transcriber said it wouldn't be a problem cuz they can actually make a template  uh  that has beep  number  beep. So for them it'll be very quick O_K. Yeah. to - to put those in there when they're transcribing. So  um  we - We're gonna send them one more sample meeting  uh  and Thilo has run his segmentation. Adam's gonna generate the chunked file. And then  um  I'll give it to Brian and they can try that out. And when we get that back we'll see if that sort of fixes the problem we had with  uh  too many beeps in the last transcription. O_K. Do w- do - what - Do you have any idea of the turn-around on - on those steps you just said? Great. Uh. Uh. Our s- our - On our side? or including I_B_M's? Including I_B_M's. Well  I don't know. The last one seemed like it took a couple of weeks. O_K. Um  maybe even three. Uh  that's just the I_B_ M side. Our side is quick. I mean  I - I don't know. How long does your - ? It should @@ be finished today or something. Yeah. Well  I meant the overall thing. e- e- u- u- The reason I'm asking is because  uh  Jane and I have just been talking  and she's just been Yeah. doing. Uh  e- a  you know  further hiring of transcribers. And so we don't sort of really know Mm-hmm. Mm-hmm. exactly what they'll be doing  how long they'll be doing it  and so forth  because right now she has no choice but to operate in the mode that we already have working. And  uh  Right. so it'd be - It'd be good to sort of get that resolved  uh  soon as we could  and then - Yeah. I - Yeah  I - I hope @@ we can get a better estimate from this one that we send them. Mm-hmm. So. Um. I - I don't know yet Yeah. Um - how long that'll take. I mean in particular I would - I would really hope that when we do this DARPA meeting in July that we sort of have - we're - we're into production mode  somehow - You know  that we - we actually Mm-hmm. have a stream going and we know how - how well it does and how - Yeah. and how it operates. I think that would - that would certainly be a - a very good thing to know. Right. Right. O_K. Uh. Maybe before we do the meeting info organize thing  maybe you could say relevant stuff about where we are in transcriptions. O_K. So  um  we - Uh  the transcribers have continued to work past what I'm calling ""set one""  which was the s- the set that I've been  uh - O_K  talking about up to this point  but  uh  they've gotten five meetings done in that set. Right now they're in the process of being edited. Um  the  um - Let's see  I hired two transcribers today. I'm thinking of hiring another one  which will - because we've had a lot of attrition. And that will bring our total to - They die off after they do this for a while. Yeah. Yeah. Burn-out. Well  you know  it's - it's various things. So  one of them had a baby. Um  you know  one of them really w- wasn't planning - Oh  that was an unfor- unforeseen side effect of - Eh  one of them  um  had never planned to work past January. I mean  it's th- all these various things  cuz we  you know  we presented it as possibly a month project back in January and - and - Yeah. and - and - Um  so it makes sense. Uh  through attrition we - we've - we're down to - to two  but they're really solid. We're really lucky the two that we kept. And  um - Well  I don't mean - I don't mean anything against the others. What I mean is we've got a good cause - a good core. No. We had a good core - Well  they won't hear this since they're going. They won't be transcribing this meeting. Yeah  but still. I mean  I d- it's just a matter of we - w- we're - we've got  uh  No backs. two of the ones who - who  um  ha- had been putting in a lot of hours up to this point and they're continuing to put in a - a lot of hours  which is wonderful  and excellent work. And so  then  in addition  um  I hired two more today and I'm planning to h- hire a third one with this - within this coming week  but - but the plan is - just as  uh  Morgan was saying we discussed this  and the plan right now is to keep the staff on the - on the leaner side  you know  rather than hiring  like  eight to ten right now  Mm-hmm. because if the I_B_M thing comes through really quickly  then  um  we wouldn't wanna have to  uh  you know  lay people off and stuff. So. And this way it'll - I mean  I got really a lot of response for - for my notice and I think I could hire additional people if I wish to. Yeah. An- and the other thing is  I mean  in the unlikely event - and since we're so far from this  it's a little hard to plan this way - in the unlikely event that we actually find that we have  uh  transcribers on staff who are twiddling their thumbs because  you know  there's  you know  all the stuff that - that was sitting there has been transcribed and they're - and they're faster - the - the pipeline is faster than - uh  than the generation  um  eh  i- in - in the day - e- event that that day actually dawns  uh  I - I bet we could find some other stuff for them to do. So I - I think Oh  yes. that  eh  eh  a- as we were talking  if we - if we hire twelve  then we could  you know  run into a problem later. I mean  we also just couldn't sustain that forever. But - but  um - for all sorts of reasons - but if we hire f- you know  f- we have five on staff - five or six on staff at any given time  then it's a small enough number so we can be flexible either way. Good. O_K. Good. It'd be great  too  if  um  we can - we might need some help again getting the tighter boundaries or some hand - to experiment with  um - you know  to have a ground truth for this segmentation work  which - I guess you have some already that was really helpful  and we could probably use more. Mmm  yeah. That was a thing I - I planned working on  is  uh  to use the - the transcriptions which are done by now  and to - to use them as  uh - Yeah. Oh. Oh  the new ones with the tighter boundaries. Yeah. Yeah. And to use them for - for training a - or for - fo- whatever. Yeah. To - to create some speech-nonspeech labels out of them  and - Yeah  but that - that's a thing w- was - w- what I'm just looking into. O_K. The - the - the pre-segmentations are so much - are s- so extremely helpful. Now there was  uh  I g- guess - So  a couple weeks ago I needed some new ones and it happened to be during the time that he was on vacation - f- for just very few days you were away. Yeah. But it happened to be during that time I needed one  so I - so I started them on the non-pre-segmented and then switched them over to yours and  um  they  um - you know  they always appreciate that when they have that available. And he's  uh  usually  eh  uh  um - Um. So they really appreciate it. But I was gonna say that they do adjust it once in a while. You know  once in a while there's something like  Yeah  sure. um  and e- Actually you talked to them. Didn't you? Did you? Have you - ? Yeah. I talked to Helen. And - and - and she was - And so  I asked her - I mean  They're very perceptive. I really want to have this meeting of the transcribers. I haven't done it yet  but I wanna do that and she's out of town  um  for a couple of weeks  but I wanna do that when she returns. Um  cuz she was saying  you know  in a - in a span of very short period - we asked - It seems like the ones that need to be adjusted are these - these - these things  and she was saying the short utterances  uh  the  um - Hmm. Mmm. Yeah. you know  I mean  you're - You're aware of this. Yeah. But - but actually i- it's so correct for so much of the time  that it's an enormous time saver and it just gets tweaked a little around the boundaries. That's great. So. Um. Yeah. I think it'd be interesting to combine these. Yeah. Is there actually a record of where they change? I mean  you can compare  do a diff on the - just so that we knew - You could do it. It's - it's complicated in that Yeah. um  hhh  i- hhh  i- Actually  when - when they create new - yeah  new segments or something  it will be  uh  not that easy but - hmm. I mean  if we keep a old copy of the old time marks just so that if we run it we know whether we're - which ones were cheating and I think one could do that. Yeah. Yeah. Yeah. That would be great  yeah  to know that. which one would be good. There is a - there is one problem with that and that is when they start part way through then what I do is I merge what they've done with the pre-segmented version. So it's not a pure - Yeah. it's not a pure condition. Wha- what you'd really like is that Mm-hmm. they started with pre-segmented and were pre-segmented all the way through. And  um - @@ - I  uh - the - it wasn't possible for about four of the recent ones. But  it will be possible in the future because we - we're  um. Yeah. @@ Mmm  that's great. It would. Yeah. Yeah. As long as we have a record  I guess  of Yeah. the original automatic one  we can always find out Yeah. how well we would do fr- from the recognition side by using those boundaries. Um. You know  a completely non-cheating version. Also if you need someone to record this meeting  I mean  I'm happy to - for the transcribers - Yeah. Yeah. I could do it  or Chuck or Adam. Thank you. O_K. So  uh  u- you were saying something about organizing the meeting info? Yeah. So  um  uh  Jane and Adam and I had a meeting where we talked about the reorganization of the directory structure for all of the meeting - Did you record it? No. For all the Meeting Recorder data. We should have. Um. And so we've got a plan for what we're gonna do there. And then  Jane also s- prepared a - um  started getting all of the - the meetings organized  so she prepared a - a spreadsheet  which I spent the last couple of days adding to. So I went through all of the data that we have collected so far  and have been putting it into  uh  a spreadsheet with start time  the date  the old meeting name  the new meeting name  the number of speakers  the duration of the meeting  comments  you know  what its transcription status is  all that kind of stuff. And so  the idea is that we can take this and then export it as H_T_M_L and put it on the Meeting Recorder web page so we can keep people updated about what's going on. Oh  great. Um  I've gotta get some more information from Jane cuz I have some - some gaps here that I need to get her to fill in  but so far  um  as of Monday  the fourteenth  um  we've had a total number of meeting- sixty-two hours of meetings that we have collected. And  um - Uh  some other interesting things  average number of speakers per meeting is six. Um  and I'm gonna have on here the total amount that's been transcribed so far  but I've got a bunch of - uh  that's what I have to talk to Jane about  figuring out exactly which ones have - have been completed and so forth. But  um  this'll be a nice thing that we can put up on the - the web site and people can be informed of the status of various different ones. And it'll also list  uh  like under the status  if it's at I_B_M or if it's at ICSI  uh  or if it's completed or which ones we're excluding and - and there's a place for comments  so we can  um  say why we're excluding things and so forth. So. Now would the ones that  um  are already transcribed - we h- we have enough there that c- you know  we've already done some studies and so forth and - um  shouldn't we go through and do the business -es u- of - of having the  um  uh  participants approve it  uh  for - approve the transcriptions for distribution and so forth? Um  interesting idea. In principle  I - I would say yes  although I still am doing some - the final-pass editing  trying to convert it over to the master file as the - being the channelized version and it's - Yeah  it seems like I get into that a certain way and then something else intervenes and I have to stop. Cleaning up the things like the  uh  uh  places where the transcriber was uncertain  and - and doing spot-checking here and there. So  um  uh  I guess it would make sense to wait until th- that's done  um  but - but - Well  le- let me put in another sort of a milestone kind of - as - as I did with the  uh  uh - the - the pipeline. Yeah. Um  we are gonna have this DARPA meeting in the middle of July  and I think it w- it'd be - Yes. given that we've been - we've given a couple public talks about it already  spaced by months and months  I think it'd be pretty bad if we continued to say none of this is available. Um. It'll certainly be done by then. Yeah. Right. So we can s- we - we wanna be able to say ""here is a subset that is available right now"" Mm-hmm. That's right. and that's has been through the legal issues and so forth. So. That's right. Yeah. That's right. So that - O_K? O_K. So  And they don't have to approve  by - before July. you know  th- an edited version  they can just give their approval to whatever Well  in principle  yes. But  I mean  i- if - if - if somebody actually did get into some legal issue with it then we- Well  maybe - version Bu- Yeah. But th- I mean  the editing will continue. Presumably if - if s- errors are found  they will be fixed  but they won't change the - Content  really. the content of the meetings. So. Well  see  this is the - this is the issue. Subtleties. Well  i- if Jane is clarifying question question  then  you know  how can they agree to it before they know her final version? The other thing  too  is there can be subtleties where a person uses this word instead of that word  which @@ could've been transcribed in the other way. Yeah. Thing - And no- and they wouldn't have been slanderous if it had been this other word. You know? I- it - you know  there- there is a point at which I agree it becomes ridiculous because  you know  you could do this final thing and then a year from now somebody could say  you know  that should be a period and not a question mark. Right? And you don't - you - there's no way that we're gonna go back and ask everybody ""do you approve this  uh  you know - this document now?"" So - So I think what it is is that the - the - the - the thing that they sign - I - I haven't looked at it in a while  but it has to be open enough that it sort of says ""O_K  from now on - you know  now that I've read this  you can use - do anything you want with these data."" Mm-hmm. And  uh - But  i- I think we wanna - So  assuming that it's in that kind of wording  which I don't remember  um  I think i- we just wanna have enough confidence ourselves that it's so close to the final form it's gonna be in  a year from now that they're - Mm-hmm. I agree. Mmm. I totally agree. It's just  uh  a question of  Uh. uh  if - if the person is using the transcript as the way of them judging what they said and whether it was slanderous  then it seems like it's - it's - i- it needs to be more correct than if we could count on them re-listening to the meeting. Because it becomes  eh  in a way a - a f- uh  a legal document i- if they've agreed to that. Well  I forget how we end- Right. I forget how we ended up on this  but I remember my taking the position of not making it so - so easy for everybody to observe everything and Adam was taking the position of - of having it be really straightforward for people to check every aspect of it including the audio. And I don't remember who won  Adam or me  but - uh  the - Well  if it's only the transcript  though - I mean  th- this - this is my point  that - that Uh  that- that's why I'm bringing this up again  because I can't remember how we ended up. then it becomes - That it was the transcrip- He wanted to do a web interface that would make it - Well  if it's just the audio - Well. that would give you access to the transcript and the audio. That's what Adam wanted. Mm-hmm. And I don't remember how we ended up. I mean  with the web interface it's interesting  because you could allow the person who signs to be informed when their transcript changes  or something like that. And  I mean  I would say "" no "". Like  I don't wanna know  but some people might be really interested and then y- In other words  they would be informed if there was some significant change other than typos and things like that. You decided you were whispering Satanic incantations under your breath when you were - Well  I don't know what happened to the small heads thing  but I j- Um  I'm just saying that  like  you know  you can sort of say that any things that are deemed - They disappeared from view. Anyway. I mean  I agree that at some point people probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent  I guess  if - if those change. Cuz assumi- assuming we - we don't really distribute things that have any significant changes from what they sign anyway. Tha- That's - How about having them approve the audio and not the transcripts? Oh  my God. Uh. That would be simpler  if we could count on them listening. Talk. But no one will listen to the hours and hours of - Well  that's O_ K. We just have to give them a chance to listen to it  and if they don't  that's their problem. That's - hmm  hmm. You - you d- Well. That's like - Unfortunately  uh  in - in the sign- thing that they signed  it says "" transcripts "". ""You'll be - you'll be provided the transcripts when they're available."" No  I'm serious. Really? I- I - I think Yeah. Mmm. Yeah. Mmm. that's a lot to ask for people that have been in a lot of meetings. Yeah. Yeah. W- anyway  haven't we - we've gone down this path a number of times. I know this can lead to extended conversations and - and not really get anywhere  so let - let me just suggest that - uh  off-line that  uh  the people involved figure it out and take care of it before it's July. Yes. O_K. So - so that in July we can tell people Yes. ""yes  we have this and you can use it"". It's done  ready  available. Good. Uh. So  let's see. What else we got? Uh. Don did - did a report about his project in class and  uh - an oral and written - written version. So that was stuff he was doing with you. Well. I mean  it's - I guess one thing we're learning is that the amount - We have Yeah. eight meetings there because we couldn't use the non-native - all non-native meetings and it's  well  probably below threshold on enough data for us for the things we're looking at because the prosodic features are very noisy and so you - you need a lot of data in order to model them. Um  so we're starting to see some patterns and we're hoping that maybe with  I don't know  double or triple the data - with twenty meetings or so  that we would start to get better results. But we did find that some of the features that  I gue- Jane would know about  that are expressing sort of the distance of  um  boundaries from peaks in the utterance and some local  um  range - pitch range effects  like how close people are to their floor  are showing up in these classifiers  which are also being given some word features that are cheating  cuz they're true words. Um  so these are based on forced alignment. Word features like  um  word frequency and whether or not something's a backchannel and so forth. So  we're starting to see  I think  some So the dominant features  including everything  were those - those quasi-cheating things. Right? Where these are - interesting patterns. Sometimes not. I think it depends what you're looking at  a- actually. Yeah. Sometimes positions in sentences obviously  or in spurts  was helpful. I don't know if that's cheating  too. Right. Um  Spurts wouldn't be. Right? spurts is not cheating except that of course you know the real words  but roughly speaking  the recognized words are gonna give you a similar type of position. It's either early or late. Right. Right. Would they give you the same number of words  though? Right. Not exactly  but i- No- But ra- somewhat? Y- yeah it should be. On the average. Well  we don't know and actually that's one of the things we're interested in doing  is a sort of - Have you tried using just time  as opposed to number of words? Uh-huh. So. I think ti- uh - Just p- time position  like when the word starts? Yeah. I don't know if that was in the - Well  no  I mean t- time - time position relative to the Eh - You know  uh- Start. beginning of the spurt. Yeah  uh  we didn't try it  but it's s- Yeah. There's all these things to do. Like  there's a lot of different features you could just pull out. Yeah. I mean that wouldn't be cheating because you can detect pause pretty well within the time. Right. Right. And it depends on speaking rate - How about time position normalized by speak- Yeah. Yeah. speaking rate. Yeah. Yeah. Yeah. That's actually why I didn't use it at first. But we - one of the interesting things was Yeah. Mm-hmm. I guess you reported on some te- punctuation type - finding sentence boundaries  finding Yeah. disfluency boundaries  and then I had done some work on finding from the foreground speech whether or not someone was likely to interrupt  so where - you know  if I'm talking now and someone - and - and Andreas is about to interrupt me  is he gonna choose a certain place in my speech  either prosodically or word-based. And there the prosodic features actually showed up and a neat thing - even though the word features were available. And a neat thing there too is I tried some - putting the speaker - So  I gave everybody a short version of their name. So the real names are in there  which we couldn't use. Uh  we should use I_Ds or something. And those don't show up. So that means that overall  um  it wasn't just modeling Morgan  or it wasn't just modeling a single person  Mm-hmm. um  but was sort of trying to  uh  get a general idea - the model - the tree classifier was trying to find general locations that were applicable to different speakers  even though there are huge speaker effects. So. The - but the main limitation now is I - because we're only looking at things that happen every ten words or every twenty words  we need more - more data and more data per speaker. So. It'd also be interesting to look at the E_D_U meetings because we did include meeting type as a feature  so whether you were in a r- Meeting Recorder meeting or a Robustness meeting did matter to interrupts because there are just fewer interrupts in the Robustness meetings. Mm-hmm. And so the classifier learns more about Morgan than it does about sort of the average person  which is Mm-hmm. not bad. It'd probably do better than - Um  but it wasn't generalizing. So it's - Yeah. And I think Don  um - Well  we have a long list of things he's starting to look at now over the summer  where we can - And he'll be able to report on more things in the future. But it was great that we could at least go from the - you know  Jane's transcripts and the  uh  recognizer output and get it to this point. And I think it's something Mari can probably use in her preliminary report - like  ""yeah  we're at the point where we're training these classifiers and we're just reporting very preliminary but suggestive results that some features  both word and pro- prosodic  work. "" The other thing that was interesting to me is that the pitch features are better than in Switchboard. And I think that really is from the close-talking mikes  cuz the pitch processing that was done has much cleaner behavior than - than the Switchboard telephone bandwidth. Hmm. W- wh- wh- wh- Better in what sense? Um. Well  first of all  the pitch tracks are m- have less  um  halvings and doublings than - than Switchboard and there's a lot less dropout  so if you ask how many regions where you would normally expect some vowels to be occurring Mm-hmm. are completely devoid of pitch information  in other words the pitch tracker just didn't get a high enough probability of voicing for words - for - for  Hmm. you know  five word- there are much fewer than in Switchboard. So the missing - We had a big missing data problem in Switchboard and  so the features weren't as reliable cuz they were often just not available. So that's actually good. Could it have to do with the - the lower frequency cut-off on the Switchboard? Ma- maybe. I mean  the tele- we had telephone bandwidth for Switchboard and we had the an- annoying sort of telephone handset movement problem that I think may also affect it. Hmm. So we're just getting better signals in - in this data. Which is nice. So. Yeah. Anyway  Don's been doing a great job and we hope to Great. continue with  um  Andreas's help and also some of Thilo's help on this  to - to try to get a non-cheating version of how all this would work. Y- Yeah. Sure. Yeah. Has - has  uh - ? We just - I think  just talked about this the other day  but h- has - has anybody had a chance to try changing  uh  insertion penalty sort of things with the - with the  uh - uh  using the tandem system Oh  yeah. I tried that. It didn't  input for the - ? um  help dramatically. Um. Were they out of balance? I didn't - I didn't notice. The - There were a little - the relative number of - I think there were a higher number of deletions  actually. Oh. Deletions? So  you  uh - So  actually it - it preferred to have a positive - er  negative insertion penalty  which means Uh- huh. that  um - But  you know  it didn't change th- the - by adjusting that - the  um - O_K. Yeah. The error changed by probably one percent or so. But  you know  given that that word error rate is so high  that's not a - O_K. So that - So that's - So that's not the problem. Yeah. That's not the problem. No. But  uh  we s- just  um  uh - you know  Chuck and I talked and the @@ next thing to do is probably to tune the - um  the size of the Gaussian system  um  @@ to - to this - to this feature vector  which we haven't done at all. We just used the same configuration as we used for the - Hmm. for the standard system. And  for instance  uh  Dan - @@ Dan just sent me a message saying that C_M_U used  um  something like ten Gaussians per cluster - @@ You know  each - each mixture has ten Gaussians Mm-hmm. Hmm. We're using sixty- four  right? and - and we're using sixty-four  so that's Yeah. obviously a big difference and it might be way off and give very poorly trained  Hmm. uh  you know  Gaussians that way  uh  an- and poorly trained mixture weights. So - so  we have - The turn-around time on the training when we train only the - a male system with  uh  you know  our small training set  is less than twenty-four hours  so we can run lots of - uh  basically just brute force  try a whole bunch of different um  settings. And  uh  with the new machines it'll be even better. So. O_K. Yeah. We get twelve of those  huh? Yeah. O_K. But the P_L_P features work - um  uh  you know  continue to improve the  um - As I said before  the - uh using Dan's  uh  uh  vocal tract normalization option works very well. Mm-hmm. So  um  @@ I ran one experiment where we're just did the vocal tract le- normalization only in the test data  so I didn't bother to retrain the models at all  and it improved by one percent  which is about what we get with - uh  with  you know  just @@ actually doing both training and test normalization  um  with  um  the  uh - uh  with the standard system. So  in a few hours we'll have the numbers for the - for retraining everything with vocal tract length normalization and - So  that might even improve it further. Great. So  it looks like the P_L_fea- P_ features do very well now with - after having figured out all these little tricks to - to get it to work. Yeah. So. Wait. So you mean you improve one percent over Good. a system that doesn't have any V_T_ L in it already? Exactly. Yeah. O_K. Yeah. O_K . So then - then we'll have our baseline to - to compare the currently hideous  uh  uh  new thing with. But - Right. a- Right. And - and what that suggests also is of course that the current Yeah. Switchboard M_L_P isn't trained on very good features. Uh  because it was trained on whatever  you know  was used  uh  last time you did Hub-five stuff  which didn't have any of the - Right. But all of these effects were j- like a couple percent. Uh. Right? I mean  y- the - Well  but if you add them all up you have  uh  almost five percent difference now. Add all of them. I thought one was one point five percent and one was point eight. Yeah. And now we have another percent with the V_T_ L. That's three point three. Um  actually  and it's  @@ um  What's actually qu- interesting is that with - um  well  you m- prob- maybe another half percent if you do the V_T_L in training  and then interestingly  if you optimize you get more of a win out of rescoring the  um  uh  the N_ best lists  uh  and optimizing the weights  um  uh than - Yeah. Than you do with the standard? So - Yeah. But the part that's actually adjustment of the front- end per se as opposed to doing - putting V_T_L_N in or something is - it was a couple percent. Right. Right? It was - it was - there was - there was one thing that was one and a half percent and one that was point eight. So - and - and - let me see if I remember what they were. One of them was  uh  the change to  uh - because it did it all at once  to - uh  from bark scale to mel scale  Mm-hmm. which I really feel like saying in quotes  because @@ they're essentially the same scale but the - but - but - but Yeah. Why did that cha- ? any i- individual particular implementation of those things puts things in a particular place. Mm-hmm. So that's why I wanted to look - I still haven't looked at it yet. I - I wanna look at exactly where the filters were in the two  and it - Mm-hmm. it's probably something like there's one fewer or one more filter in the sub one kilohertz band and for whatever reason with this particular experiment it was better one way or the other. Mm-hmm. Hmm. Um  it could be there's something more fundamental but it - you know  I - I don't know it yet. And the other - and the other - that was like one and a half or something  and then there was point eight percent  which was - what was the other thing? Well  that was combined with the triangular. Right? Yeah. Those - those two were together. We d- weren't able to separate them out cuz it was just done in one thing. But then there was a point eight percent which was something else. Do you remember the - ? Yeah. Right. The low-frequency cut-off. Oh  yeah. So that was - that was  uh - that one I can claim credit for  uh  i- in terms of screwing it up in the first place. So that someone e- until someone else fixed it  which is that  um  I never put - when I- u- We had some problems before with offsets. This inf- this went back to  uh  I think Wall Street Journal. So we - we had  uh - Hmm. ea- everybody else who was doing Wall Street Journal knew that there were big D_C offsets in th- in these data - in those data and - and - and nobody happened to mention it to us  and we were getting these  Hmm. like  really terrible results  like two  three times the error everybody else was getting. And then in casual conversation someone ment- mentioned ""uh  well  I guess  you know  of course you're taking care of the offsets. "" I said "" what offsets?"" And at that point  you know  we were pretty new to the data and we'd never really  like  looked at it on a screen and then when we just put it on the screen and wroop! Mm-hmm. Mmm. there's this big D_C offset. Mm-hmm. So  um  in P_L_P- There was a - like a hum or some- or - when they recorded it? Or just - ? No. It's just  it - it's - it's not at all uncommon for - for recorded electronics to have different  um  D_C offsets. Huh. It's - it's  you know  no big deal. It's - you know  you could have ten  twenty  maybe thirty millivolts  whatever  and it's consistently in there. The thing is  most people's front-ends have pre- emphasis with it  with zero at zero frequency  so that it's irrelevant. Uh  but with P_L_ P  we didn't actually have that. We had - we had the equivalent of pre-emphasis in a - a  uh  Fletcher-Munson style weighting that occurs in the middle of P_L_ P  but it doesn't actually have a zero at zero frequency  like  eh  uh  typical simple fr- pre- emphasis does. Hmm. We had something more fancy. It was later on it didn't have that. So at that point I reali- ""oh sh- we better have a - have a high-pass filter "" just  you know - just take care of the problem. So I put in a high-pass filter at  uh  I think ninety - ninety hertz or so uh  for a sixteen kilohertz sampling rate. And I never put anything in to adjust it for different - different sampling rates. And so - well  so  you know  the code doesn't know anything about that and so this is all at eight kilohertz and so it was at forty- five hertz instead of at - Hmm. instead of at ninety. So  um  I don't know if Dan fixed it or - or  uh  Well  he made it a parameter. what he - He made it a parameter. So. Yeah  I guess if he did it right  he did fix it and then - and then it's taking care of sampling rate  which is great. What - what is the parameter? Is it  uh  just the f- lower cut-off that you want? He had a - It's called  uh  H_- H_P_F. H_ - Yeah. Does H_P_F on - on his feat- feature. u- And - but H_P_F  you know  when you put a number after it  uses that as the Mm-hmm. hertz value of the cut-off. So. Yeah. Oh  O_K. I mean  frankly  we never did that with the RASTA filter either  so the RASTA filter is actually doing a different thing Mm-hmm. in the modulation spectral domain depending on what sampling rate you're doing  which is another old - old bug of mine. Mm-hmm. But  um - Um. So that - that was the problem there was th- we - we - we had always intended to cut off below a hundred hertz and it just Mm-hmm. wasn't doing it  so now it is. So  that hep- that helped us by  like  eight tenths of a percent. It still wasn't a big deal. O_K. Well  but  um - Well  uh  again  after completing the current experiments  we'll - we can add up all the Oh  yeah. But - uh differences and - and - an- but  I guess my - my point was that - that  um  the hybrid system thing that we did was  uh  primitive in many ways. Y- Right. And I think I agree with you that if we fixed lots of different things and they would all add up  we would probably have a - a - a competitive system. But I think not that much of it is due to the front-end per se. I think maybe a couple percent of it is  as far as I can see from this. Mm-hmm. Uh  unless you call - well  if you call V_T_L the front-en- front-end  that's  uh  a little more. But that's sort of more both  kind of. Right? But. One experiment we should - we'll probably need to do though when - um  at some point  is  since we're using that same - the net that was trained on P_L_P without all these things in it  for the tandem system  we may wanna go back and retrain  Well  that's what I meant  in fact. Yeah. yeah  yeah  for the tandem. You know  so we can see if it - what effect it has on the tandem processing. So - so  the thing is - is Mm-hmm. do we expect - ? eh At this point I'm as- I mean  you know - e- I'm wondering is it - Can we expect  uh  a tandem system to do better than a properly trained - you know  a Gaussian system trained directly on the features with  you know  the right ch- choice of parameters? Well  that's what we're seeing in other areas. Yes. Right? So  it's - so  um  um - So  we - But - but we may not. I mean  if it doesn't perform as well  we may not know why. Right? Cuz we need to do Right. the exact experiment. I mean  the reason to think it should is because you're putting in the same information and you're transforming it to be more discriminative. So. Um. Now the thing is  in some databases I wouldn't expect it to necessarily give you much and - and part of what I view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do  not just th- the standard front-end  but other things  like with multiple streams and so forth  Mm-hmm. and allows you to feed them to the other system with this - through this funnel. Um  so I think - I think that's the real power of it. I wouldn't expect huge in- huge improvements. Um  but it should at least be roughly the same and maybe a little better. If it's  you know  like way way worse then  you know - Mm-hmm. Right. So  Morgan  an- another thing that Andreas and I were talking about was  so @@ in the first experiment that he did we just took the whole fifty-six  uh  outputs and that's  um  basically compared to a thirty-nine input feature vector Mm-hmm. Mm-hmm. from either M_F_C_C or P_L_P. But one thing we could do is - Let - let me - let me just ask you something. When you say take the fifty-six outputs  these are the pre- final nonlinearity outputs and they're - and - Yeah. Through the regular tandem outputs. through the K_L_T. Through the K_L_T. All that kinda stuff. O_K. And so - so then you u- Do you use all fifty-six of the K_L_T or - ? That's what we did. Right? O_K. So one thing we were wondering is  if we did principal components and  say  took out just thirteen  and then did deltas and double-deltas on that - so we treated the th- Yes. Yes. first thirteen as though they were standard features. Yeah. I mean  did Dan do experiments like that to - ? Uh. Talk with Stephane. He did some things like that. It was either him or Carmen. I forget. Mm-hmm. Mmm. I mean these were all different databases and different - you know  in H_T_K and all that  so i- it - it may not apply. But Yeah. my recollection of it was that it didn't make it better but it didn't make it worse. Hmm. But  again  given all these differences  maybe it's more important in your case that you not take a lot of these low-variance  uh  components. Cuz in a sense  the net's already got quite a bit of context in Yeah. those features  so if we did deltas and double-deltas on top of those  we're getting sort of even more. Which could be good or not. Yeah. Yeah. Yeah. Worth trying. But there the main point is that  um  you know  it took us a while but we have the procedure for coupling the two systems debugged now and - I mean  there's still conceivably some bug somewhere in the way we're feeding the tandem features - uh  either generating them or feeding them to this - to the Mm-hmm. Yeah. S_R_I system  but There might be  cuz that's a pretty big difference. it's - Yeah. But And I'm wondering how we can - Yeah. how we can debug that. I mean how - Um. Hmm. I'm actually f- quite sure that the - What if - ? feeding the features into the system and training it up  that - that - I think that's - this - that's essentially the same as we use with the ce- with the P_L_ P fe- features. And that's obviously working great. So. I- um. Yeah. There could be a bug in - in the - There - we could - somewhere before that. the - another degree of freedom is how do you generate the K_L_ T transform? Mm-hmm. That's - Right? We to- Right. well  and another one is the normalization of the inputs to the net. Yeah. These nets are trained with particular normalization and when that gets screwed up it - it can really hurt it. I'm doing what Eric - E- Eric coached me through then - that part of it  so I'm pretty confident in that. I mean  the only O_K. slight difference is that I use normalization values that  um  Andreas calculated from the original P_L_P  which is right. N- Yeah. Right. Right. So  I u- I do - Oh  we actually don't do that normalization for the P_L_P  do we? For the st- just the straight P_L_P features? No. The - the S_R_I system does it. S_R_ I system does that. Right. Yeah. Right. Well  you might e- e- So that's - that's another - So  there's - there is - there is room for bugs that we might not have Yeah. Yeah. Mm-hmm. Yeah. I - discovered  but - I would actually double check with Stephane at this point  cuz he's probably the one here - I mean  he and Dan are the ones who are at this point most experienced with the tandem Mm-hmm. thing and there may - there may be some little bit here and there that is not - not being handled right. Yeah. It's hard with features  cuz you don't know what they should look like. I mean  you can't just  like  print the - the values out in ASCII and  you know  look at them  see if they're - Not unless you had a lot of time and - Well - eh  and also they're not - I mean  as I understand it  you - you don't have a way to optimize the features for the final word error. Right? Right. I mean  these are just discriminative  but they're not  um  optimized for the final - They're optimized for phone discrimination  not for - Right. So it - there's always this question of whether you might do better with those features if there was a way to train it That's right. Well  the other - for the word error metric that you're actually - Yeah  th- the - Mm- Mmm. Well  you actually are. that you're actually - But - but it - but in an indirect way. Well  right. It's indirect  so you don't know - So wha- w- what - an- and you may not be in this case  come to think of it  because  uh  you're just taking something that's trained up elsewhere. So  what - what you - what you do in the full procedure is you  um  uh  have an embedded training. So in fact you - the - the net is trained on  uh  uh  a  uh  Viterbi alignment of the training data that comes from your full system. And so that's where the feedback comes all around  so that it is actually discriminant. You can prove that it's - it's a  uh - If you believe in the Viterbi assumption that  uh  getting the best path  uh  is almost equivalent to getting the best  uh  total probability  um  then you actually do improve that by  uh - by training up on local - local  uh - local frames. But  um  we aren't actually doing that here  because we did - we did that for a hybrid system  and now we're plugging it into another system and so it isn't - i- i- i- it wouldn't quite apply here. So another huge experiment we could do would be to Do y- take the tandem features  uh  do S_R_I Mm-hmm. forced alignments using those features  and then re-do the net with those. Mmm  uh - Exactly. Exactly. Yeah. So that you can optimize it for the word error. Yeah. Yeah. Another thing is since you're not using the net for recognition per se but just for this transformation  it's probably bigger than it needs to be. But - So that would save a lot of time. And there's a mismatch in the phone sets. Mmm. So  you're using a l- a long- a larger phone set than what - Yeah. Actually all those things could - could - could - could  uh - could affect it as well. Yeah. Yeah. The other thing  uh  just to mention that Stephane - this was an innovation of Stephane's  which was a pretty neat one  uh  and might particularly apply here  given all these things we're mentioning. Um  Stephane's idea was that  um  discriminant  uh  approaches are great. Even the local ones  given  you know  these potential outer loops which  you know  you can convince yourself turn into the global ones. Um  however  there's times when it is not good. Uh  when something about the test set is different enough from the training set that - that  uh  the discrimination that you're learning is - is - is not a good one. Mm-hmm. So  uh  his idea was to take as the input feature vector to the  uh  Gaussian mixture system  uh  a concatenation of the neural net outputs and the regular features. Yeah. That - Oh  we already talked about that. Yeah. Mm-hmm. Didn't you - did you do that already or - ? El- Yeah. No  but we - we - when - when we - when I first started corresponding with Dan about how to go about this  Oh. That makes a lot of sense. Huh. I think that was one of the things that we definitely went there . Yeah. Yeah. I mean  I'm sure that Stephane wasn't the first to think of it  but actually Stephane did it and - Yeah. Uh-huh. And i- does it help? and - and it helped a lot. Yeah. Oh  O_K. So that's - that - that's our current best - best system in the  uh - Oh. O_K. uh  in the Aurora thing. Yeah. Yeah. That makes sense. And do you do a K_L_T transform on the con- on the combined feature vector? As - you should never do worse. I - I  uh  missed what you said. Do you - d- you do a K_L_T transform on the combined feature vector? Yeah. O_K. Well  actually  I  uh - you should check with him  because he tried several different combinations. Because you end up with this huge feature vector  so that might be a problem  a- unless you do some form of dimensionality reduction. Yeah. I  uh  th- what I don't remember is which came out best. So he did one where he put o- put e- the whole thing into one K_L_T  and another one  since the - the P_L_P things are already orthogonalized  Mm-hmm. he left them alone and - and just did a K_L_T on the - on the - on the net outputs and then concatenated that. Mmm. And I don't remember which was better. Did he - did he try to - ? So he always ended up with a feature vector that was twice as long as either one of the - ? No. I don't know  i- I - I don't know. You have to check with him. Yeah. O_K. Actually  I have to run. I'm into big ideas these days. Yeah. Uh. We need to close up cuz I need to save the data and  @@ Not to mention the fact that we're missing snacks. Yeah. um  get a call. Right. Uh- Did people wanna do the digits or  um  do them together? I don't know. Um. I - I g- I think  given that we're in a hurry for snacks  maybe we should do them together. Should we just - ? O_K. I mean  are we trying to do them in synchrony? That might be fun. Adam's not here  so he's not here to tell me no. Well  it's - it's - it's not - You know  it's not gonna work out but we could - we could just  uh  uh  see if we find a rhythm  you know  what - Sure. Uh  O_ 's or zeroes  we wanna agree on that? @@ Maybe just whatever people would naturally do? I don't know. Oh  but if we were a singing group  we would wanna decide. Right? Be harmony. Yeah. Yeah. Mine's identical to yours. Is that correct? We might wa- Sorry. So I set up and we didn't have enough digit forms so I xeroxed the same one seven times. Oh. I see. So these are excellent. Oh. I see. Why don't we do zer- i- Anyone have a problem with saying zero? No. Is zero O_K? Yeah. O_K. One and a two and three. seven eight seven seven eight seven seven eight seven seven eight seven e- seven one five two one five two one five two one five two one five two z- zero three zero two zero three zero two zero three zero two O_ three zero two eight one two zero eight one two zero eight one two zero eight one two zero two two six one two two six one two two six one two two six one two two six one four six zero three four six zero three four six zero three four six zero three four six zero three zero seven eight zero seven eight zero seven eight zero seven eight zero seven eight two six six two six six two six six two six six two six six two two three two two three two two three two two three two two three four nine eight seven four nine eight seven four nine eight seven four nine eight seven four nine eight seven zero seven five two zero seven five two zero seven five two zero seven five two zero seven five two nine one zero nine nine one zero nine nine one zero nine nine one zero nine nine one zero nine one one one one one eight zero six eight zero six eight zero six eight zero six eight zero six zero five zero five zero five zero five zero five one five six one five six one five six one five six one five six two two two two two eight eight eight eight eight four three six four three six four three six four three six four three six five seven five seven five seven five seven five seven nine five one nine five one nine five one nine five one nine five one eight eight eight eight eight eight four nine eight four nine eight four nine eight four nine eight four nine five three five three five three five three five three two five three eight two five three eight two five three eight two five three eight two five three eight one two zero zero one two zero zero one two zero zero one two zero zero one two zero zero one seven three three one seven three three one seven three three one seven three three one seven three three eight six zero zero eight six zero zero eight six zero zero eight six zero zero eight six zero zero Once more with feeling. No  just k- just kidding. And th- And that was transcript L_ one three eight. Oh  yeah. It was. Light kind of music. We should start a cult. Yeah. It sounded like a cult  didn't it? Really. It sounded very lethargic. I needed protein. And now we're gonna go out and have snacks with no protein in them. It was the lack of prosodic  uh - Now we will eat snacks. Exactly. Everybody sort of lowers their pitch range. Right  and applesauce. Ask everybody con- to contribute to the third worl- ",Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data  naming conventions for files  speaker identification tags  and encoding files with details about the recording. The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program  transcriptions  and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features. Particular focus was paid to questions about transcription procedures  i.e. how to deal with overlooked backchannels  and audible breaths. A small percentage of transcripts will be changed to reflect mis-read  uncorrected digits. A speaker database will be compiled to establish consistent links between speakers and their corresponding identification tags. Sections of densely overlapping speech will require hand-checking so that overlooked backchannels may be manually segmented and labelled. The transcribers should only code audible breaths within a grouping of words  and not outside regions of continuous speech. It was further determined that audible breaths are an important facet of recorded speech  and that removing them from the corpus would be contrary to the aims of the project. Speaker mn005 will prepare his results for detecting speaker overlap and present them in the next meeting. During digits readings  subjects tend to chunk numbers together rather than reading each number separately. When working from the mixed channel  transcribers may select only one start and end time for overlapping speech  resulting in points of overlap that are less tightly tuned. Transcribers are likely to overlook backchannels in densely populated sections of speaker overlap. Speaker mn014 reported that this is also problematic for the automatic detection of speech and non-speech  as backchannels that are very short and not loud enough will inevitably be overlooked. Speaker mn005 reported problems distinguishing between possible harmonics and other frequency peaks  and creating an algorithm for obtaining the instantaneous frequency. The encoding of all audible breaths is too time-consuming. The first test set of digits is complete and includes 4 000 lines  each comprising between 1-10 digits. New digits forms were distributed for eliciting different prosodic groupings of numbers. New naming conventions were discussed as means for facilitating the sorting process. Existing files will be changed so that all filenames are of equal length. Similar changes will be made to speaker identification tags. Files will also contain information specifying channel  microphone  and broadcaster information. A proposal is being drafted for a grant from the NSF's ITR program for extending the research initiatives of the Meeting Recorder project. Speaker fe008 is performing channel-by-channel transcriptions to create tighter time bins. Tentative plans are to assign single channels to the transcriber pool and then piece them together afterwards. Efforts by speaker mn005 are in progress to detect speaker overlap in the mixed signal using harmonicity-related features. For determining the instantaneous frequency  speaker me013 recommended deriving the maxima from energy multiples of a given frequency. It was also suggested that speaker mn005 should determine whether portions of the signal are voiced or unvoiced  as voiced intervals reflecting a relatively low fraction of energy in the harmonic sequence are likely to indicate sections of overlap. 
"Why? I'm known. I - Um. No  cuz she already told me it  before she told you. No  she told me a long time ago. She told me - she told me like two weeks ago. Oh  well  it doesn't matter what time. O_K. @@ You know how to toggle the display width function - Wow. Well maybe she hadn't just started transcribing me yet. Anyway. What is it? Let me explain something to you. Um  My laugh is better than yours. there. Yo. I beg to differ. Um  O_K. But you have to say something genuinely funny before you'll get an example. Yeah. The thing is I don't know how to get to the next page. Here. No. @@ You should be - at least be self-satisfied enough to laugh at your own jokes. Actually I thought - There. No  it's a different laugh. How weird. Ooh  wow! Oh! Holy mackerel. Wow. Whoa! What?! Oh. O_K. I wasn't even doing anything. O_K. Uh. Eva's got a laptop  she's trying to show it off. That was r- actually Robert's idea. But anyhow. Um O_ K. So  here we are. Once again. Once again  right  together. Um  so we haven't had a meeting for a while  and - and probably won't have one next week  I think a number of people are gone. Um  so Robert  why don't you bring us up to date on where we are with E_D_U? Um  uh in a - in a smaller group we had uh  talked and decided about continuation of the data collection. So Fey's time with us is almost officially over  and she brought us some thirty subjects and  t- collected the data  and ten dialogues have been transcribed and can be looked at. If you're interested in that  talk to me. Um  and we found another uh  cogsci student who's interested in playing wizard for us. Here we're gonna make it a little bit more complicated for the subjects  uh this round. She's actually suggested to look um  at the psychology department students  because they have to partake in two experiments in order to fulfill some requirements. So they have to be subjected  before they can actually graduate. And um  we want to design it so that they really have to think about having some time  two days  for example  to plan certain things and figure out which can be done at what time  and  um  sort of package the whole thing in a - in a re- in a few more complicated um  structure. That's for the data collection. As for SmartKom  I'm - the last SmartKom meeting I mentioned that we have some problems with the synthesis  which as of this morning should be resolved. Good. And  so  ""should be"" means they aren't yet  but - but I think I have the info now that I need. Plus  Johno and I are meeting tomorrow  so maybe uh uh  when tomorrow is over  we're done. And ha- n- hav- we'll never have to look at it again Maybe it'll take some more time  to be realistic  but at least we're - we're seeing the end of the tunnel there. That was that. Um  the uh  uh I don't think we need to discuss the formalism that'll be done officially s- once we're done. Um  something happened  in - on Eva's side with the P_R_M that we're gonna look at today  and um  we have a visitor from Bruchsal from the International University. Andreas  I think you've met everyone except Nancy. Sorry. Hi. Hi. Yeah. Hi. Hi. Hi. And  um  So when you said ""Andreas"" I thought you were talking about Stolcke. Now I know that we aren't  O_K. Andy  you actually go by Andy  right? Oh  O_K. Yeah. Eh - Cuz there is another Andreas around  so  to avoid some confusion. Hmm. That will be Reuter? Yeah. Oh  O_K. So my scientific director of the E_M_L is also the dean of the International University  one of his many occupations that just contributes to the fact that he is very occupied. And  um  the - um  he @@ might tell us a little bit about what he's actually doing  and why it is s- somewhat related  and - by uh using maybe some of the same technologies that we are using. And um. Was that enough of an update? I think so. In what order shall we proceed? O_K. Maybe you have your on-line - Uh  yeah  sure. Um  so  I've be- just been looking at  um  Ack! What are you doing? Yeah . O_K. Um  I've been looking at the P_R_M stuff. Um  so  this is  sort of like the latest thing I have on it  and I sorta constructed a couple of classes. Like  a user class  a site class  and - and you know  a time  a route  and then - and a query class. And I tried to simplify it down a little bit  so that I can actually um  look at it more. It's the same paper that I gave to Jerry last time. Um  so basically I took out a lot of stuff  a lot of the decision nodes  and then tried to - The red lines on the  um  graph are the um  relations between the different um  classes. Like  a user has like  a query  and then  also has  you know um  reference slots to its preferences  um  the special needs and  you know  money  and the user interest . And so this is more or less similar to the flat Bayes-net that I have  you know  with the input nodes and all that. And - So I tried to construct the dependency models  and a lot of these stuff I got from the flat Bayes-net  and what they depend on  and it turns out  you know  the C_P_T's are really big  if I do that  so I tried to see how I can do  um - put in the computational nodes in between. And what that would look like in a P_R_M. And so I ended up making several classes - Actually  you know  a class of - with different attributes that are the intermediate nodes  and one of them is like  time affordability money affordability  site availability  and the travel compatibility. And so some of these classes are - s- some of these attributes only depend on stuff from  say  the user  or s- f- just from  I don't know  like the site. S- like  um  these here  it's only like  user  but  if you look at travel compatibility for each of these factors  you need to look at a pair of  you know  what the um  preference of the user is versus  you know  what type of an event it is  or you know  which form of transportation the user has and whether  you know  the onsite parking matters to the user  in that case. And that makes the scenario a little different in a P_R_M  because  um  then you have one-user objects and potentially you can have many different sites in - in mind. And so for each of the site you'll come up with this rating  of travel compatibility. And  they all depend on the same users  but different sites  and that makes a - I'm tr- I w- I wa- have been trying to see whether the P_R_M would make it more efficient if we do inferencing like that. And so  I guess you end up having fewer number of nodes than in a flat Bayes-net  cuz otherwise you would - c- well  it's probably the same . But um  No  you would definitely have - be able to re-use  like  um  all the user stuff  and not - not having to recompute a lot of the stuff  because it's all from the user side. So if you changed sites  you - you can  you know  save some work on that. But  you know  in the case where  it depends on both the user and the site  then I'm still having a hard time trying to see how um  using the P_R_M will help. Um  so anyhow  using those intermediate nodes then  this - this would be the class that represent the intermediate nodes. And that would - basically it's just another class in the model  with  you know  references to the user and the site and the time. And then  after you group them together this - no- the dependencies would - of the queries would be reduced to this. And so  you know  it's easier to specify the C_P_T and all. Um  so I think that's about as far as I've gone on the P_R_M stuff. Well Right. No. So y- you didn't yet tell us what the output is. The output. So what decisions does this make? O_K. So it only makes two decisions  in this model. And one is basically how desirable a site is meaning  um  how good it matches the needs of a user. And the other is the mode of the visit  whether th- It's the E_V_A decision. Um  so  instead of um  doing a lot of  you know  computation about  you know  which one site it wants of - the user wants to visit  I'll come - well  try to come up with like  sort of a list of sites. And for each site  you know  where - h- how - how well it fits  and basically a rating of how well it fits and what to do with it. So. Anything else I missed? So that was pretty quick. She's ac- uh uh Eva's got a little write-up on it that uh  probably gives the - the details to anybody who needs them. Um  so the - You - you didn't look at all yet to see if there's anybody has a implementation . No  not yet  um - O_K. So one - so one of the questions  you know  about these P_R_Ms is Mm-hmm. uh  we aren't gonna build our own interpreter  so if - if we can't find one  then we uh  go off and do something else and wait until s- one appears. Uh  so one of the things that Eva's gonna do over the next few weeks is see if we can track that down. Uh  the people at Stanford write papers as if they had one  but  um  we'll see. So w- Anyway. So that's a - a major open issue. If there is an interpreter  it looks like you know  what Eva's got should run and we should be able to actually um  try to solve  you know  the problems  to actually take the data  and do it. Uh  and we'll see. Uh  I actually think it is cleaner  and the ability to instantiate  you know  instance of people and sites and stuff  um  will help in the expression. Whether the inference gets any faster or not I don't know. Uh  it wouldn't surprise me if it - if it doesn't. Mm-hmm. You know  it's the same kind of information. I think there are things that you can express this way which you can't express in a normal belief-net  uh  without going to some incredible hacking of - sort of rebuilding it on the fly. I mean  the notion of instantiating your el- elements from the ontology and stuff fits this very nicely and doesn't fit very well into the extended belief-net. So that was one of the main reasons for doing it. Um. I don't know. So  uh  people who have thought about the problem  like Robert i- it looked to me like if Eva were able to come up with a you know  value for each of a number of uh  sites plus its E_V_A thing  that a travel planner should be able to take it from there. And - you know  with some other information about how much time the person has and whatever  and then plan a route. Um-hmm  um  well  first of all uh  uh  great looks  mu- much cleaner  nnn  nnn  Certain - certain beauty in it  so  um  if beauty is truth  then  uh we're in good shape. But  the um  as  uh  mentioned before we probably should look at t- the details. So if you have a write-up then uh  I'd love to read it and uh - Mm-hmm. because  um  i- Can you go all the way back to the - the very top? Yeah. Um  uh these - @@ these - w- w- when these are instantiated they take on the same values? that we had before? or are they - I can't really see the whole thing. have they changed  in a sense? Well I think I basically leave them to similar things. Uh-huh. Some of the things might - that might be different  maybe like - are that the hours for the site. Hmm. And  eventually I meant that to mean whether they're open at this hour or not. And status would be  you know  more or less like  whether they're under construction  and - and - or Uh-huh. And the  uh  stuff like that. other question I would have is that presumably  from the way the Stanford people talk about it  you can put the probabilities also on the relations. If - Which is the structural uncertainty? Yeah. Yeah  I - that's - That I think was actually in the previous - the Ubenth stuff. I don't remember whether they carried that over to this or not  Mmm. uh  structural uncertainty. It's sort of in the definition or - in the - in Daphne's definition of a P_R_M is that O_K. classes and relations  and you're gonna have C_P_T's over the classes and their relations. Alright. More uncertainty  or - or - Uh  I remember them learning when  you know  you don't know the structure for sure  but I don't remember reading how you specify I should say. Yeah. Yeah  that would be exactly my question. Well - Right. wh- to start with. Yeah. Yeah. Yeah. So  uh  the - the plan is - is when Daphne gets back  we'll get in touch and supposedly  um  we'll actually get s- deep - seriously connected to - to their work and Yep. somebody'll - Uh  you know - If it's a group meeting once a week probably someone'll go down and  whatever. So  we'll actually figure all this out. O_K . O_K. Then I think the w- long term perspective is - is pretty clear. We get rocking and rolling on this again  once we get a package  if  when  and how  then Mm-hmm. this becomes foregrounded profiled  focused  again. Designated? Of course. And um  until then we'll come up with a something that's - @@ that's way more complicated for you. Right? O_K. Because this was laughingly easy  right? Actually I had to take out a lot of the complicated stuff  cuz I - I made it really complicated in the beginning  and Jerry was like  ""this is just too much"". Yeah. So  um  you could  from this  go on and say suppose there's a group of people traveling together and you wanted to plan something that somehow  with some Pareto optimal That's good . uh  uh  thing for - That's definitely a job for artificial intelligence. uh  or - Well that's not - not even something humans - yeah. Except for humans can't really solve it either  so. Right. Right. Well that's the - that would - that would be a - uh  you could sell it  as a - O_K  eh you don't have to fight about this  just give your preferences to the - Yeah. And then you can blame the computer. So. w- Exactly. Hmm. But what does it - uh - Would a pote- potential result be to - to split up and never talk to each other again? You know. That should be one of them. Yeah. Yeah. Right. That'd be nice. Mmm. Anyway. So. So there i- there are some - some u- uh  you know  uh  elaborations of this that you could try to put in to this structure  but I don't think it's worth it now. Because we're gonna see what - what else uh - what else we're gonna do. Anyway. But uh  it's good  yeah and - and there were a couple other ideas of - of uh  things for Eva to look at in - in the interim. Good. Then  we can move on and see what Andreas has got out his sleeve. Or Andy  for that matter? O_K. So uh  uh  well  thanks for having me here  first of all. Um  so maybe just a - a little background on - on my visit. So  uh  I'm not really involved in any project  that's uh - that's relevant to you uh  a- at the moment  uh  the - the reason is really for me uh  to have an opportunity to talk to some other researchers in the field. And - and so I'll just n- sort of give you a real quick introduction to what I'm working on  and um  I just hope that you have some comments or  maybe you're interested in it to find out more  and - and so I'll be uh  happy to talk to you and - and uh  I'd also like to find out some more and - and maybe I'll just walk around the office and and then - and ask some - some questions  uh  in a couple days. So I'll be here for uh  tomorrow and then uh  the remainder of uh  next week. O_K  so  um  what I started looking at  uh  to begin with is just uh  content management systems uh  i- i- in general. So um  uh what's uh - Sort of the state of the art there is to um - uh you have a bunch of - of uh documents or learning units or learning objects  um  and you store meta-data uh  associate to them. So there's some international standards like the I_-triple-E_  uh - There's an I_-triple-E_  L_O_N standard  and um  these fields are pretty straightforward  you have uh author information  you have uh  size information  format information and so on. Uh  but they're two uh fields that are um  more interesting. One is uh you store keywords associated with the uh - with the document  and one is uh  you have sort of a  um  well  what is the document about? So it's some sort of taxonomic uh  ordering of - of the - of the units. Now  if you sort of put on your semantic glasses  uh you say  well that's not all that easy  because there's an implicit um  uh  assumption behind that is that uh  all the users of this system share the same interpretation of the keyword and the same interpretation of uh  whichever taxonomy is used  and uh  I think that's a - that's a very - that's a key point of these systems and they sort of always brush over this real quickly without really elaborating much of that and uh - As a matter of fact  the only thing that m- apparently really works out so far are library ordering codes  which are very  very coarse grain  so you have some like  science  biology  and then - But that's really all that we have at the moment. So I think there's a huge  um  uh need for improvement there. Now  what this uh - a standard like this would give us is we could um  sort of uh with a search engine just query uh  different repositories all over the world. But we can't really - Um  so what I'm - what I try to do is um  to have um  uh - So. So the scenario is the following  you- you're working on some sort of project and you encounter a certain problem. Now  what - what we have at our university quite a bit is that uh  students um  try to u- program a certain assignment  for example  they always run into the same problems  uh  and they always come running to us  and they'll say why's it not - it's not working  and we always give out the same answer  so we thought  well  it'd be nice to have a system that could sort of take care of this  and so  what I want to build is basically a - a smart F_A_ Q system. Now  what you uh need to do here is you need to provide some context information which is more elaborate than ""I'm looking for this and this and this keyword. "" So. And I think that I don't need to tell you this. I'm - I'm sure you have the same - when - when somebody utters a sentence in a certain  uh  context it  and - and the same sentence in another context makes a huge difference. So  I want to be able to model information like  um  so in the - in the context of - in the context of developing distributed systems  of a- at a computer science school  um  what kind of software is the person using  which homework assignment is he or she working on at the moment  um  maybe what's the background of that student's um  which um  which error message was encountered. So this sort of information I think should be transmitted  uh  when a certain document is retrieved. Now  um  basically giving this um - Uh so we somehow need to have a formalized um  way of writing this down basically  and that's where the shared interpretation of - of certain terms and keywords comes in again. And  using this and some - some uh  knowledge about the domain I think you can do some - some simple inferences. Like you know that when somebody's working about - uh  working on - on servlets for example  he's using Java  cuz servlets are used - are written in Java. So some - some inferences like that  now  um  u- using this you can infer more information  and you could then match this to the meta-data of um - off the documents you're - you're searching against. So  uh what I wanna do is basically have some sort of um - given these inputs  and then I can compute how many documents match  and use this as a metric in the search. Now  what I plan to do is I want to uh sort of do a uh - uh try to improve the quality of the search results  and I want to do this by having a depth uh  um  um - steepest descent approach. So if I knew which operating system the person was working on  would this improve my search result? And - and having uh  uh a symbolic formalized model of this I could simply compute that  and find out which um - which questions are worth um  asking. And that's what I then propagate back to the user  and - and sort of try to optimize the search in this way. Now  the big problem that I'm facing right now is um  it's fairly easy to hack up a system uh quickly  that - that works in the small domain  but the problem is obviously the scalability. And uh uh  so Robert was mentioning uh  earlier today is that uh  Microsoft for example with their printer set up program has a Bayesian network  which does exactly this  but there you face a problem that these are very hard to extend. And so  uh what I'm - What I try to do is basically try to model this uh  in a way that you could really combine uh  knowledge from very different sources  and - and um  sort of looking into some of the ideas that the semantic web community uh  came up with. Trying to - to have uh  an approach how to integrate s- uh certain uh - representation of certain concepts and also some computational rules  um  what you can do with those. Um. What I'm also looking into is a probabilistic approach into this because document retrievals is a very fuzzy procedure  so it's probably not that easy to simply have a symbolic uh  computational model. That - that probably isn't expressive enough. So. So that's another thing  um  which I think you're also uh  uh looking into right now. And then um  uh sort of as an add-on to this whole idea  um  uh that would be now  depending on what the search engine or the content repository - depending on which - um  uh  which uh  rules and which ontologies it - it uses  or basically its view of the world  uh you can get very different results. So it might ma- make a lot of sense to actually query a lot of different search engines. And there you could have an idea where you actually have sort of a - a peer to peer approach  where we're all sort of carrying around our individual bookshelves  and um  if you have a question about a homework  it's - probably makes sense to ask somebody who's in your class with you  sort of the guru in the certain area  rather than going to some Yahoo-like uh  search engine. So these are some of the - just in a nutshell  some of the ideas. And I think a lot of the - even though it's a - it's a very different domain  but I think a lot of the  um  issues are - are fairly similar. So. O_K. And so some of the - I don't know how much you know about the larger Heidelberg project  I - Are you - Uh I know  yeah I know abou- about it. So it seems like a lot of - some of the issues are the same. It's like  um  you know  the c- context-based factors that influence how you interpret  Mm-hmm. Mm-hmm. um  s- how to interpret. In - in this case  infer- in- in knowing - wanting to know what kinds of things to ask. We- we've kind of talked about that  but we haven't Mm-hmm. worried too much about that end of the discourse. But maybe you guys had that in the previous Well  in a - in one - t- one s- mmm  small difference in a - in a way  is that models. he doesn't have to come up with an answer  but he wants to point to the places w- w- Yeah  so. So I'm - I'm not - I'm not building an expert - Uh  I want to build a smart librarian  basically that can point you to the right reference. I don't wanna compute the answer  Documents that have the answers. Mm-hmm. Right. Right. so it's a little bit easier for me. Well. Uh  you have to s- still m- understand what the content says about itself  and then match it to Mm-hmm. what you think the informational needs - Mm-hmm. So you also don't have to figure out what the content is. You're just taking the keywords as a topic text  as - I - I assume that - that the- there will be learning systems that - that tag their - their content. O_K. And um  um  Right. m- @@ and basically what I - what I envision is that you - rather than just supplying a bunch of keywords you could basically - for - for an F_A_Q for example you could state sort of like a logic condition  when this document applies. So ""this document explains how to set up your uh  mail account on Linux"" or something like this. Mm-hmm. So. So something - something very specific that you can then - But the - I think that the key point with these uh  learning systems is that uh  a learning system is only as good as uh the amount of content it - it carries. You can have the best learning system with the best Mmm  mm-hmm. search interface  if there's no content inside of it  it's not very useful. So I think ultimately because um  uh developing these - these rules and these inference uh - inferences I think is very costly  so um  uh I think you must be able to reuse some - some existing um  domain - domain information  or - or - or ontologies that - that uh other people wrote and then try to integrate them  and then also search the entire web basically  rather than just the small uh  content management system. O_K. Mm-hmm. So I think that's - that's crucial for - for the success of - or @@ - So  you're not - I guess I'm trying to figure out how - how it maps to the kinds of things Mm-hmm. that we've talked about in this group  and  actually associated groups  cuz some of us do pretty detailed linguistic analyses  and I'm guessing that you - you won't be doing that? No. O_K. Just checking. So  O_K. Hmm. No. So  you take the query  and - and - On the other hand  uh  FrameNet could well be useful. So do you know the FrameNet story? Um  yeah. Uh  not - not too much  but uh  O_K. Oh. Th- that's another thing you might wanna look into while you're here. I have a rough overview. Because  um  you know  the standard story is that keyworks - keywords evoke frames  and the frames may well give you additional keywords or uh  if you know that - that - that a - a bunch of keywords uh  indicate a frame  then you can find documents that actually have the whole frame  rather th- than just Mmm. Mmm. uh  individual - So there's a lot of stuff  and people are looking at that. Most of the work here is just trying to get the frames right. There's linguists and stuff and there's a lot of it and they're - they're busily working away. But there are some application efforts trying to exploit it. And this looks t- it seems to be that this is a place where Yeah. Yeah. you might be able to do that. Yeah. I'm sure I could learn a lot about um  Mmm. yeah  just how to - how to come up with these structures  cuz it's - it's very easy to whip up something quickly  but it maybe then makes sense to - to me  but not to anybody else  and - and if we want to share and integrate things  they must - well  they must be well designed really. Remember the uh  Prashant story? Right. The absolutely no - no linguistic background person that the I_U sent over here. Right. And Andreas and I tried to come up wi- or we had come up actually with a eh - with him working on an interface for FrameNet  as it was back then  that would Right. p- do some of the work for this machine  Yeah. which uh  never got done because Prashant found a happy occupation which in the - W- yeah  I know  I mean it - it - he - w- he did w- what - what he did was much more s- sensible for him. I think uh  Absolutely. Yeah. But so - I'm just saying  the uh  we had that idea you know - Yeah. The idea was there. Yeah  O_K. uh to - to exploit FrameNet Yeah. Hmm. there as well. And um. Yeah  actually you guys never - And Srini's doing information extraction also  right? with that FrameNet base. Mm-hmm. Right. Yeah. Mmm. So you - you guys never sent anybody else from I_ U. You were y- no - Except - except Prashant? Yeah. Uh  this was supposedly an exchange program  and - I - we - you know  it's fine. We don't care  but it just - I'm a little surprised that Um  @@ uh  Andreas didn't come up with anyone else he wanted to send. @@ @@ Uh I don't know  I mean the uh - Alright. I mean I had forgotten a- I - To be honest with you  I'd totally forgotten we had a program. Hmm. Uh it's in the program? Uh I - I think it's - it's really the lack of students uh  at I_U at the moment. Yeah. Yeah. No  no. There was a whole co- There was a little contract signed. It was - Yeah. Yeah  yeah. I think it's ju- it's more the lack of - of students  really  and w- we have all these sponsors that are always sort of eager to get some teams. But - Yeah  I know. Mmm. Right. Right. Well I mean if - if I were a student  I'd love to come here  rather than Yeah. work for some German company  or - Right. You are being recorded right now  so beware. Oh  right! Well  I didn't say anybody to - anything to offend - well  except for the sponsors maybe  but - Right. Anyway. Right. So I thi- tha- that's - that's one of the things that might be worth looking into while you're here. Mm-hmm. Uh  unfortunately  Srini  who is heavily involved in DAML and all this sort of stuff is himself out of town. Mm-hmm. Well I'll go to the uh  Semantic Web Workshop  uh  Right  and - in two weeks. @@ Yeah  for - for some reason he's not doing that. Yeah. I don't know why he @@ - oh  I  who knows? Anyway  s- yeah  you'll see - you'll certainly see a lot of the people there. Well  he had other things to do. The uh - The other person I thought of is Dan Gildea? because he did some work on topic Yeah. St- statistical stuff. That would be a very good idea. spotting w- um  Mm-hmm. which is  I mean  you - I mean. I don't - Depending on how well you wanna integrate with that end  you know  like  taking the data and fig- you said the learning systems that figure out - We - There's someone in ICSI who actually has been working on - has worked on that kinda stuff  and he's worked with frame net  so you could talk to him about  you know  both of those things at once. So. Mm-hmm. Mm-hmm. And he just finished writing a draft of his thesis. So. So  uh  who is that again? I- u- Dan Gildea  G_I_L_D_E_A. And  he's in one of the rooms on the fifth floor and stuff  and - Who? I can take you to his office. It's just around the corner. O_K  great. Hmm. Well  if you fal- solve the problem  hope you can do one for us too. Alright  was there anything else for this? One of these times soon we're gonna hear about construal. Yeah. I'm sure. I have um - I think it was November two thousand three or some - No. Wh- I had something in my calendar. Oh  O_K. Right . Um  Wait a second. That's a long way away. Good thinking! Uh well  maybe I can - I can bribe my way out of this. So. So I did some double checking and it seems like spring break in two thousand one. No. Talk about changing the topic. Well  no  but he's - he's - he's - he's - as you said  he's  like the state legislature  he's trying to offer us bribes. At least this is a private meeting. Right  exactly  O_K  that's the link. This uh - Oh  they refused the budget again? Is it - so about CITRIS? Yeah  still nothing. Uh  this - this - this - t- the s- we're  uh  involved in a literally three hundred million dollar uh  program. Uh  with the State of California. And  the State of California is now a month and a half behind its legis- its legally required date to approve a budget. So the budget has not been approved. And two days ago - There's two l- you know  so  two branches of legislature. One branch approved it  Mm-hmm. and  um  yesterdayday there was this uh - uh I thought that the other branch would just approve it  but now there's actually a little back sliding to people who - who approved it got flak from there  eh anyway. So  um - Oh! I have to tell you a wonderful story about this  O_K? And then we'll go. So  I - it turns out I wound up having lunch today with a guy named Tom Kalil. K_I_L_L - K_A_L_I_L. And  uh  he now works at Berkeley. In fact he's hired to run a lot of CITRIS  even though we don't have the money they - So they've been hiring people right and left  so  uh  they think the money's coming. So - and he was  I think  the chief staffer to Clinton on technology matters. He was in the White House  I don't remember what he was saying . A- anyway  like that. And  is now doing all the politics for CITRIS  but also  has a uh  a lot of interest in uh  actually doing things for society  so digital divide and stuff like that. So that's s- interesting to me but maybe not to you. But the really interesting thing was  he st- he s- he s- said something about  you know I'm interested in things that have high social multiplier  something that is of great social value. He said  ""for example""  this was his only example  ""if you had a adult literacy program that was as good as an individual tutor  and as compelling as a video game  then that would have a huge social impact"". I said  ""Oh great! That's a good problem to work on."" Anyway. So it was nice that uh  he's got this view  of A_  that's what you should try to do  and B_  uh  language would be a good way to do it. So that's - Mmm. Definitely. So anyway  that's the end of the story. But for adults and not for the This was - Yeah. I didn't push him on the ch- on the child thing  but  uh  children. Uh-huh. you know  a- again  if - if you - if you Oh. um  and this was - this was literacy  which actually is somewhat different problem. Maybe easier. I don't know. Mm-hmm. So this is reading  rather than teaching - Another project we started on  and - and didn't get funded for was  uh  to try to build an automatic tutoring program  for kids whose first language wasn't English. Which is like half the school population in California. Something like that  isn't it? Mm-hmm. Yeah. So  enormous problem in California  and the idea was if we're so smart about language understanding and speech understanding  couldn't we build uh  programs that would be tutors for the kids. We think we could. Anyway. So - so - But this is a slightly different problem  and Mm-hmm. um  I know none of us have the spare time to look at it right now  but it i- it's - it's interesting and I may um  talk to him some more about is em- somebody already doing this  and stuff like that. So anyway  that was - that was today's little story. Hmm. O_K. So I - I did manage to get - pull my head out of the sling by sidetracking into CITRIS  but uh or - a- temporarily putting it out of the sling but  I - I'll volunteer to put it right back in by stating that No  no. Right. I am n- uh among some other things in the process of writing up stuff that we have been discussing at our daily meetings  Yeah. and also revising  thanks for all the comments  the c- the original construal proposal. And  if I put one and one together  I may end up with a number that's greater than one and that I - I can potentially present once you get back. Greater than two? You're good. Nnn. s- sometimes  you know the sum is not uh less than the - Uh  right  right. Right. Right. Anyway. Yeah  so - O_K  so that'd be great  but I'd - I think it's - it's time again  right? Absolutely. Yeah. But um  and hopefully all sidetracking Yeah. O_K. um  other things will have disappeared  soon. Good. Yep. Done? ","This meeting mainly outlines the progress of the meeting recorder project. In particular  the group discuss their preparation of materials for the transcriptions of digits by IBM  and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting. Other discussion focuses on the re-evaluation of recognition without cheating on segmentation  and also how SRI recognition can be improved  especially for the female group. A number of issues regarding the management of data are addressed by the group: The inclusion of different data types in the corpus  and the storage and back-up of the group's data. Progress has been made in naming conventions  with file reorganisation to be done at a later date  however this was not discussed fully due to Chuck's absence. Finally  Absinthe is now up and running with improved performance. Discussion of demos for the July DARPA meeting were left to the individuals concerned. A number of data issues were resolved: After discussing the human-computer interaction Smartkom data  the group decide that different types of data can be included in the meeting corpus  but that it should be structured into different directories according to data type. Some of the data storage problems can be overcome by backing up using the NW archive. However  file reorganisation will be left until just before zero-level back up. The group decide to use IBM transcription of the digits  in addition to automatic methods. If IBM methods work  transcribers will check and comment these. Discussion of demos for the July meeting has been postponed: the individuals concerned will meet independently. Disk space is an issue for the group  especially in terms of back-up  which is 75% full: DVDs or CDs are unreliable and cannot be used  and although tape is reliable  this creates access issues. Experimentation with the SRI recognition have shown greater error when using tandem features  with vocal tract normalisation also making results worse. In particular more error is found with the female group which is 1-2% worse than the males. Digit and beeps have been re-recorded by Chuck to aid IBM transcription  and enable alignment. The group discuss the extent to which digits can be automatically transcribed  including their experimentation with forced alignment and speech recognition. Transcription is progressing well: two transcribers hired and and two more will be hired soon. Five ""set 2"" meetings are being edited by the head transcriber  and ""set 3"" are being prepared  with the aim of having 20 available for the DARPA demo. Pre-segmentation is very useful  with visual information desirable for transcription of backchannel behaviour. Now Thilo's segmenter is working  the group discuss re-evaluation of recognition without cheating on the segmentation  possibly using time-constrained alignment. Also  they discuss the use of recogniser alignment to train the speech detector. The group discuss possible ways to improve the SRI recognition error rate  suggestions include use of low-pass filter  or retraining models. Differences in smoothing are proposed to be mainly responsible for the difference between the male and female results. File reorganisation was discussed briefly as Chuck was not present  however progress has been made in sharing file naming conventions with UW. Also  the Absinthe machine is now working well  and has speeded up in proportion to its extra processors. "
